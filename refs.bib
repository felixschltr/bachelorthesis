
@article{schiff_deaf_1972,
	title = {Deaf and Hearing Children's Performance on a Tactual Perception Battery},
	volume = {35},
	issn = {0031-5125},
	url = {https://doi.org/10.2466/pms.1972.35.3.683},
	doi = {10.2466/pms.1972.35.3.683},
	abstract = {A battery of tactual sensitivity tests was administered to 300 deaf and hearing children and adolescents. The tests included vibrotactile and two-point sensitivity on several areas of the hand, gap-detection using two stimulation techniques, roughness discrimination, pattern discrimination, and cross-modal object identification. Measures included sensory thresholds, correct discrimination, errors, and in some cases, response latencies. Deaf youngsters were more sensitive than their hearing counterparts with vibrotactile and two-point measures. On most remaining tasks, deaf and hearing Ss' performance accuracies did not differ, although hearing Ss performed faster on all timed tasks. Improvements with age were evident with both speed and accuracy measures for several tasks. Results were discussed as to deaf/hearing differences, and reading achievement scores, active versus passive touch, developmental changes, and relations among the tactual tasks and measures of the battery. The findings strongly suggested that different measures of tactual sensitivity tap quite different sensory and perceptual abilities.},
	pages = {683--706},
	number = {3},
	journaltitle = {Perceptual and Motor Skills},
	shortjournal = {Percept Mot Skills},
	author = {Schiff, William and Dytell, Rita Scher},
	urldate = {2019-01-02},
	date = {1972},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/SLQW35CZ/Schiff and Dytell - 1972 - Deaf and Hearing Children's Performance on a Tactu.pdf:application/pdf}
}

@article{stevens_spatial_1996,
	title = {Spatial Acuity of the Body Surface over the Life Span},
	volume = {13},
	issn = {0899-0220},
	url = {https://doi.org/10.3109/08990229609051403},
	doi = {10.3109/08990229609051403},
	abstract = {Spatial acuity over 13 regions of the body was assessed cross-sectionally in 122 male and female subjects between 8 and 87 years of age. Of two measures, the primary one was a threshold for detecting a gap between two points (a refinement of the conventional two-point threshold). The secondary one was a threshold of point localization in 7 of these 13 body regions. The two measures yielded similar pictures of body acuity and age-related changes in acuity, and they agreed in essentials with an early acuity map dating back to Weber in 1835, as cited and confirmed experimentally by Weinstein (1968). To this acuity map, the present study added the dimension of age. The main finding was that aging is much harder on some body regions than on others. Declining acuity with age was found to characterize all regions to one degree or another, but the hands and feet turned out to be far more vulnerable than the more central regions, including the very acute lip and tongue. Deterioration of acuity in the great toe (averaging 400\% between youth and advanced age) and fingertip (averaging 130\%) may adversely affect such diverse activities as braille reading, grasping, and maintaining balance. The acuity map determined by gap discrimination was essentially the same for males and females; however, males gave significantly smaller localization thresholds than females. In two body regions tested (fingertip and upper lip), children significantly outperformed young adults at gap discrimination.},
	pages = {153--166},
	number = {2},
	journaltitle = {Somatosensory \& Motor Research},
	author = {Stevens, Joseph C. and Choo, Kenneth K.},
	urldate = {2019-01-02},
	date = {1996},
	pmid = {8844964},
	keywords = {aging, gap discrimination, point localization, spatial acuity, two-point discrimination},
	file = {Snapshot:/home/felix/Zotero/storage/HJJAHRP5/08990229609051403.html:text/html}
}

@article{craig_grating_1999,
	title = {Grating orientation as a measure of tactile spatial acuity},
	volume = {16},
	issn = {0899-0220},
	url = {https://doi.org/10.1080/08990229970456},
	doi = {10.1080/08990229970456},
	abstract = {Recent studies have used grating orientation as a measure of tactile spatial acuity on the fingerpad. In this task subjects identify the orientation of a grooved surface presented in either the proximal-distal or lateral-medial orientation. Other recent results have suggested that there might be a substantial anisotropy on the fingerpad related to spatial sensitivity. This anisotropy was revealed using a task in which subjects discriminated between a smooth and a grooved surface presented at different orientations on the fingerpad. The anisotropy was substantial enough that it might permit subjects to discriminate grating orientation on the basis of intensive rather than spatial cues. The present study examined the possibility that anisotropy on the fingerpad might provide cues in a spatial acuity task. The ability of subjects to discriminate between a smooth and a grooved surface was measured under conditions that are typically used in grating orientation tasks. No evidence of anisotropy was found. Also, using a grating orientation task, separate estimates were made of sensitivity in the proximal-distal and lateral-medial orientations. Again no evidence of anisotropy was found. Consistent with changes in the density of innervation, grating orientation sensitivity was found to vary as a function of location on the fingerpad. The results support the view that grating orientation is a valid measure of spatial acuity reflecting underlying neural, spatial mechanisms.},
	pages = {197--206},
	number = {3},
	journaltitle = {Somatosensory \& Motor Research},
	author = {Craig, James C.},
	urldate = {2019-01-02},
	date = {1999},
	keywords = {Tactile Sensitivity Spatial Acuity Cutaneous Sensitivity},
	file = {Full Text PDF:/home/felix/Zotero/storage/EVBDEIWT/Craig - 1999 - Grating orientation as a measure of tactile spatia.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/TFERYJ6N/08990229970456.html:text/html}
}

@article{craig_two-point_2000,
	title = {The Two-Point Threshold: Not a Measure of Tactile Spatial Resolution},
	volume = {9},
	issn = {0963-7214},
	url = {https://doi.org/10.1111/1467-8721.00054},
	doi = {10.1111/1467-8721.00054},
	shorttitle = {The Two-Point Threshold},
	abstract = {The two-point threshold, or compass test, has long been used as a measure of tactile spatial resolution; however, since it was first developed, there have been problems associated with its use. Some of these problems include setting an appropriate criterion for responding “two,” extreme variability both within and between subjects, and the ability of subjects to discriminate two points from one at separations well below the two-point threshold. Recent neurophysiological results have clarified some of the neural mechanisms responsible for spatial resolution and demonstrated the inadequacy of the two-point threshold as a measure of spatial mechanisms. Several new methods may overcome these problems and provide a valid measure of spatial resolution and a reflection of neural mechanisms.},
	pages = {29--32},
	number = {1},
	journaltitle = {Current Directions in Psychological Science},
	shortjournal = {Curr Dir Psychol Sci},
	author = {Craig, James C. and Johnson, Kenneth O.},
	urldate = {2019-01-02},
	date = {2000-02-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/JL5QYZ7S/Craig and Johnson - 2000 - The Two-Point Threshold Not a Measure of Tactile .pdf:application/pdf}
}

@article{mountcastle_frequency_1990,
	title = {Frequency discrimination in the sense of flutter: psychophysical measurements correlated with postcentral events in behaving monkeys},
	volume = {10},
	rights = {© 1990 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/10/9/3032},
	doi = {10.1523/JNEUROSCI.10-09-03032.1990},
	shorttitle = {Frequency discrimination in the sense of flutter},
	abstract = {The capacities of humans and monkeys to discriminate between the frequencies of mechanical sinusoids delivered to the glabrous skin of the hand have been measured in psychophysical experiments. The 2 primates have similar capacities; they make discriminations with Weber fractions that change little over the frequency range from 20 to 200 Hz. The discriminatory capacities are similar whether stimuli are received passively or acquired actively. Combined experiments have been made in monkeys in which the electrical signs of the activity of quickly adapting ({QA}) and slowly adapting ({SA}) neurons of postcentral areas 3b and 1 were recorded, both in the working state as the animal made discriminations and in the irrelevant state in which the stimuli did not guide behavior. The neuronal responses were analyzed in terms of discharge rates, periodicities in the neuronal discharges, and harmonic contents. It was shown that discriminatory capacity depends upon the period lengths in the sets of periodically entrained activity evoked by stimuli readily discriminated, and not upon the small differences in rates of discharge evoked by those stimuli. The periodicities were shown by harmonic analysis to be sharply limited to stimulus frequencies. Low-frequency stimuli evoke periodicities at the second and third harmonics in some neurons, in addition to strongly periodic signals at the fundamental frequency of the stimuli. Their presence does not appear to interfere with frequency discrimination. Neuronal responses recorded in the stimulus-irrelevant state were not distinguishable from those recorded as monkeys made discriminations. The responses of {SA} neurons, recorded under similar conditions, resembled those of {QA} neurons in almost every feature, but reasons are given for concluding that the {SA} system plays no role in frequency discrimination in the sense of flutter.},
	pages = {3032--3044},
	number = {9},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Mountcastle, V. B. and Steinmetz, M. A. and Romo, R.},
	urldate = {2019-01-02},
	date = {1990-09-01},
	langid = {english},
	pmid = {2118947},
	file = {Full Text PDF:/home/felix/Zotero/storage/BK6RIJPF/Mountcastle et al. - 1990 - Frequency discrimination in the sense of flutter .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/EL928KKL/3032.html:text/html}
}

@article{verrillo_vibrotactile_1966,
	title = {Vibrotactile thresholds for hairy skin},
	volume = {72},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0023321},
	abstract = {Absolute vibrotactile thresholds were determined as a function of stimulus frequency and contractor area on the hairy skin of the volar forearm. Thresholds for vibration decrease in direct proportion to the contractor area with a slope of -3 db. per doubling of area. When plotted as a function of frequency these data yield a U-shaped curve with a slope of -12 db. in lower frequencies and +9 db. in frequencies above 220 cps. Both these findings confirm previous data obtained on glabrous skin. Some differences between hairy and glabrous skin were found and discussed. Evidence is presented in support of a hypothesis which suggests that there may be 2 types of mechanoreceptors in cutaneous tissue. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {47--50},
	number = {1},
	journaltitle = {Journal of Experimental Psychology},
	author = {Verrillo, Ronald T.},
	date = {1966},
	keywords = {Skin (Anatomy), Stimulus Frequency, Thresholds, Vibrotactile Thresholds},
	file = {Snapshot:/home/felix/Zotero/storage/37PC8GWV/1966-08361-001.html:text/html}
}

@article{gescheider_selective_1979,
	title = {Selective adaptation of vibrotactile thresholds},
	volume = {3},
	issn = {0363-3799(Print)},
	abstract = {Conducted 3 experiments, each with 3 experienced Ss. Psychophysical thresholds for the detection of vibrotactile stimuli on the thenar eminence were measured before and after adaptation by a 250-Hz stimulus of varied intensity. When the test stimulus was 140 Hz, thresholds began to be elevated as soon as the intensity of the adapting stimulus exceeded absolute threshold. This result was consistent with independent evidence obtained from measurements of unadapted thresholds that thresholds for 140- and 250-Hz stimuli were mediated by the same receptor system (Pacinian). When the test stimulus was either 20 or 30 Hz, the adapting stimulus had no effect until it was approximately 24 db above the psychophysical threshold. This value corresponded exactly to the postulated threshold of non-Pacinian receptors as estimated from measurements of unadapted threshold. Similar frequency-dependent adaptation effects were observed when the rigid surround used to confine the vibratory stimulus to the region of the vibrating contactor was removed. Findings support a duplex theory of vibrotactile sensitivity. (25 ref) ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {37--48},
	number = {1},
	journaltitle = {Sensory Processes},
	author = {Gescheider, George A. and Frisina, Robert D. and Verrillo, Ronald T.},
	date = {1979},
	keywords = {Vibrotactile Thresholds, Sensory Adaptation, Stimulus Intensity, Stimulus Parameters},
	file = {Snapshot:/home/felix/Zotero/storage/VRTUILNK/1981-02563-001.html:text/html}
}

@article{lamore_evidence_1988,
	title = {Evidence for different types of mechanoreceptors from measurements of the psychophysical threshold for vibrations under different stimulation conditions},
	volume = {83},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.396365},
	doi = {10.1121/1.396365},
	pages = {2339--2351},
	number = {6},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Lamoré, P. J. J. and Keemink, C. J.},
	urldate = {2019-01-02},
	date = {1988-06-01},
	file = {Snapshot:/home/felix/Zotero/storage/WTS2PAX2/1.html:text/html}
}

@article{johnson_roles_2001,
	title = {The roles and functions of cutaneous mechanoreceptors},
	volume = {11},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438800002348},
	doi = {10.1016/S0959-4388(00)00234-8},
	abstract = {Combined psychophysical and neurophysiological research has resulted in a relatively complete picture of the neural mechanisms of tactile perception. The results support the idea that each of the four mechanoreceptive afferent systems innervating the hand serves a distinctly different perceptual function, and that tactile perception can be understood as the sum of these functions. Furthermore, the receptors in each of those systems seem to be specialized for their assigned perceptual function.},
	pages = {455--461},
	number = {4},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Johnson, Kenneth O},
	urldate = {2019-01-02},
	date = {2001-08-01},
	keywords = {cutaneous, neurophysiology, psychophysics, receptor, somatosensory, tactile},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/6R48VARA/S0959438800002348.html:text/html}
}

@article{verrillo_effect_1963,
	title = {Effect of Contactor Area on the Vibrotactile Threshold},
	volume = {35},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1918868},
	doi = {10.1121/1.1918868},
	pages = {1962--1966},
	number = {12},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Verrillo, Ronald T.},
	urldate = {2019-01-02},
	date = {1963-12-01},
	file = {Snapshot:/home/felix/Zotero/storage/QFUY9S2X/1.html:text/html}
}

@article{perez_two-point_2000,
	title = {Two-point vibrotactile discrimination related to parameters of pulse burst stimulus},
	volume = {38},
	issn = {1741-0444},
	url = {https://doi.org/10.1007/BF02344692},
	doi = {10.1007/BF02344692},
	abstract = {Tactile spatial resolution is an important factor in the design of vibrotactile arrays. The two-point discrimination distance is used as a measure of tactile spatial resolution. An experimental study is presented showing the effect of pulse burst stimulus parameters, pulse repetition period and duty cycle on two-point vibrotactile spatial discrimination. An array of piezoceramic vibrators is used to measure two-point spatial discrimination on the index finger. In a group of 14 subjects, the average two-point discrimination distance for a pulse repetition period of 1/25 s is 2.1 mm ({SD}=1.0), whereas for 1/500 s it is 5.1 mm ({SD}=0.9). Differences in discrimination distances are statistically significant according to the {ANOVA} analysis (p{\textless}0.001). Results show that the two-point discrimination distance is better for longer pulse repetition periods. Therefore the pulse repetition period in an excitatory waveform composed of bursts of pulses is important for tactile resolution. No statistically significant differences in discrimination distances are found between bursts of pulses of 50\% duty cycle and those of lower duty cycle. The latter result indicates that, by choosing low-duty cycle waveforms for vibrotactile stimulation, the power can be reduced with no loss in two-point discrimination capacity.},
	pages = {74--79},
	number = {1},
	journaltitle = {Medical and Biological Engineering and Computing},
	shortjournal = {Med. Biol. Eng. Comput.},
	author = {Perez, C. A. and Holzmann, C. A. and Jaeschke, H. E.},
	urldate = {2019-01-02},
	date = {2000-01-01},
	langid = {english},
	keywords = {Tactile excitation, Tactile parameter optimisation, Two-point vibrotactile discrimination, Vibrotactile excitation, Vibrotactile resolution},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/IR33KB3S/Perez et al. - 2000 - Two-point vibrotactile discrimination related to p.pdf:application/pdf}
}

@article{johansson_receptive_1976,
	title = {Receptive field sensitivity profile mechanosensitive units innervating the glabrous skin of the human hand},
	volume = {104},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/0006899376906272},
	doi = {10.1016/0006-8993(76)90627-2},
	pages = {330--334},
	number = {2},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Johansson, Roland S.},
	urldate = {2019-01-02},
	date = {1976-03-12},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/HEMQFHI3/0006899376906272.html:text/html}
}

@online{noauthor_export_nodate,
	title = {Export to {RefWorks} - Which version?},
	url = {https://refworks.proquest.com/combined-export/?detoken=YtQ-N8Q5Qk5mXO-sLP44},
	urldate = {2019-01-02},
	file = {Snapshot:/home/felix/Zotero/storage/PQTU4ZXB/combined-export.html:text/html}
}

@article{bolanowski_four_1988,
	title = {Four channels mediate the mechanical aspects of touch},
	volume = {84},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.397184},
	doi = {10.1121/1.397184},
	pages = {1680--1694},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Bolanowski, S. J. and Gescheider, G. A. and Verrillo, R. T. and Checkosky, C. M.},
	urldate = {2019-01-02},
	date = {1988-11-01},
	file = {Bolanowski_88_Four.pdf:/home/felix/Zotero/storage/NBV66W2W/Bolanowski_88_Four.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/QTMNLPNJ/1.html:text/html}
}

@article{gondan_tutorial_2016,
	title = {A tutorial on testing the race model inequality},
	volume = {78},
	issn = {1943-393X},
	url = {https://doi.org/10.3758/s13414-015-1018-y},
	doi = {10.3758/s13414-015-1018-y},
	abstract = {When participants respond in the same way to stimuli of two categories, responses are often observed to be faster when both stimuli are presented together (redundant signals) relative to the response time obtained when they are presented separately. This effect is known as the redundant signals effect. Several models have been proposed to explain this effect, including race models and coactivation models of information processing. In race models, the two stimulus components are processed in separate channels, and the faster channel determines the processing time. This mechanism leads, on average, to faster responses to redundant signals. In contrast, coactivation models assume integrated processing of the combined stimuli. To distinguish between these two accounts, Miller (Cognitive Psychology, 14, 247–279, 1982) derived the well-known race model inequality, which has become a routine test for behavioral data in experiments with redundant signals. In this tutorial, we review the basic properties of redundant signals experiments and current statistical procedures used to test the race model inequality during the period between 2011 and 2014. We highlight and discuss several issues concerning study design and the test of the race model inequality, such as inappropriate control of Type I error, insufficient statistical power, wrong treatment of omitted responses or anticipations, and the interpretation of violations of the race model inequality. We make detailed recommendations on the design of redundant signals experiments and on the statistical analysis of redundancy gains. We describe a number of coactivation models that may be considered when the race model has been shown to fail.},
	pages = {723--735},
	number = {3},
	journaltitle = {Attention, Perception, \& Psychophysics},
	shortjournal = {Atten Percept Psychophys},
	author = {Gondan, Matthias and Minakata, Katsumi},
	urldate = {2019-01-08},
	date = {2016-04-01},
	langid = {english},
	keywords = {Attention: divided attention and inattention, Multisensory processing, Reaction time methods},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/ET3B279R/Gondan and Minakata - 2016 - A tutorial on testing the race model inequality.pdf:application/pdf}
}

@article{otto_multisensory_2017,
	title = {Multisensory Decisions: the Test of a Race Model, Its Logic, and Power},
	volume = {30},
	issn = {2213-4794, 2213-4808},
	url = {https://brill.com/abstract/journals/msr/30/1/article-p1_1.xml},
	doi = {10.1163/22134808-00002541},
	shorttitle = {Multisensory Decisions},
	abstract = {The use of separate multisensory signals is often beneﬁcial. A prominent example is the speed-up of responses to two redundant signals relative to the components, which is known as the redundant signals effect ({RSE}). A convenient explanation for the effect is statistical facilitation, which is inherent in the basic architecture of race models (Raab, 1962, Trans. N. Y. Acad. Sci. 24, 574–590). However, this class of models has been largely rejected in multisensory research, which we think results from an ambiguity in deﬁnitions and misinterpretations of the inﬂuential race model test (Miller, 1982, Cogn. Psychol. 14, 247–279). To resolve these issues, we here discuss four main items. First, we clarify deﬁnitions and ask how successful models of perceptual decision making can be extended from uni- to multisensory decisions. Second, we review the race model test and emphasize elements leading to confusion with its interpretation. Third, we introduce a new approach to study the {RSE}. As a major change of direction, our working hypothesis is that the basic race model architecture is correct even if the race model test seems to suggest otherwise. Based on this approach, we argue that understanding the variability of responses is the key to understand the {RSE}. Finally, we highlight the critical role of model testability to advance research on multisensory decisions. Despite being largely rejected, it should be recognized that race models, as part of a broader class of parallel decision models, demonstrate, in fact, a convincing explanatory power in a range of experimental paradigms. To improve research consistency in the future, we conclude with a short checklist for {RSE} studies.},
	pages = {1--24},
	number = {1},
	journaltitle = {Multisensory Research},
	author = {Otto, Thomas U. and Mamassian, Pascal},
	urldate = {2019-01-08},
	date = {2017},
	langid = {english},
	file = {Otto and Mamassian - 2017 - Multisensory Decisions the Test of a Race Model, .pdf:/home/felix/Zotero/storage/9UVWE8EH/Otto and Mamassian - 2017 - Multisensory Decisions the Test of a Race Model, .pdf:application/pdf}
}

@online{noauthor_tactile_nodate,
	title = {Tactile Functions of Mechanoreceptive Afferents Innervating the Hand {\textbar} Ovid},
	url = {https://oce.ovid.com/article/00004691-200011000-00002/HTML},
	urldate = {2019-01-15},
	file = {Tactile Functions of Mechanoreceptive Afferents Innervating the Hand | Ovid:/home/felix/Zotero/storage/IVBJWD7E/HTML.html:text/html}
}

@article{mcglone_cutaneous_2010,
	title = {The cutaneous sensory system},
	volume = {34},
	issn = {0149-7634},
	url = {http://www.sciencedirect.com/science/article/pii/S014976340900116X},
	doi = {10.1016/j.neubiorev.2009.08.004},
	series = {Touch, Temperature, Pain/Itch and Pleasure},
	abstract = {The cutaneous senses are traditionally thought to comprise four recognized submodalities that relay tactile, thermal, painful and pruritic (itch) information to the central nervous system, but there is growing evidence for the presence of a fifth modality that conveys positive affective (pleasant) properties of touch. Cutaneous sensory channels can be further classified as serving predominantly either discriminative or affective functions. The former provides information about the spatial and temporal localisation of events on the body surface, e.g., the presence of an insect or the temperature of a cold wind; and the latter, although widely recognised as providing the afferent neural input driving the negative emotional experience of pain, is here posited to provide the afferent neural input driving the positive emotional experience of affiliative touch as well. A distinction is made between the properties of fast conducting myelinated afferents and those of slowly conducting unmyelinated afferents, with the former subserving a sensory-discriminative role, and the latter an affective-motivational one. Here we review the basic elements of the somatosensory system and outline evidence for the inclusion of the ‘fifth’ sub-modality, conveyed by low-threshold C-fiber mechanoreceptors as the counterpart of high-threshold C-fiber nociceptors with both C-fiber systems serving opposing aspects of affective touch, yet underpining a common mechanism for the preservation of self and species.},
	pages = {148--159},
	number = {2},
	journaltitle = {Neuroscience \& Biobehavioral Reviews},
	shortjournal = {Neuroscience \& Biobehavioral Reviews},
	author = {{McGlone}, Francis and Reilly, David},
	urldate = {2019-01-16},
	date = {2010-02-01},
	keywords = {C-fibres, {CT}-afferents, Cutaneous, Itch, Pain, Pleasure, Somatosensory, Temperature, Touch},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/ZCSGUMX4/S014976340900116X.html:text/html}
}

@article{johnson_tactile_1981,
	title = {Tactile spatial resolution. I. Two-point discrimination, gap detection, grating resolution, and letter recognition},
	volume = {46},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1981.46.6.1177},
	doi = {10.1152/jn.1981.46.6.1177},
	pages = {1177--1192},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Johnson, K. O. and Phillips, J. R.},
	urldate = {2019-01-16},
	date = {1981-12-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/98UYD7SR/Johnson and Phillips - 1981 - Tactile spatial resolution. I. Two-point discrimin.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/4975FES8/jn.1981.46.6.html:text/html}
}

@article{phillips_tactile_1981,
	title = {Tactile spatial resolution. {II}. Neural representation of Bars, edges, and gratings in monkey primary afferents},
	volume = {46},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1981.46.6.1192},
	doi = {10.1152/jn.1981.46.6.1192},
	pages = {1192--1203},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Phillips, J. R. and Johnson, K. O.},
	urldate = {2019-01-16},
	date = {1981-12-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/HIIPAP58/Phillips and Johnson - 1981 - Tactile spatial resolution. II. Neural representat.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/HQAUSK9Q/jn.1981.46.6.html:text/html}
}

@article{phillips_tactile_1981-1,
	title = {Tactile spatial resolution. {III}. A continuum mechanics model of skin predicting mechanoreceptor responses to bars, edges, and gratings},
	volume = {46},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1981.46.6.1204},
	doi = {10.1152/jn.1981.46.6.1204},
	pages = {1204--1225},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Phillips, J. R. and Johnson, K. O.},
	urldate = {2019-01-16},
	date = {1981-12-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/EYNI4MM4/Phillips and Johnson - 1981 - Tactile spatial resolution. III. A continuum mecha.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/7V98IU2J/jn.1981.46.6.html:text/html}
}

@article{goodwin_representation_1995,
	title = {Representation of curved surfaces in responses of mechanoreceptive afferent fibers innervating the monkey's fingerpad},
	volume = {15},
	rights = {© 1995 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/15/1/798},
	doi = {10.1523/JNEUROSCI.15-01-00798.1995},
	abstract = {The aim was to elucidate how the population of digital nerve afferents signals information about the shape of objects in contact with the fingerpads during fine manipulations. Responses were recorded from single mechanoreceptive afferent fibers in median nerves of anesthetized monkeys. Seven spherical surfaces were used, varying from a highly curved surface (radius, 1.44 mm; curvature, 694 m-1) to a flat surface (radius, infinity; curvature, 0 m-1). These were applied to the fibers' receptive fields, which were located on the central portion of a fingerpad. When the objects were located at the centers of the receptive fields, the responses of the slowly adapting fibers ({SAIs}) increased as the curvature of the surface increased and as the contact force increased. All {SAIs} behaved in the same way, differing only by a scaling factor (the sensitivity of the individual afferent). Responses of the rapidly adapting afferents were small and did not vary systematically with the stimulus parameters, and most Pacinians did not respond at all. Stimuli were applied at different positions in the receptive fields of {SAIs} to define the response profiles of the afferents (response as a function of position on the fingerpad). All {SAIs} had similarly shaped profiles for the same surface curvature and the shape differed for different curvatures. These profiles reflected the shape of the stimulus. An increase in contact force scaled these profiles upward. Thus, the population of digital nerve fibers signals unambiguous information about the shape and contact force of curved surfaces contacting the fingerpad.},
	pages = {798--810},
	number = {1},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Goodwin, A. W. and Browning, A. S. and Wheat, H. E.},
	urldate = {2019-01-16},
	date = {1995-01-01},
	langid = {english},
	pmid = {7823181},
	file = {Full Text PDF:/home/felix/Zotero/storage/8CURPPQ2/Goodwin et al. - 1995 - Representation of curved surfaces in responses of .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/PYZJNKGJ/798.html:text/html}
}

@article{goodwin_encoding_1997,
	title = {Encoding of Object Curvature by Tactile Afferents From Human Fingers},
	volume = {78},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.1997.78.6.2881},
	doi = {10.1152/jn.1997.78.6.2881},
	abstract = {Goodwin, A. W., V. G. Macefield, and J. W. Bisley. Encoding of object curvature by tactile afferents from human fingers. J. Neurophysiol. 78: 2881–2888, 1997. Isolated responses were recorded from fibers in the median nerves of human subjects by using microneurography. Mechanoreceptive afferent fibers with receptive fields on the fingerpads were selected. The fingers were immobilized and spherical stimuli were applied passively to the receptive field with a contact force of 40-, 60-, or 80-g weight. The radii of the spheres were 1.92, 2.94, 5.81, or 12.4 mm or ∞ (flat); the corresponding curvatures, given by the reciprocal of the radii, were 694, 340, 172, 80.6, or 0 m−1, respectively. When the spheres were applied to the receptive field center of slowly adapting type I afferents ({SAIs}), the response increased as the curvature of the sphere increased and also increased as the contact force increased. All {SAIs} behaved in the same way except for a scaling factor proportional to the sensitivity of the afferent. When a sphere was located at different positions in the receptive field, the shape of the resulting response profile reflected the shape of the sphere; for more curved spheres the profile was higher and narrower (increased peak and decreased width). Slowly adapting type {II} afferents ({SAIIs}) showed different response characteristics from the {SAIs} when spheres were applied to their receptive field centers. As the curvature of the stimulus increased from 80.6 to 172 m−1, the response increased. However, further increases in curvature did not result in further increases in response. An increase in contact force resulted in an increase in the response of {SAIIs}; this increase was proportionately greater than it was for {SAIs}. For {SAIIs}, the shape of the receptive field profile did not change when the curvature of the stimulus changed. For fast-adapting type I afferents ({FAIs}), the responses were small and did not change systematically with changes in curvature or contact force. Fast-adapting type {II} afferents ({FAIIs}) did not respond to our stimuli. Human {SAIs}, {FAIs}, and {FAIIs} behaved like monkey {SAIs}, {FAIs}, and {FAIIs}, respectively. The response of the {SAI} population contains accurate information about the shape of the sphere and its position of contact on the finger and also indicates contact force. Conversely, whereas {SAIIs} possess a greater capacity to encode changes in contact force, they provide only coarse information on local shape.},
	pages = {2881--2888},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Goodwin, A. W. and Macefield, V. G. and Bisley, J. W.},
	urldate = {2019-01-16},
	date = {1997-12-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/7UVN3WPF/Goodwin et al. - 1997 - Encoding of Object Curvature by Tactile Afferents .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/I4B4MVGW/jn.1997.78.6.html:text/html}
}

@article{yoshioka_neural_2001,
	title = {Neural Coding Mechanisms Underlying Perceived Roughness of Finely Textured Surfaces},
	volume = {21},
	rights = {Copyright © 2001 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/21/17/6905},
	doi = {10.1523/JNEUROSCI.21-17-06905.2001},
	abstract = {Combined psychophysical and neurophysiological studies have shown that the perceived roughness of surfaces with element spacings of {\textgreater}1 mm is based on spatial variation in the firing rates of slowly adapting type 1 ({SA}1) afferents (mean absolute difference in firing rates between {SA}1 afferents with receptive fields separated by ∼2 mm). The question addressed here is whether this mechanism accounts for the perceived roughness of surfaces with element spacings of {\textless}1 mm. Twenty triangular and trapezoidal gratings plus a smooth surface were used as stimulus patterns [spatial periods, 0.1–2.0 mm; groove widths ({GWs}), 0.1–2.0 mm; and ridge widths ({RWs}), 0–1.0 mm]. In the human psychophysical studies, we found that the following equation described the mean roughness magnitude estimates of the subjects accurately (0.99 correlation): 0.2 + 1.6GW − 0.5RW − 0.25GW2. In the neurophysiological studies, these surfaces were scanned across the receptive fields of {SA}1, rapidly adapting, and Pacinian ({PC}) afferents, innervating the glabrous skin of anesthetized macaque monkeys. {SA}1 spatial variation was highly correlated (0.97) with human roughness judgments. There was no consistent relationship between {PC} responses and roughness judgments; {PC} afferents responded strongly and almost equally to all of the patterns. Spatial variation in {SA}1 firing rates is the only neural code that accounts for the perceived roughness of surfaces with finely and coarsely spaced elements. When surface elements are widely spaced, the spatial variation in firing rates is determined primarily by the surface pattern; when the elements are finely spaced, the variation in firing rates between {SA}1 afferents is determined by stochastic variation in spike rates.},
	pages = {6905--6916},
	number = {17},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Yoshioka, Takashi and Gibb, Barbara and Dorsch, Andrew K. and Hsiao, Steven S. and Johnson, Kenneth O.},
	urldate = {2019-01-16},
	date = {2001-09-01},
	langid = {english},
	pmid = {11517278},
	keywords = {somatosensory, tactile, fine texture, grating, macaque, mechanoreceptor, {PC}, peripheral nerve, psychophysical roughness magnitude, {RA}, roughness, {SA}1},
	file = {Full Text PDF:/home/felix/Zotero/storage/GLWY5HIF/Yoshioka et al. - 2001 - Neural Coding Mechanisms Underlying Perceived Roug.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/5V87ZW6L/6905.html:text/html}
}

@article{mountcastle_detection_1972,
	title = {Detection thresholds for stimuli in humans and monkeys: comparison with threshold events in mechanoreceptive afferent nerve fibers innervating the monkey hand.},
	volume = {35},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1972.35.1.122},
	doi = {10.1152/jn.1972.35.1.122},
	shorttitle = {Detection thresholds for stimuli in humans and monkeys},
	pages = {122--136},
	number = {1},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Mountcastle, V B and {LaMotte}, R H and Carli, G},
	urldate = {2019-01-16},
	date = {1972-01-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/G6DPB7MC/Mountcastle et al. - 1972 - Detection thresholds for stimuli in humans and mon.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/KKTQMV23/jn.1972.35.1.html:text/html}
}

@article{lamotte_capacities_1975,
	title = {Capacities of humans and monkeys to discriminate vibratory stimuli of different frequency and amplitude: a correlation between neural events and psychological measurements},
	volume = {38},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1975.38.3.539},
	doi = {10.1152/jn.1975.38.3.539},
	shorttitle = {Capacities of humans and monkeys to discriminate vibratory stimuli of different frequency and amplitude},
	abstract = {The capacities of monkeys and humans to discriminate between mechanical sinusoids differing in amplitude or frequency were measured in a two-alternative, forced-choice task. The difference limen for amplitude discrimination for both species remained constant near 10\% of the standard amplitude over the range of 17-30 {dB}, relative to detection threshold. Equal subjective intensity curves in the 20-40 Hz range were determined at 20 and 29 {dB}, relative to detection threshold. These curves followed the threshold curve and were identical for the two species. The difference limen for frequency discrimination averaged 1.8 Hz for humans and 2.7 Hz for monkeys; the range of values for the two species overlapped nearly completely. The small sizes of these difference limens indicate, we believe, the capacity of highly trained individuals of either species to ascertain small differences in the temporal order of somesthetic stimuli and of the neural events evoked by them. In one series of experiments we demonstrated that subjects of both species possess two threshold for two different aspects of flutter-vibration which are displaced from each other along the intensive continuum. For either species, the minimum level of stimulus amplitude required for threshold frequency discrimination is about 8 {dB} above that sufficient for detection. This difference in amplitude is called the atonal interval and matches that observed between absolute and tuning thresholds for quickly adapting, mechanoreceptor afferents (the Meissner afferents) which innervate the glabrous skin of the monkey hand. These and previous findings have permitted a number of direct correlations between behavioral and neural events as regards the sense of flutter. The neural codes for the intensity and frequency of flutter appear to be different. The capacity to detect the presence of a mechanical sinusoid and the capacity to judge its subjective intensity are likely to depend on criterion levels of activity in the total population of Meissner afferents, the former on the appearance of any activity (absolute threshold) in a small population of the most sensitive of these fibers and the latter on the overall size of the active population of neuronal elements at each level of amplitude. The total activity in the relevant neural population elicited by sinusoids of increasing amplitude defines a prothetic continuum along which subjects can judge the magnitude of sensation..},
	pages = {539--559},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {{LaMotte}, R. H. and Mountcastle, V. B.},
	urldate = {2019-01-16},
	date = {1975-05-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/ESHVWRYP/LaMotte and Mountcastle - 1975 - Capacities of humans and monkeys to discriminate v.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/6SRLU83U/jn.1975.38.3.html:text/html}
}

@article{talbot_sense_1968,
	title = {The sense of flutter-vibration: comparison of the human capacity with response patterns of mechanoreceptive afferents from the monkey hand.},
	volume = {31},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1968.31.2.301},
	doi = {10.1152/jn.1968.31.2.301},
	shorttitle = {The sense of flutter-vibration},
	pages = {301--334},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Talbot, W H and Darian-Smith, I and Kornhuber, H H and Mountcastle, V B},
	urldate = {2019-01-16},
	date = {1968-03-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/5NJJTNU4/Talbot et al. - 1968 - The sense of flutter-vibration comparison of the .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/ICFG32SB/jn.1968.31.2.html:text/html}
}

@article{johansson_signals_1987,
	title = {Signals in tactile afferents from the fingers eliciting adaptive motor responses during precision grip},
	volume = {66},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/BF00236210},
	doi = {10.1007/BF00236210},
	abstract = {{SummaryWhile} human subjects lift small objects using the precision grip between the tips of the fingers and thumb the ratio between the grip force and the load force (i.e. the vertical lifting force) is adapted to the friction between the object and the skin. The present report provides direct evidence that signals in tactile afferent units are utilized in this adaptation. Tactile afferent units were readily excited by small but distinct slips between the object and the skin revealed as vibrations in the object. Following such afferent slip responses the force ratio was upgraded to a higher, stable value which provided a safety margin to prevent further slips. The latency between the onset of the a slip and the appearance of the ratio change (74 ±9 ms) was about half the minimum latency for intended grip force changes triggered by cutaneous stimulation of the fingers. This indicated that the motor responses were automatically initiated. If the subjects were asked to very slowly separate their thumb and the opposing finger while the object was held in air, grip force reflexes originating from afferent slip responses appeared to counteract the voluntary command, but the maintained upgrading of the force ratio was suppressed. In experiments with weak electrical cutaneous stimulation delivered through the surfaces of the object it was established that tactile input alone could trigger the upgrading of the force ratio. Although, varying in responsiveness, each of the three types of tactile units which exhibit a pronounced dynamic sensitivity ({FA} I, {FA} {II} and {SA} I units) could reliably signal these slips. Similar but generally weaker afferent responses, sometimes followed by small force ratio changes, also occurred in the {FA} I and the {SA} I units in the absence of detectable vibrations events. In contrast to the responses associated with clear vibratory events, the weaker afferent responses were probably caused by localized frictional slips, i.e. slips limited to small fractions of the skin area in contact with the object. Indications were found that the early adjustment to a new frictional condition, which may appear soon (ca. 0.1–0.2 s) after the object is initially gripped, might depend on the vigorous responses in the {FA} I units during the initial phase of the lifts (see Westling and Johansson 1987). The role of the tactile input in the adaptation of the force coordination to the frictional condition is discussed.},
	pages = {141--154},
	number = {1},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Johansson, R. S. and Westling, G.},
	urldate = {2019-01-16},
	date = {1987-03-01},
	langid = {english},
	keywords = {Cutaneous mechanoreceptors, Exteroceptive reflexes, Human hand, Motor control, Precision grip, Sensori-motor memory},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/ZU76NCU2/Johansson and Westling - 1987 - Signals in tactile afferents from the fingers elic.pdf:application/pdf}
}

@article{macefield_control_1996,
	title = {Control of grip force during restraint of an object held between finger and thumb: responses of cutaneous afferents from the digits},
	volume = {108},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/BF00242913},
	doi = {10.1007/BF00242913},
	shorttitle = {Control of grip force during restraint of an object held between finger and thumb},
	abstract = {Unexpected pulling and pushing loads exerted by an object held with a precision grip evoke automatic and graded increases in the grip force (normal to the grip surfaces) that prevent escape of the object; unloading elicits a decrease in grip force. Anesthesia of the digital nerves has shown that these grip reactions depend on sensory signals from the digits. In the present study we assessed the capacity of tactile afferents from the digits to trigger and scale the evoked grip responses. Using tungsten microelectrodes inserted percutaneously into the median nerve of awake human subjects, unitary recordings were made from ten {FA} I and 13 {FA} {II} rapidly adapting afferents, and 12 {SA} I and 18 {SA} {II} slowly adapting afferents. While the subject held a manipulandum between a finger and the thumb, tangential load forces were applied to the receptor-bearing digit (index, middle, or ring finger or thumb) as trapezoidal load-force profiles with a plateau amplitude of 0.5 – 2.0 N and rates of loading and unloading at 2 – 8 N/s, or as “step-loads” of 0.5 N delivered at 32 N/s. Such load trials were delivered in both the distal (pulling) and proximal (pushing) direction. {FA} I afferents responded consistently to the load forces, being recruited during the loading and unloading phases. During the loading ramp the ensemble discharge of the {FA} I afferents reflected the first time-derivative of the load force (i.e., the load-force rate). These afferents were relatively insensitive to the subject's grip force responses. However, high static finger forces appeared to suppress excitation of these afferents during the unloading phase. The {FA} {II} afferents were largely insensitive to the load trials: only with the step-loads did some afferents respond. Both classes of {SA} afferents were sensitive to load force and grip force, and discharge rates were graded by the rate of loading. The firing of the {SA} I afferents appeared to be relatively more influenced by the subject's grip-force response than the discharge of the {SA} {II} afferents, which were more influenced by the load-force stimulus. The direction in which the tangential load force was applied to the skin influenced the firing of most afferents and in particular the {SA} {II} afferents. Individual afferents within each class (except for the {FA} {IIs}) responded to the loading ramp before the onset of the subject's grip response and may thus be responsible for initiating the automatic increase in grip force. However, nearly half of the {FA} I afferents recruited by the load trials responded to the loading phase early enough to trigger the subject's gripforce response, whereas only ca. one-fifth of the {SA} Is and {SA} {IIs} did so. These observations, together with the high density of {FA} I receptors in the digits, might place the {FA} I afferents in a unique position to convey the information required to initiate and scale the reactive gripforce responses to the imposed load forces.},
	pages = {155--171},
	number = {1},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Macefield, Vaughan G. and Häger-Ross, Charlotte and Johansson, Roland S.},
	urldate = {2019-01-16},
	date = {1996-02-01},
	langid = {english},
	keywords = {Precision grip, Cutaneous afferents, Hand, Human, Sensorimotor integration},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/MSPKYEQ4/Macefield et al. - 1996 - Control of grip force during restraint of an objec.pdf:application/pdf}
}

@article{srinivasan_tactile_1990,
	title = {Tactile detection of slip: surface microgeometry and peripheral neural codes},
	volume = {63},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1990.63.6.1323},
	doi = {10.1152/jn.1990.63.6.1323},
	shorttitle = {Tactile detection of slip},
	abstract = {1. The role of the microgeometry of planar surfaces in the detection of sliding of the surfaces on human and monkey fingerpads was investigated. By the use of a servo-controlled tactile stimulator to press and stroke glass plates on passive fingerpads of human subjects, the ability of humans to discriminate the direction of skin stretch caused by friction and to detect the sliding motion (slip) of the plates with or without micrometer-sized surface features was determined. To identify the associated peripheral neural codes, evoked responses to the same stimuli were recorded from single, low-threshold mechanoreceptive afferent fibers innervating the fingerpads of anesthetized macaque monkeys. 2. Humans could not detect the slip of a smooth glass plate on the fingerpad. However, the direction of skin stretch was perceived based on the information conveyed by the slowly adapting afferents that respond differentially to the stretch directions. Whereas the direction of skin stretch signaled the direction of impending slip, the perception of relative motion between the plate and the finger required the existence of detectable surface features. 3. Barely detectable micrometer-sized protrusions on smooth surfaces led to the detection of slip of these surfaces, because of the exclusive activation of rapidly adapting fibers of either the Meissner ({RA}) or the Pacinian ({PC}) type to specific geometries of the microfeatures. The motion of a smooth plate with a very small single raised dot (4 microns high, 550 microns diam) caused the sequential activation of neighboring {RAs} along the dot path, thus providing a reliable spatiotemporal code. The stroking of the plate with a fine homogeneous texture composed of a matrix of dots (1 microns high, 50 microns diam, and spaced at 100 microns center-to-center) induced vibrations in the fingerpad that activated only the {PCs} and resulted in an intensive code. 4. The results show that surprisingly small features on smooth surfaces are detected by humans and lead to the detection of slip of these surfaces, with the geometry of the microfeatures governing the associated neural codes. When the surface features are of sizes greater than the response thresholds of all the receptors, redundant spatiotemporal and intensive information is available for the detection of slip.},
	pages = {1323--1332},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Srinivasan, M. A. and Whitehouse, J. M. and {LaMotte}, R. H.},
	urldate = {2019-01-16},
	date = {1990-06-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/SSUBFAUC/Srinivasan et al. - 1990 - Tactile detection of slip surface microgeometry a.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/PRT4XAM8/jn.1990.63.6.html:text/html}
}

@article{gray_john_archibald_browne_initiation_1950,
	title = {The initiation of nerve impulses by mesenteric Pacinian corpuscles},
	volume = {137},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rspb.1950.0026},
	doi = {10.1098/rspb.1950.0026},
	abstract = {A preparation of a single Pacinian corpuscle in the cat’s mesentery has been used to study the initiation of nerve impulses in sensory endings. The minimum movement of a mechanical stimulator required to excite a single corpuscle has been found to be 0⋅5μ in 100 μsec. It has been difficult to produce repetitive discharges with rectangular pulses of long duration, either mechanical or of constant current. The latency between a mechanical stimulus and the initiation of an impulse has a value around 1⋅5 msec, for threshold stimuli, and this decreases to a minimum value around 0⋅5 msec, as the stimulus is increased; it is altered only slightly, if at all, by changes in the duration of the maintained displacement of the mechanical stimulator. Subthreshold mechanical stimuli have been shown to facilitate stimulation by electrical test shocks. The return of excitability at the ending is independent of the nature of the conditioning stimulus and varies but little with the nature of the test shock. The value of the latency at threshold is unaffected by the relatively refractory state. The relations of these results to various hypotheses are discussed, and it is suggested that these results can all be accounted for in terms of the known properties of axons.},
	pages = {96--114},
	number = {886},
	journaltitle = {Proceedings of the Royal Society of London. Series B - Biological Sciences},
	shortjournal = {Proceedings of the Royal Society of London. Series B - Biological Sciences},
	author = {{Gray John Archibald Browne} and {Malcolm J. L} and {Brown George Lindor}},
	urldate = {2019-01-16},
	date = {1950-04-13},
	file = {Full Text PDF:/home/felix/Zotero/storage/YEQPCW3P/Gray John Archibald Browne et al. - 1950 - The initiation of nerve impulses by mesenteric Pac.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/3K7NXZ4M/rspb.1950.html:text/html}
}

@online{noauthor_response_nodate,
	title = {Response of Pacinian corpuscles to sinusoidal vibration - Sato - 1961 - The Journal of Physiology - Wiley Online Library},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1961.sp006817},
	urldate = {2019-01-16},
	file = {Response of Pacinian corpuscles to sinusoidal vibration - Sato - 1961 - The Journal of Physiology - Wiley Online Library:/home/felix/Zotero/storage/6ST556NV/jphysiol.1961.html:text/html}
}

@article{sato_response_1961,
	title = {Response of Pacinian corpuscles to sinusoidal vibration},
	volume = {159},
	rights = {© 1961 The Physiological Society},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1961.sp006817},
	doi = {10.1113/jphysiol.1961.sp006817},
	pages = {391--409},
	number = {3},
	journaltitle = {The Journal of Physiology},
	author = {Sato, M.},
	urldate = {2019-01-16},
	date = {1961},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/H97FXY8A/Sato - 1961 - Response of Pacinian corpuscles to sinusoidal vibr.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/93V3UYHS/jphysiol.1961.html:text/html}
}

@article{brisben_detection_1999,
	title = {Detection of Vibration Transmitted Through an Object  Grasped in the Hand},
	volume = {81},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.1999.81.4.1548},
	doi = {10.1152/jn.1999.81.4.1548},
	abstract = {Detection of vibration transmitted through an object grasped in the hand.  A tool or probe often functions as an extension of the hand, transmitting vibrations to the hand to produce a percept of the object contacting the tool or probe. This paper reports the psychophysical results of a combined psychophysical and neurophysiological study of the perception of vibration transmitted through a cylinder grasped in the hand. In the first part of the psychophysical study, 19 subjects grasped a cylinder, 32 mm diam, with an embedded motor that caused vibration parallel to the axis of the cylinder. The relationship between threshold and frequency was the traditional U-shaped function with a minimum between 150 and 200 Hz. Except a study by Békésy in which subjects grasped a rod that vibrated parallel to the skin surface, thresholds above 20 Hz were lower and the slopes were steeper than any reported previously. Thresholds were {\textless}0.01 μm in some subjects. Data from both the psychophysical and the neurophysiological studies suggest that detection performance at frequencies {\textgreater}20 Hz was based on activity in Pacinian afferents. The extreme sensitivity compared with previous reports may have resulted from differences in contact area, direction of vibration, contact force, and the shape of the stimulus probe. The effects of each of these variables were studied. At 40 and 300 Hz (frequencies near the lower and upper end of the Pacinian range) thresholds were 9.8 and 18.5 {dB} (68 and 88\%) lower, respectively, when subjects grasped the cylinder than when a 1-mm-diam probe vibrated perpendicular to the skin. These differences were accounted for as follows: 1) thresholds at a single fingerpad obtained with the large cylindrical surface were, on average, 20 and 60\% lower, respectively, than thresholds with the punctate probe; 2) thresholds at the palm were, on average, 15 and 40\% lower, respectively, than at the fingerpads; 3) thresholds obtained when the subjects grasped the cylinder averaged 40 and 20\% less, respectively, than when the cylinder contacted only the palm;4) thresholds with the cylinder contacting two fingers were 10 and 30\% lower, respectively, than thresholds with the cylinder contacting a single finger; and 5) thresholds with vibration parallel to the skin surface were, on average, 10 and 30\% lower, respectively, than thresholds with vibration perpendicular to the skin. Contact force, which was varied from 0.05 to 1.0 N, had no effect.},
	pages = {1548--1558},
	number = {4},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Brisben, A. J. and Hsiao, S. S. and Johnson, K. O.},
	urldate = {2019-01-17},
	date = {1999-04-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/LRKGSZUP/Brisben et al. - 1999 - Detection of Vibration Transmitted Through an Obje.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/TVECM8WR/jn.1999.81.4.html:text/html}
}

@article{hunt_nature_1961,
	title = {On the nature of vibration receptors in the hind limb of the cat},
	volume = {155},
	rights = {© 1961 The Physiological Society},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1961.sp006621},
	doi = {10.1113/jphysiol.1961.sp006621},
	pages = {175--186},
	number = {1},
	journaltitle = {The Journal of Physiology},
	author = {Hunt, C. C.},
	urldate = {2019-01-17},
	date = {1961},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/QFHU9GTM/Hunt - 1961 - On the nature of vibration receptors in the hind l.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/IYR2FTQH/jphysiol.1961.html:text/html}
}

@article{lindblom_discharge_1966,
	title = {The discharge from vibration-sensitive receptors in the monkey foot},
	volume = {15},
	issn = {0014-4886},
	url = {http://www.sciencedirect.com/science/article/pii/0014488666901385},
	doi = {10.1016/0014-4886(66)90138-5},
	abstract = {The discharge in forty primary afferent fibers innervating vibration-sensitive receptors in the monkey foot was analyzed. The receptive fields were large with diffuse borders. The receptors were located in subcutaneous and deeper tissue layers. The threshold for external mechanical stimuli was very low both for single and repetitive discharge, especially in glabrous skin and other regions offering low impedance pathways for the transmission of the mechanical stimulus to the receptor site. In terms of short-duration displacement of the glabrous skin in the plantar metacarpal region, the threshold for single afferent impulses varied from less than 5 up to 30 μ. The lowest effective displacement rate, or critical slope, was from 1.8 to 36 mm/sec in the same skin area. With sinusoidal movements, the lower and upper frequency limits of discharge and the threshold amplitude for 1 impulse/cycle at various frequencies were determined. There was a threshold minimum between 50 and 200 cycle/sec. With suprathreshold sinusoidal stimulation of constant amplitude, changes in the ratio of stimulus to response frequency were observed throughout the frequency continuum. The general characteristics of the discharge indicated that the receptors were Pacinian corpuscles. The possible implications of the results for tactile and vibratory sensation are discussed.},
	pages = {401--417},
	number = {4},
	journaltitle = {Experimental Neurology},
	shortjournal = {Experimental Neurology},
	author = {Lindblom, U. and Lund, L.},
	urldate = {2019-01-17},
	date = {1966-08-01},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/I6STCSLF/0014488666901385.html:text/html}
}

@article{edin_quantitative_1992,
	title = {Quantitative analysis of static strain sensitivity in human mechanoreceptors from hairy skin},
	volume = {67},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1992.67.5.1105},
	doi = {10.1152/jn.1992.67.5.1105},
	abstract = {1. Microelectrode recordings from 15 slowly adapting ({SA}) cutaneous mechanoreceptor afferents originating in hairy skin were obtained from the radial nerve in humans. 2. Controlled skin stretch was applied to the back of the hand that encompassed the physiological range of skin stretch during movements at the metacarpophalangeal ({MCP}) joints. 3. Both {SA} Group I and {II} afferents showed exquisite dynamic and static sensitivity to skin stretch. The median static strain sensitivity was 1.0 imp.s-1 per percent skin stretch for {SAI} units and 1.8 for {SAII} units. 4. Translated into sensitivity to movements at the {MCP} joint, both {SAI} and {SAII} afferents in the skin of the back of the hand displayed a positional sensitivity that was comparable with that reported for muscle spindle afferents. 5. These data give quantitative support to suggestions that skin receptors in the human hairy skin provide information on nearby joint configurations and therefore may play a specific role in proprioception, kinesthesia, and motor control.},
	pages = {1105--1113},
	number = {5},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Edin, B. B.},
	urldate = {2019-01-17},
	date = {1992-05-01},
	file = {Snapshot:/home/felix/Zotero/storage/FGW9V5BF/jn.1992.67.5.html:text/html}
}

@article{olausson_tactile_2000,
	title = {Tactile directional sensibility: peripheral neural mechanisms in man},
	volume = {866},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/S0006899300022782},
	doi = {10.1016/S0006-8993(00)02278-2},
	shorttitle = {Tactile directional sensibility},
	abstract = {Tactile directional sensibility, i.e. the ability to tell the direction of an object’s motion across the skin, is an easily observed sensory function that is highly sensitive to disturbances of the somatosensory system. Based on previous psychophysical experiments on healthy subjects it was concluded that directional sensibility depends on two kinds of information from cutaneous mechanoreceptors; spatio-temporal information and information about friction-induced changes in skin stretch. In the present study responses to similar probe movements as in the psychophysical experiments were recorded from human single mechanoreceptors in the forearm skin. All slowly adapting type 2 ({SA}2) units were spontaneously active, and with increasing force of friction their discharge rates were modified by probe movements at increasing distances from the Ruffini end-organ, reflecting the high stretch-sensitivity of these units. Slowly adapting type 1 ({SA}1) and field units responded to the moving probe within well-defined skin areas directly overlying the individual receptor terminals, and compared to the {SA}2 units their response properties were less dependent on the force of friction. The results suggest that {SA}1 and field units have the capacity to signal spatio-temporal information, whereas a population of {SA}2 units have the capacity to signal direction-specific information about changes in lateral skin stretch.},
	pages = {178--187},
	number = {1},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Olausson, Håkan and Wessberg, Johan and Kakuda, Naoyuki},
	urldate = {2019-01-17},
	date = {2000-06-02},
	keywords = {Human, Mechanoreceptor, Microneurography, Skin},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/S4W2C9TC/S0006899300022782.html:text/html}
}

@article{edin_quantitative_1992-1,
	title = {Quantitative analysis of static strain sensitivity in human mechanoreceptors from hairy skin},
	volume = {67},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1992.67.5.1105},
	doi = {10.1152/jn.1992.67.5.1105},
	abstract = {1. Microelectrode recordings from 15 slowly adapting ({SA}) cutaneous mechanoreceptor afferents originating in hairy skin were obtained from the radial nerve in humans. 2. Controlled skin stretch was applied to the back of the hand that encompassed the physiological range of skin stretch during movements at the metacarpophalangeal ({MCP}) joints. 3. Both {SA} Group I and {II} afferents showed exquisite dynamic and static sensitivity to skin stretch. The median static strain sensitivity was 1.0 imp.s-1 per percent skin stretch for {SAI} units and 1.8 for {SAII} units. 4. Translated into sensitivity to movements at the {MCP} joint, both {SAI} and {SAII} afferents in the skin of the back of the hand displayed a positional sensitivity that was comparable with that reported for muscle spindle afferents. 5. These data give quantitative support to suggestions that skin receptors in the human hairy skin provide information on nearby joint configurations and therefore may play a specific role in proprioception, kinesthesia, and motor control.},
	pages = {1105--1113},
	number = {5},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Edin, B. B.},
	urldate = {2019-01-17},
	date = {1992-05-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/75LEIN9Q/Edin - 1992 - Quantitative analysis of static strain sensitivity.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/M9SRAXK7/jn.1992.67.5.html:text/html}
}

@article{johansson_tactile_1979,
	title = {Tactile sensibility in the human hand: relative and absolute densities of four types of mechanoreceptive units in glabrous skin.},
	volume = {286},
	rights = {© 1979 The Physiological Society},
	issn = {1469-7793},
	url = {https://physoc.onlinelibrary.wiley.com/doi/abs/10.1113/jphysiol.1979.sp012619},
	doi = {10.1113/jphysiol.1979.sp012619},
	shorttitle = {Tactile sensibility in the human hand},
	abstract = {1. Single unit impulses were recorded with percutaneously inserted tungsten needle electrodes from the median nerve in conscious human subjects. 2. A sample of 334 low threshold mechanoreceptive units innervating the glabrous skin area of the hand were studied. In accordance with earlier investigations, the units were separated into four groups on the basis of their adaptation and receptive field properties: {RA}, {PC}, {SA} I and {SA} {II} units. 3. The locations of the receptive fields of individual units were determined and the relative unit densities within various skin regions were calculated. The over-all density was found to increase in the proximo-distal direction. There was a slight increase from the palm to the main part of the finger and an abrupt increase from the main part of the finger to the finger tip. The relative densities in these three regions were 1, 1.6, 4.2. 4. The differences in over-all density were essentially accounted for by the two types of units characterized by small and well defined receptive fields, the {RA} and {SA} I units, whereas the {PC} and {SA} {II} units were almost evenly distributed over the whole glabrous skin area. 5. The spatial distribution of densities supports the idea that the {RA} and {SA} I units account for spatial acuity in psychophysical tests. This capacity is known to increase in distal direction along the hand. 6. On the basis of histological data regarding the number of myelinated fibres in the median nerve, a model of the absolute unit density was proposed. It was estimated that the density of low threshold mechanoreceptive units at the finger tip is as high as 241 u./cm2, whereas in the palm it is only 58 u./cm2.},
	pages = {283--300},
	number = {1},
	journaltitle = {The Journal of Physiology},
	author = {Johansson, R. S. and Vallbo, A. B.},
	urldate = {2019-01-20},
	date = {1979},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/N62V25XN/Johansson and Vallbo - 1979 - Tactile sensibility in the human hand relative an.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/6GDN7XB5/jphysiol.1979.html:text/html}
}

@online{noauthor_thresholds_nodate,
	title = {Thresholds of mechanosensitive afferents in the human hand as measured with von Frey hairs - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/0006899380908033},
	urldate = {2019-01-20},
	file = {Thresholds of mechanosensitive afferents in the human hand as measured with von Frey hairs - ScienceDirect:/home/felix/Zotero/storage/UPANXITM/0006899380908033.html:text/html}
}

@article{johansson_thresholds_1980,
	title = {Thresholds of mechanosensitive afferents in the human hand as measured with von Frey hairs},
	volume = {184},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/0006899380908033},
	doi = {10.1016/0006-8993(80)90803-3},
	abstract = {Afferent activity in low threshold mechanoreceptive units innervating the glabrous skin area of the hand was recorded from the median nerve of human subjects, using tungsten needle electrodes. The units were classified as {RA}, {PC}, {SA} I and {SA} {II} units mainly on the basis of their adaptation and receptive field properties Thresholds of the units were determined by two methods, the force threshold was determined with von Frey hairs and the indentation threshold with triangular indentations of controlled amplitudes. The characteristics of the force developed by the von Frey hairs as a function of movement parameters was analyzed when the hairs were prodded against a force transducer. The rise time was 10–20 msec and the variability of the peak force was within-20\% of the steady-state force during repetitive prodding with various repetition rates. The von Frey thresholds were determined for 284 units and the indentation threshold for 116 of them. The {RA} and {PC} units were the most sensitive unit types with median thresholds of 0.58 {mN} and 0.54 {mN}. The medians of the slowly adapting {SA} I and {SA} {II} units, were 1.3 {mN} and 7.5 {mN}. The threshold distributions for all unit types were positively skewed. No regional differences were found but the thresholds were identical in skin areas where the psychophysical thresholds have been shown to be diverse. The relation between force threshold and indentation threshold was analyzed for 116 units. There was a positive correlation between the two thresholds, although the relation appeared not to be identical for the four types of units and the scatter was considerable.},
	pages = {343--351},
	number = {2},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Johansson, R. S. and Vallbo, Å. B. and Westling, G.},
	urldate = {2019-01-20},
	date = {1980-02-24},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/Z5ZCR24E/0006899380908033.html:text/html;Submitted Version:/home/felix/Zotero/storage/CGWCANQL/Johansson et al. - 1980 - Thresholds of mechanosensitive afferents in the hu.pdf:application/pdf}
}

@article{olausson_tactile_2000-1,
	title = {Tactile directional sensibility: peripheral neural mechanisms in man},
	volume = {866},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/S0006899300022782},
	doi = {10.1016/S0006-8993(00)02278-2},
	shorttitle = {Tactile directional sensibility},
	abstract = {Tactile directional sensibility, i.e. the ability to tell the direction of an object’s motion across the skin, is an easily observed sensory function that is highly sensitive to disturbances of the somatosensory system. Based on previous psychophysical experiments on healthy subjects it was concluded that directional sensibility depends on two kinds of information from cutaneous mechanoreceptors; spatio-temporal information and information about friction-induced changes in skin stretch. In the present study responses to similar probe movements as in the psychophysical experiments were recorded from human single mechanoreceptors in the forearm skin. All slowly adapting type 2 ({SA}2) units were spontaneously active, and with increasing force of friction their discharge rates were modified by probe movements at increasing distances from the Ruffini end-organ, reflecting the high stretch-sensitivity of these units. Slowly adapting type 1 ({SA}1) and field units responded to the moving probe within well-defined skin areas directly overlying the individual receptor terminals, and compared to the {SA}2 units their response properties were less dependent on the force of friction. The results suggest that {SA}1 and field units have the capacity to signal spatio-temporal information, whereas a population of {SA}2 units have the capacity to signal direction-specific information about changes in lateral skin stretch.},
	pages = {178--187},
	number = {1},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Olausson, Håkan and Wessberg, Johan and Kakuda, Naoyuki},
	urldate = {2019-01-20},
	date = {2000-06-02},
	keywords = {Human, Mechanoreceptor, Microneurography, Skin},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/76DREAAB/Olausson et al. - 2000 - Tactile directional sensibility peripheral neural.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/7FS2MIUA/S0006899300022782.html:text/html}
}

@article{mountcastle_cortical_1969,
	title = {Cortical neuronal mechanisms in flutter-vibration studied in unanesthetized monkeys. Neuronal periodicity and frequency discrimination.},
	volume = {32},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1969.32.3.452},
	doi = {10.1152/jn.1969.32.3.452},
	pages = {452--484},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Mountcastle, V B and Talbot, W H and Sakata, H and Hyvärinen, J},
	urldate = {2019-01-20},
	date = {1969-05-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/9D6R9XA3/Mountcastle et al. - 1969 - Cortical neuronal mechanisms in flutter-vibration .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/44KMZSXB/jn.1969.32.3.html:text/html}
}

@article{mountcastle_cortical_1969-1,
	title = {Cortical neuronal mechanisms in flutter-vibration studied in unanesthetized monkeys. Neuronal periodicity and frequency discrimination.},
	volume = {32},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1969.32.3.452},
	doi = {10.1152/jn.1969.32.3.452},
	pages = {452--484},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Mountcastle, V B and Talbot, W H and Sakata, H and Hyvärinen, J},
	urldate = {2019-01-21},
	date = {1969-05-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/7VFX34N6/Mountcastle et al. - 1969 - Cortical neuronal mechanisms in flutter-vibration .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/FM9HXPAX/jn.1969.32.3.html:text/html}
}

@article{mountcastle_frequency_1990-1,
	title = {Frequency discrimination in the sense of flutter: psychophysical measurements correlated with postcentral events in behaving monkeys},
	volume = {10},
	rights = {© 1990 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/10/9/3032},
	doi = {10.1523/JNEUROSCI.10-09-03032.1990},
	shorttitle = {Frequency discrimination in the sense of flutter},
	abstract = {The capacities of humans and monkeys to discriminate between the frequencies of mechanical sinusoids delivered to the glabrous skin of the hand have been measured in psychophysical experiments. The 2 primates have similar capacities; they make discriminations with Weber fractions that change little over the frequency range from 20 to 200 Hz. The discriminatory capacities are similar whether stimuli are received passively or acquired actively. Combined experiments have been made in monkeys in which the electrical signs of the activity of quickly adapting ({QA}) and slowly adapting ({SA}) neurons of postcentral areas 3b and 1 were recorded, both in the working state as the animal made discriminations and in the irrelevant state in which the stimuli did not guide behavior. The neuronal responses were analyzed in terms of discharge rates, periodicities in the neuronal discharges, and harmonic contents. It was shown that discriminatory capacity depends upon the period lengths in the sets of periodically entrained activity evoked by stimuli readily discriminated, and not upon the small differences in rates of discharge evoked by those stimuli. The periodicities were shown by harmonic analysis to be sharply limited to stimulus frequencies. Low-frequency stimuli evoke periodicities at the second and third harmonics in some neurons, in addition to strongly periodic signals at the fundamental frequency of the stimuli. Their presence does not appear to interfere with frequency discrimination. Neuronal responses recorded in the stimulus-irrelevant state were not distinguishable from those recorded as monkeys made discriminations. The responses of {SA} neurons, recorded under similar conditions, resembled those of {QA} neurons in almost every feature, but reasons are given for concluding that the {SA} system plays no role in frequency discrimination in the sense of flutter.},
	pages = {3032--3044},
	number = {9},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Mountcastle, V. B. and Steinmetz, M. A. and Romo, R.},
	urldate = {2019-01-21},
	date = {1990-09-01},
	langid = {english},
	pmid = {2118947},
	file = {Full Text PDF:/home/felix/Zotero/storage/LZYAPJSJ/Mountcastle et al. - 1990 - Frequency discrimination in the sense of flutter .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/7UT3P9HN/3032.html:text/html}
}

@article{lamotte_capacities_1975-1,
	title = {Capacities of humans and monkeys to discriminate vibratory stimuli of different frequency and amplitude: a correlation between neural events and psychological measurements},
	volume = {38},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1975.38.3.539},
	doi = {10.1152/jn.1975.38.3.539},
	shorttitle = {Capacities of humans and monkeys to discriminate vibratory stimuli of different frequency and amplitude},
	abstract = {The capacities of monkeys and humans to discriminate between mechanical sinusoids differing in amplitude or frequency were measured in a two-alternative, forced-choice task. The difference limen for amplitude discrimination for both species remained constant near 10\% of the standard amplitude over the range of 17-30 {dB}, relative to detection threshold. Equal subjective intensity curves in the 20-40 Hz range were determined at 20 and 29 {dB}, relative to detection threshold. These curves followed the threshold curve and were identical for the two species. The difference limen for frequency discrimination averaged 1.8 Hz for humans and 2.7 Hz for monkeys; the range of values for the two species overlapped nearly completely. The small sizes of these difference limens indicate, we believe, the capacity of highly trained individuals of either species to ascertain small differences in the temporal order of somesthetic stimuli and of the neural events evoked by them. In one series of experiments we demonstrated that subjects of both species possess two threshold for two different aspects of flutter-vibration which are displaced from each other along the intensive continuum. For either species, the minimum level of stimulus amplitude required for threshold frequency discrimination is about 8 {dB} above that sufficient for detection. This difference in amplitude is called the atonal interval and matches that observed between absolute and tuning thresholds for quickly adapting, mechanoreceptor afferents (the Meissner afferents) which innervate the glabrous skin of the monkey hand. These and previous findings have permitted a number of direct correlations between behavioral and neural events as regards the sense of flutter. The neural codes for the intensity and frequency of flutter appear to be different. The capacity to detect the presence of a mechanical sinusoid and the capacity to judge its subjective intensity are likely to depend on criterion levels of activity in the total population of Meissner afferents, the former on the appearance of any activity (absolute threshold) in a small population of the most sensitive of these fibers and the latter on the overall size of the active population of neuronal elements at each level of amplitude. The total activity in the relevant neural population elicited by sinusoids of increasing amplitude defines a prothetic continuum along which subjects can judge the magnitude of sensation..},
	pages = {539--559},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {{LaMotte}, R. H. and Mountcastle, V. B.},
	urldate = {2019-01-21},
	date = {1975-05-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/H558FYGM/LaMotte and Mountcastle - 1975 - Capacities of humans and monkeys to discriminate v.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/UQRIFYTL/jn.1975.38.3.html:text/html}
}

@article{romo_cognitive_2003,
	title = {Cognitive neuroscience: Flutter Discrimination: neural codes, perception, memory and decision making},
	volume = {4},
	rights = {2003 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1058},
	doi = {10.1038/nrn1058},
	shorttitle = {Cognitive neuroscience},
	abstract = {Recent studies combining psychophysical and neurophysiological experiments in behaving monkeys have provided new insights into how several cortical areas integrate efforts to solve a vibrotactile discrimination task. In particular, these studies have addressed how neural codes are related to perception, working memory and decision making in this model. The primary somatosensory cortex drives higher cortical areas where past and current sensory information are combined, such that a comparison of the two evolves into a behavioural decision. These and other observations in visual tasks indicate that decisions emerge from highly-distributed processes in which the details of a scheduled motor plan are gradually specified by sensory information.},
	pages = {203--218},
	number = {3},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Romo, Ranulfo and Salinas, Emilio},
	urldate = {2019-01-21},
	date = {2003-03},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/WXSNTH8D/nrn1058.html:text/html}
}

@article{hernandez_temporal_2002,
	title = {Temporal Evolution of a Decision-Making Process in Medial Premotor Cortex},
	volume = {33},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S089662730200613X},
	doi = {10.1016/S0896-6273(02)00613-X},
	abstract = {The events linking sensory discrimination to motor action remain unclear. It is not known, for example, whether the motor areas of the frontal lobe receive the result of the discrimination process from other areas or whether they actively participate in it. To investigate this, we trained monkeys to discriminate between two mechanical vibrations applied sequentially to the fingertips; here subjects had to recall the first vibration, compare it to the second one, and indicate with a hand/arm movement which of the two vibrations had the higher frequency. We recorded the activity of single neurons in medial premotor cortex ({MPC}) and found that their responses correlate with the diverse stages of the discrimination process. Thus, activity in {MPC} reflects the temporal evolution of the decision-making process leading to action selection during this perceptual task.},
	pages = {959--972},
	number = {6},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Hernández, Adrián and Zainos, Antonio and Romo, Ranulfo},
	urldate = {2019-01-21},
	date = {2002-03-14},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/L2Q28IQ3/Hernández et al. - 2002 - Temporal Evolution of a Decision-Making Process in.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/E9XBVPVW/S089662730200613X.html:text/html}
}

@article{hernandez_discrimination_1997,
	title = {Discrimination in the Sense of Flutter: New Psychophysical Measurements in Monkeys},
	volume = {17},
	rights = {Copyright © 1997 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/17/16/6391},
	doi = {10.1523/JNEUROSCI.17-16-06391.1997},
	shorttitle = {Discrimination in the Sense of Flutter},
	abstract = {Humans and monkeys have similar capacities to discriminate the frequencies of mechanical sinusoids delivered to their hands in the range that corresponds to the sense of flutter (10–50 Hz). Previous studies showed that monkeys can discriminate whether comparison stimuli are higher or lower in frequency than a base stimulus that does not vary from trial to trial during an experiment. We verified this result in two monkeys trained in this manner. To confirm that these animals were able to discriminate, we tested them in a variant of the task in which the frequency of the base stimulus changed randomly from trial to trial. The monkeys failed to discriminate in this new testing mode; instead they seemed to categorize the comparison stimuli, ignoring the base stimulus. After further training in the randomized base condition, the two monkeys learned to discriminate accurately. We then explored how the stimulation parameters affected performance. We found that animals could discriminate accurately with stimulus durations as short as 250 msec, with interstimulus intervals as long as 10 sec, with 50\% differences between base and comparison stimulus amplitudes or when stimulated on a different finger. Performance did not degrade in these conditions, even though the monkeys had never been trained or tested under them. The results show that monkeys may try to categorize rather than discriminate when the task allows either strategy, although they are capable of performing true discriminations very robustly. These findings have important implications for investigating the neuronal processes underlying sensory discrimination.},
	pages = {6391--6400},
	number = {16},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Hernández, Adrián and Salinas, Emilio and Garcı́a, Rafael and Romo, Ranulfo},
	urldate = {2019-01-21},
	date = {1997-12-1},
	langid = {english},
	pmid = {9236247},
	keywords = {psychophysics, categorization, discrimination, flutter, monkeys, vibrotactile stimuli},
	file = {Full Text PDF:/home/felix/Zotero/storage/7SCUYHKV/Hernández et al. - 1997 - Discrimination in the Sense of Flutter New Psycho.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/P4GFEY3V/6391.html:text/html}
}

@article{gescheider_vibrotactile_1990,
	title = {Vibrotactile intensity discrimination measured by three methods},
	volume = {87},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.399300},
	doi = {10.1121/1.399300},
	pages = {330--338},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Gescheider, George A. and Bolanowski, Stanley J. and Verrillo, Ronald T. and Arpajian, Dean J. and Ryan, Timothy F.},
	urldate = {2019-01-21},
	date = {1990},
	file = {Snapshot:/home/felix/Zotero/storage/895TU55A/1.html:text/html}
}

@article{craig_difference_1972,
	title = {Difference threshold for intensity of tactile stimuli},
	volume = {11},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03210362},
	doi = {10.3758/BF03210362},
	abstract = {The difference threshold ({DL}) for brief tactile stimuli (taps) and vibrotactile stimuli was determined using a 2IFC procedure. The measurements were made at several intensities both in quiet and in the presence of a background vibration. The results show that in the absence of background vibration the {DLs} for higher intensity stimuli are similar for both taps and vibration, whereas at lower intensities the {DL} is larger for taps. In the presence of background vibration the {DL} for vibratory stimuli is elevated to a much greater extent than it is for tap stimuli. The {DL} is affected by both the intensity of the signal and the intensity of the background vibration.},
	pages = {150--152},
	number = {2},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Craig, James C.},
	urldate = {2019-01-21},
	date = {1972-03-01},
	langid = {english},
	keywords = {Auditory Stimulus, Difference Threshold, Sensation Level, Tactile Stimulus, Vibrotactile Stimulus},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/GH2IETBZ/Craig - 1972 - Difference threshold for intensity of tactile stim.pdf:application/pdf}
}

@article{alary_tactile_2009,
	title = {Tactile acuity in the blind: A closer look reveals superiority over the sighted in some but not all cutaneous tasks},
	volume = {47},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S002839320900133X},
	doi = {10.1016/j.neuropsychologia.2009.03.014},
	shorttitle = {Tactile acuity in the blind},
	abstract = {Previous studies have shown that blind subjects may outperform the sighted on certain tactile discrimination tasks. We recently showed that blind subjects outperformed the sighted in a haptic 2D-angle discrimination task. The purpose of this study was to compare the performance of the same blind (n=16) and sighted (n=17, G1) subjects in three tactile discrimination tasks dependent solely on cutaneous inputs from the fingertip of the index finger, D2. A second group of sighted subjects (n=30, G2) were also tested. Texture discrimination thresholds were 0.62 (G1)–0.80mm (G2) for the sighted subjects, and 0.64mm for the blind (standard, 2mm spatial period). Grating orientation thresholds were 0.99 (G1)–1.12mm (G2) for the sighted subjects, and 0.96mm for the blind. Finally, vibrotactile frequency discrimination thresholds (100Hz standard) were 19.5 (G2) and 20.0Hz (G1) for the sighted, and 16.5Hz for the blind subjects. There were no significant differences in performance between the blind and the sighted subjects for the grating orientation or vibrotactile frequency discrimination tasks. In contrast, blind subjects outperformed the sighted for the texture discrimination task (G2 only), possibly reflecting the fact that the raised dot surfaces were similar to the dots forming Braille characters (all were fluent Braille readers).},
	pages = {2037--2043},
	number = {10},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Alary, Flamine and Duquette, Marco and Goldstein, Rachel and Elaine Chapman, C. and Voss, Patrice and La Buissonnière-Ariza, Valérie and Lepore, Franco},
	urldate = {2019-01-21},
	date = {2009-08-01},
	keywords = {Blind, Human psychophysics, Tactile acuity},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/YWHNJRD3/S002839320900133X.html:text/html}
}

@article{alary_tactile_2009-1,
	title = {Tactile acuity in the blind: A closer look reveals superiority over the sighted in some but not all cutaneous tasks},
	volume = {47},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S002839320900133X},
	doi = {10.1016/j.neuropsychologia.2009.03.014},
	shorttitle = {Tactile acuity in the blind},
	abstract = {Previous studies have shown that blind subjects may outperform the sighted on certain tactile discrimination tasks. We recently showed that blind subjects outperformed the sighted in a haptic 2D-angle discrimination task. The purpose of this study was to compare the performance of the same blind (n=16) and sighted (n=17, G1) subjects in three tactile discrimination tasks dependent solely on cutaneous inputs from the fingertip of the index finger, D2. A second group of sighted subjects (n=30, G2) were also tested. Texture discrimination thresholds were 0.62 (G1)–0.80mm (G2) for the sighted subjects, and 0.64mm for the blind (standard, 2mm spatial period). Grating orientation thresholds were 0.99 (G1)–1.12mm (G2) for the sighted subjects, and 0.96mm for the blind. Finally, vibrotactile frequency discrimination thresholds (100Hz standard) were 19.5 (G2) and 20.0Hz (G1) for the sighted, and 16.5Hz for the blind subjects. There were no significant differences in performance between the blind and the sighted subjects for the grating orientation or vibrotactile frequency discrimination tasks. In contrast, blind subjects outperformed the sighted for the texture discrimination task (G2 only), possibly reflecting the fact that the raised dot surfaces were similar to the dots forming Braille characters (all were fluent Braille readers).},
	pages = {2037--2043},
	number = {10},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Alary, Flamine and Duquette, Marco and Goldstein, Rachel and Elaine Chapman, C. and Voss, Patrice and La Buissonnière-Ariza, Valérie and Lepore, Franco},
	urldate = {2019-01-21},
	date = {2009-08-01},
	keywords = {Blind, Human psychophysics, Tactile acuity},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/TXRBCC6M/Alary et al. - 2009 - Tactile acuity in the blind A closer look reveals.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/GHX45AVY/S002839320900133X.html:text/html}
}

@online{noauthor_comparing_nodate,
	title = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination: A Human {fMRI} Study {\textbar} Journal of Neurophysiology},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00940.2009},
	urldate = {2019-01-21},
	file = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination\: A Human fMRI Study | Journal of Neurophysiology:/home/felix/Zotero/storage/UQU2VS2I/jn.00940.html:text/html}
}

@article{li_hegner_comparing_2010,
	title = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination: A Human {fMRI} Study},
	volume = {103},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00940.2009},
	doi = {10.1152/jn.00940.2009},
	shorttitle = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination},
	abstract = {We investigated to which extent the discrimination of tactile patterns and vibrotactile frequencies share common cortical areas. An adaptation paradigm has been used to identify cortical areas specific for processing particular features of tactile stimuli. Healthy right-handed subjects performed a delayed-match-to-sample ({DMTS}) task discriminating between pairs of tactile patterns or vibrotactile frequencies in separate functional {MRI} sessions. The tactile stimuli were presented to the right middle fingertip sequentially with a 5.5 s delay. Regions of interest ({ROIs}) were defined by cortical areas commonly activated in both tasks and those that showed differential activation between both tasks. Results showed recruitment of many common brain regions along the sensory motor pathway (such as bilateral somatosensory, premotor areas, and anterior insula) in both tasks. Three cortical areas, the right intraparietal sulcus ({IPS}), supramarginal gyrus ({SMG})/parietal operculum ({PO}), and {PO}, were significantly more activated during the pattern than in the frequency task. Further {BOLD} time course analysis was performed in the {ROIs}. Significant {BOLD} adaptation was found in bilateral {IPS}, right anterior insula, and {SMG}/{PO} in the pattern task, whereas there was no significant {BOLD} adaptation found in the frequency task. In addition, the right hemisphere was found to be more dominant in the pattern than in the frequency task, which could be attributed to the differences between spatial (pattern) and temporal (frequency) processing. From the different spatio-temporal characteristics of {BOLD} activation in the pattern and frequency tasks, we concluded that different neuronal mechanisms are underlying the tactile spatial and temporal processing.},
	pages = {3115--3122},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Li Hegner, Yiwen and Lee, Ying and Grodd, Wolfgang and Braun, Christoph},
	urldate = {2019-01-21},
	date = {2010-03-24},
	file = {Full Text PDF:/home/felix/Zotero/storage/ZF4G2Y6K/Li Hegner et al. - 2010 - Comparing Tactile Pattern and Vibrotactile Frequen.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/8YW8DESQ/jn.00940.html:text/html}
}

@article{harris_factors_2006,
	title = {Factors Affecting Frequency Discrimination of Vibrotactile Stimuli: Implications for Cortical Encoding},
	volume = {1},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0000100},
	doi = {10.1371/journal.pone.0000100},
	shorttitle = {Factors Affecting Frequency Discrimination of Vibrotactile Stimuli},
	abstract = {Background Measuring perceptual judgments about stimuli while manipulating their physical characteristics can uncover the neural algorithms underlying sensory processing. We carried out psychophysical experiments to examine how humans discriminate vibrotactile stimuli. Methodology/Principal Findings Subjects compared the frequencies of two sinusoidal vibrations applied sequentially to one fingertip. Performance was reduced when (1) the root mean square velocity (or energy) of the vibrations was equated by adjusting their amplitudes, and (2) the vibrations were noisy (their temporal structure was irregular). These effects were super-additive when subjects compared noisy vibrations that had equal velocity, indicating that frequency judgments became more dependent on the vibrations' temporal structure when differential information about velocity was eliminated. To investigate which areas of the somatosensory system use information about velocity and temporal structure, we required subjects to compare vibrations applied sequentially to opposite hands. This paradigm exploits the fact that tactile input to neurons at early levels (e.g., the primary somatosensory cortex, {SI}) is largely confined to the contralateral side of the body, so these neurons are less able to contribute to vibration comparisons between hands. The subjects' performance was still sensitive to differences in vibration velocity, but became less sensitive to noise. Conclusions/Significance We conclude that vibration frequency is represented in different ways by different mechanisms distributed across multiple cortical regions. Which mechanisms support the “readout” of frequency varies according to the information present in the vibration. Overall, the present findings are consistent with a model in which information about vibration velocity is coded in regions beyond {SI}. While adaptive processes within {SI} also contribute to the representation of frequency, this adaptation is influenced by the temporal regularity of the vibration.},
	pages = {e100},
	number = {1},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Harris, Justin A. and Arabzadeh, Ehsan and Fairhall, Adrienne L. and Benito, Claire and Diamond, Mathew E.},
	urldate = {2019-01-21},
	date = {2006-12-20},
	langid = {english},
	keywords = {Cognition, Hands, Monkeys, Neurons, Psychophysics, Tactile sensation, Vibration, Vibration engineering},
	file = {Full Text PDF:/home/felix/Zotero/storage/IXA5VT4M/Harris et al. - 2006 - Factors Affecting Frequency Discrimination of Vibr.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/IM8297K2/article.html:text/html}
}

@article{levanen_feeling_2001,
	title = {Feeling vibrations: enhanced tactile sensitivity in congenitally deaf humans},
	volume = {301},
	issn = {0304-3940},
	url = {http://www.sciencedirect.com/science/article/pii/S030439400101597X},
	doi = {10.1016/S0304-3940(01)01597-X},
	shorttitle = {Feeling vibrations},
	abstract = {The human nervous system displays remarkable functional plasticity following long-term sensory deprivation. For example, the auditory cortex of congenitally deaf humans may start to process tactile information. To further explore this type of cross-modal plasticity, we examined the tactile accuracy of congenitally deaf and normal hearing subjects in frequency discrimination and in detection of random suprathreshold frequency changes within a monotonous sequence of vibratory stimuli. We found that congenital deafness can enhance the accuracy of suprathreshold tactile change detection while tactile frequency discrimination is not significantly changed, although there is a trend toward reduced thresholds. The enhanced tactile sensitivity in the deaf probably reflects both neural plasticity and increased attention directed to the stimuli. Whatever the underlying neural mechanisms might be, functional compensation following early sensory loss apparently leads the remaining sensory modalities to develop capacities exceeding those of the normal functional systems.},
	pages = {75--77},
	number = {1},
	journaltitle = {Neuroscience Letters},
	shortjournal = {Neuroscience Letters},
	author = {Levänen, Sari and Hamdorf, Dorothea},
	urldate = {2019-01-21},
	date = {2001-03-23},
	keywords = {Congenital deafness, Cross-modal processing, Intramodal processing, Tactile change detection, Tactile frequency discrimination},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/MSQAYIMI/Levänen and Hamdorf - 2001 - Feeling vibrations enhanced tactile sensitivity i.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/K23PCT99/S030439400101597X.html:text/html}
}

@article{levanen_vibration-induced_1998,
	title = {Vibration-induced auditory-cortex activation in a congenitally deaf adult},
	volume = {8},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S096098220700348X},
	doi = {10.1016/S0960-9822(07)00348-X},
	abstract = {Considerable changes take place in the number of cerebral neurons, synapses and axons during development, mainly as a result of competition between different neural activities [1], [2], [3], [4]. Studies using animals suggest that when input from one sensory modality is deprived early in development, the affected neural structures have the potential to mediate functions for the remaining modalities [5], [6], [7], [8]. We now show that similar potential exists in the human auditory system: vibrotactile stimuli, applied on the palm and fingers of a congenitally deaf adult, activated his auditory cortices. The recorded magnetoencephalographic ({MEG}) signals also indicated that the auditory cortices were able to discriminate between the applied 180 Hz and 250 Hz vibration frequencies. Our findings suggest that human cortical areas, normally subserving hearing, may process vibrotactile information in the congenitally deaf.},
	pages = {869--872},
	number = {15},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Levänen, S. and Jousmäki, V. and Hari, R.},
	urldate = {2019-01-21},
	date = {1998-07-16},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/BADM4BI7/Levänen et al. - 1998 - Vibration-induced auditory-cortex activation in a .pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/VZQ43XPF/S096098220700348X.html:text/html}
}

@online{noauthor_congenital_nodate,
	title = {Congenital blindness leads to enhanced vibrotactile perception - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S0028393209003935},
	urldate = {2019-01-21},
	file = {Congenital blindness leads to enhanced vibrotactile perception - ScienceDirect:/home/felix/Zotero/storage/XHJF4FKL/S0028393209003935.html:text/html}
}

@article{wan_congenital_2010,
	title = {Congenital blindness leads to enhanced vibrotactile perception},
	volume = {48},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S0028393209003935},
	doi = {10.1016/j.neuropsychologia.2009.10.001},
	abstract = {Previous studies have shown that in comparison with the sighted, blind individuals display superior non-visual perceptual abilities and differ in brain organisation. In this study, we investigated the performance of blind and sighted participants on a vibrotactile discrimination task. Thirty-three blind participants were classified into one of three groups (congenital, early, late), depending on the age at which they became blind. Consistent with previous neuroimaging data, individuals blinded after late childhood (14 years) showed no advantage over sighted participants. Both the congenitally- and early-blind participants were better than the sighted. The congenitally blind participants were even more accurate than the early-blind participants; a distinction that has not been drawn previously. Duration of blindness did not predict task performance and the effect of onset age persisted after duration of daily Braille reading was accounted for. We conclude that complete visual deprivation early in life leads to heightened tactile acuity.},
	pages = {631--635},
	number = {2},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Wan, Catherine Y. and Wood, Amanda G. and Reutens, David C. and Wilson, Sarah J.},
	urldate = {2019-01-21},
	date = {2010-01-01},
	keywords = {Blind, Onset age, Plasticity, Tactile perception},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/F988QLEQ/Wan et al. - 2010 - Congenital blindness leads to enhanced vibrotactil.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/HEXH85S8/S0028393209003935.html:text/html}
}

@article{girard_multisensory_2011,
	title = {Multisensory gain within and across hemispaces in simple and choice reaction time paradigms},
	volume = {214},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-010-2515-9},
	doi = {10.1007/s00221-010-2515-9},
	abstract = {Recent results on the nature and limits of multisensory enhancement are inconsistent when stimuli are presented across spatial regions. We presented visual, tactile and visuotactile stimuli to participants in two speeded response tasks. Each unisensory stimulus was presented to either the left or right hemispace, and multisensory stimuli were presented as either aligned (e.g. visual right/tactile right) or misaligned (e.g. visual right/tactile left). The first task was a simple reaction time ({SRT}) paradigm where participants responded to all stimulations irrespective of spatial position. Results showed that multisensory gain and coactivation were the same for spatially aligned and misaligned visuotactile stimulation. In the second task, a choice reaction time ({CRT}) paradigm where participants responded to right-sided stimuli only, misaligned stimuli yielded slower reaction times. No difference in multisensory gain was found between the {SRT} and {CRT} tasks for aligned stimulation. Overall, the results suggest that when spatial information is task-irrelevant, multisensory integration of spatially aligned and misaligned stimuli is equivalent. However, manipulating task requirements can alter this effect.},
	pages = {1--8},
	number = {1},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Girard, Simon and Collignon, Olivier and Lepore, Franco},
	urldate = {2019-01-21},
	date = {2011-09-01},
	langid = {english},
	keywords = {Choice reaction time, Multisensory, Redundancy gain ({RG}), Simple reaction time, Tactile, Visual},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/WR8VS5TW/Girard et al. - 2011 - Multisensory gain within and across hemispaces in .pdf:application/pdf}
}

@article{soto-faraco_multisensory_2009,
	title = {Multisensory contributions to the perception of vibrotactile events},
	volume = {196},
	issn = {0166-4328},
	url = {http://www.sciencedirect.com/science/article/pii/S0166432808005317},
	doi = {10.1016/j.bbr.2008.09.018},
	abstract = {We argue that audio-tactile interactions during vibrotactile processing provide a promising, albeit largely neglected, benchmark for the systematic study multisensory integration. This article reviews and discusses current evidence for multisensory contributions to the perception of vibratory events, and proposes a framework to address a number of relevant questions. First, we highlight some of the features that characterize the senses of hearing and touch in terms of vibratory information processing, and which allow for potential cross-modal interactions at multiple levels along the functional architecture of the sensory systems. Second, we briefly review empirical evidence for interactions between hearing and touch in the domain of vibroactile perception and related stimulus properties, covering behavioural, electrophysiological and neuroimaging studies in humans and animals. Third, we discuss the vibrotactile discrimination task, which has been successfully applied in the study of perception and decision processes in psychophysical and physiological research. We argue that this approach, complemented with computational modeling using biophysically realistic neural networks, may be a convenient framework to address auditory contributions to vibrotactile processing in the somatosensory system. Finally, we comment on a series of particular issues which are relevant in multisensory research and potentially addressable within the proposed framework.},
	pages = {145--154},
	number = {2},
	journaltitle = {Behavioural Brain Research},
	shortjournal = {Behavioural Brain Research},
	author = {Soto-Faraco, Salvador and Deco, Gustavo},
	urldate = {2019-01-21},
	date = {2009-01-23},
	keywords = {Touch, Multisensory, Audio-tactile interactions, Audition, Perception, Vibrotactile events},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/YYH3ZEQK/Soto-Faraco and Deco - 2009 - Multisensory contributions to the perception of vi.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/8NP728I4/S0166432808005317.html:text/html}
}

@article{wilson_integration_2010,
	title = {Integration of auditory and vibrotactile stimuli: Effects of frequency},
	volume = {127},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.3365318},
	doi = {10.1121/1.3365318},
	shorttitle = {Integration of auditory and vibrotactile stimuli},
	pages = {3044--3059},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Wilson, E. Courtenay and Reed, Charlotte M. and Braida, Louis D.},
	urldate = {2019-01-21},
	date = {2010-05-01},
	file = {Full Text:/home/felix/Zotero/storage/TGPZ683D/Wilson et al. - 2010 - Integration of auditory and vibrotactile stimuli .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/S3GW3GDS/1.html:text/html}
}

@article{foxe_multisensory_2009,
	title = {Multisensory Integration: Frequency Tuning of Audio-Tactile Integration},
	volume = {19},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982209008768},
	doi = {10.1016/j.cub.2009.03.029},
	shorttitle = {Multisensory Integration},
	abstract = {Summary
Multisensory information can be crucial, yet in many circumstances we have little, if any, awareness of the effects of multisensory inputs on what appear to be entirely unisensory perceptions. A recent study shows robust effects of auditory input on tactile frequency discriminations and that this auditory cross-sensory interference has specific tuning.},
	pages = {R373--R375},
	number = {9},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Foxe, John J.},
	urldate = {2019-01-21},
	date = {2009-05-12},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/DNXVEMQW/Foxe - 2009 - Multisensory Integration Frequency Tuning of Audi.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/DLJHAQKL/S0960982209008768.html:text/html}
}

@article{stein_neural_2009,
	title = {The neural basis of multisensory integration in the midbrain: Its organization and maturation},
	volume = {258},
	issn = {0378-5955},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595509000665},
	doi = {10.1016/j.heares.2009.03.012},
	series = {Multisensory integration in auditory and auditory-related areas of cortex},
	shorttitle = {The neural basis of multisensory integration in the midbrain},
	abstract = {Multisensory integration describes a process by which information from different sensory systems is combined to influence perception, decisions, and overt behavior. Despite a widespread appreciation of its utility in the adult, its developmental antecedents have received relatively little attention. Here we review what is known about the development of multisensory integration, with a focus on the circuitry and experiential antecedents of its development in the model system of the multisensory (i.e., deep) layers of the superior colliculus. Of particular interest here are two sets of experimental observations: (1) cortical influences appear essential for multisensory integration in the {SC}, and (2) postnatal experience guides its maturation. The current belief is that the experience normally gained during early life is instantiated in the cortico-{SC} projection, and that this is the primary route by which ecological pressures adapt {SC} multisensory integration to the particular environment in which it will be used.},
	pages = {4--15},
	number = {1},
	journaltitle = {Hearing Research},
	shortjournal = {Hearing Research},
	author = {Stein, Barry E. and Stanford, Terrence R. and Rowland, Benjamin A.},
	urldate = {2019-01-22},
	date = {2009-12-01},
	keywords = {Audition, Cortex, Cross-modal, Development, Multisensory integration, Superior colliculus, Vision},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/ZNPHA4UU/Stein et al. - 2009 - The neural basis of multisensory integration in th.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/VN68UBD9/S0378595509000665.html:text/html}
}

@article{forster_redundant_2002,
	title = {Redundant target effect and intersensory facilitation from visual-tactile interactions in simple reaction time},
	volume = {143},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-002-1017-9},
	doi = {10.1007/s00221-002-1017-9},
	abstract = {In a simple reaction time ({RT}) task, normal observers responded faster to simultaneous visual and tactile stimuli than to single visual or tactile stimuli. {RT} to simultaneous visual and tactile stimuli was also faster than {RT} to simultaneous dual visual or tactile stimuli. The advantage for {RT} to combined visual-tactile stimuli over {RT} to the other types of stimulation could be accounted for by intersensory neural facilitation rather than by probability summation. The direction of gaze (and presumably of visual attention) to space regions near to or far from the site of tactile stimulation had no effect on tactile {RT}. However, {RT} to single or dual tactile stimuli was fastest when observers could see the sites of tactile stimulation on their hands both directly and through a mirror at the same time. All these effects can be ascribed to the convergence of tactile and visual inputs onto neural centers which contain flexible multimodal representations of body parts.},
	pages = {480--487},
	number = {4},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Forster, Bettina and Cavina-Pratesi, Cristiana and Aglioti, Salvatore M. and Berlucchi, Giovanni},
	urldate = {2019-01-22},
	date = {2002-04-01},
	langid = {english},
	keywords = {Human, Crossmodal integration, Intersensory facilitation, Reaction time, Redundant target effect},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/L8R8R6QB/Forster et al. - 2002 - Redundant target effect and intersensory facilitat.pdf:application/pdf}
}

@article{ridgway_redundant_2008,
	title = {Redundant target effect and the processing of colour and luminance},
	volume = {187},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-008-1293-0},
	doi = {10.1007/s00221-008-1293-0},
	abstract = {The redundant target effect is the observation that people typically respond faster to double targets (two targets presented simultaneously) than to either of the targets presented alone. This difference in latency is termed the redundancy gain ({RG}). Chromatic targets may be accompanied with luminance changes at their onset and offset. We have used a dynamic random luminance modulation technique to mask out luminance components of chromatic signals. Here we report on the presence of a significant {RG} for visual targets defined by their combined luminance and chromatic components as well as their chromatic content in isolation. Reaction times were measured to the onset of three classes of stimuli, namely, Long- and Short-wavelength cone sensitive (L- and S-cone) targets matched for saliency as well as luminance-defined targets. Analysis of the cumulative distributions of reaction time data showed that a neural coactivation model could fit the experimental data for chromatic targets only. When a luminance component is present, the reaction time data can be explained by a probability summation account also known as the race model.},
	pages = {153--160},
	number = {1},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Ridgway, N. and Milders, M. and Sahraie, A.},
	urldate = {2019-01-22},
	date = {2008-05-01},
	langid = {english},
	keywords = {Redundant target effect, Neural coactivation, Probability summation},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/QBM93HBL/Ridgway et al. - 2008 - Redundant target effect and the processing of colo.pdf:application/pdf}
}

@article{karns_altered_2012,
	title = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults: A Visual-Somatosensory {fMRI} Study with a Double-Flash Illusion},
	volume = {32},
	rights = {Copyright © 2012 the authors 0270-6474/12/329626-13\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/32/28/9626},
	doi = {10.1523/JNEUROSCI.6488-11.2012},
	shorttitle = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults},
	abstract = {The developing brain responds to the environment by using statistical correlations in input to guide functional and structural changes—that is, the brain displays neuroplasticity. Experience shapes brain development throughout life, but neuroplasticity is variable from one brain system to another. How does the early loss of a sensory modality affect this complex process? We examined cross-modal neuroplasticity in anatomically defined subregions of Heschl's gyrus, the site of human primary auditory cortex, in congenitally deaf humans by measuring the {fMRI} signal change in response to spatially coregistered visual, somatosensory, and bimodal stimuli. In the deaf Heschl's gyrus, signal change was greater for somatosensory and bimodal stimuli than that of hearing participants. Visual responses in Heschl's gyrus, larger in deaf than hearing, were smaller than those elicited by somatosensory stimulation. In contrast to Heschl's gyrus, in the superior-temporal cortex visual signal was comparable to somatosensory signal. In addition, deaf adults perceived bimodal stimuli differently; in contrast to hearing adults, they were susceptible to a double-flash visual illusion induced by two touches to the face. Somatosensory and bimodal signal change in rostrolateral Heschl's gyrus predicted the strength of the visual illusion in the deaf adults in line with the interpretation that the illusion is a functional consequence of the altered cross-modal organization observed in deaf auditory cortex. Our results demonstrate that congenital and profound deafness alters how vision and somatosensation are processed in primary auditory cortex.},
	pages = {9626--9638},
	number = {28},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Karns, Christina M. and Dow, Mark W. and Neville, Helen J.},
	urldate = {2019-01-22},
	date = {2012-07-11},
	langid = {english},
	pmid = {22787048},
	file = {Full Text PDF:/home/felix/Zotero/storage/IRGRWGZU/Karns et al. - 2012 - Altered Cross-Modal Processing in the Primary Audi.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/TFGLF5NN/9626.html:text/html}
}

@article{hauthal_visuo-tactile_2015,
	title = {Visuo-tactile interactions in the congenitally deaf: a behavioral and event-related potential study},
	volume = {8},
	issn = {1662-5145},
	url = {https://www.frontiersin.org/articles/10.3389/fnint.2014.00098/full},
	doi = {10.3389/fnint.2014.00098},
	shorttitle = {Visuo-tactile interactions in the congenitally deaf},
	abstract = {Auditory deprivation is known to be accompanied by alterations in visual processing. Yet not much is known about tactile processing and the interplay of the intact sensory modalities in the deaf. We presented visual, tactile, and visuo-tactile stimuli to congenitally deaf and hearing individuals in a speeded detection task. Analyses of multisensory responses showed a redundant signals effect that was attributable to a coactivation mechanism in both groups, although the redundancy gain was less in the deaf. In hearing but not deaf participants, N200 latencies of somatosensory event-related potentials were modulated by simultaneous visual stimulation. In deaf but not hearing participants, however, there was a modulation of N200 latencies of visual event-related potentials due to simultaneous tactile stimulation. A comparison of unisensory responses between groups revealed larger N200 amplitudes for visual and shorter N200 latencies for tactile stimuli in the deaf. P300 amplitudes in response to both stimuli were larger in deaf participants. The differences in visual and tactile processing between deaf and hearing participants, however, were not reflected in behavior. The electroencephalography ({EEG}) results suggest an asymmetry in visuo-tactile interactions between deaf and hearing individuals. Visuo-tactile enhancements could neither be fully explained by perceptual deficiency nor by inverse effectiveness. Instead, we suggest that results might be explained by a shift in the relative importance of touch and vision in deaf individuals.},
	journaltitle = {Frontiers in Integrative Neuroscience},
	shortjournal = {Front. Integr. Neurosci.},
	author = {Hauthal, Nadine and Debener, Stefan and Rach, Stefan and Sandmann, Pascale and Thorne, Jeremy D.},
	urldate = {2019-01-22},
	date = {2015},
	keywords = {Cross-modal Plasticity, Deafness, multisensory processing, race model, redundant signals effect},
	file = {Full Text PDF:/home/felix/Zotero/storage/FERTNY4K/Hauthal et al. - 2015 - Visuo-tactile interactions in the congenitally dea.pdf:application/pdf}
}

@article{landry_temporary_2013,
	title = {Temporary Deafness Can Impair Multisensory Integration: A Study of Cochlear-Implant Users},
	volume = {24},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797612471142},
	doi = {10.1177/0956797612471142},
	shorttitle = {Temporary Deafness Can Impair Multisensory Integration},
	abstract = {Previous investigations suggest that temporary deafness can have a dramatic impact on audiovisual speech processing. The aim of this study was to test whether temporary deafness disturbs other multisensory processes in adults. A nonspeech task involving an audiotactile illusion was administered to a group of normally hearing individuals and a group of individuals who had been temporarily auditorily deprived. Members of this latter group had their auditory detection thresholds restored to normal levels through the use of a cochlear implant. Control conditions revealed that auditory and tactile discrimination capabilities were identical in the two groups. However, whereas normally hearing individuals integrated auditory and tactile information, so that they experienced the audiotactile illusion, individuals who had been temporarily deprived did not. Given the basic nature of the task, failure to integrate multisensory information could not be explained by the use of the cochlear implant. Thus, the results suggest that normally anticipated audiotactile interactions are disturbed following temporary deafness.},
	pages = {1260--1268},
	number = {7},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Landry, Simon P. and Guillemot, Jean-Paul and Champoux, François},
	urldate = {2019-01-22},
	date = {2013-07-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/2SSJQ56D/Landry et al. - 2013 - Temporary Deafness Can Impair Multisensory Integra.pdf:application/pdf}
}

@article{nava_audio-tactile_2014,
	title = {Audio-Tactile Integration in Congenitally and Late Deaf Cochlear Implant Users},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0099606},
	doi = {10.1371/journal.pone.0099606},
	abstract = {Several studies conducted in mammals and humans have shown that multisensory processing may be impaired following congenital sensory loss and in particular if no experience is achieved within specific early developmental time windows known as sensitive periods. In this study we investigated whether basic multisensory abilities are impaired in hearing-restored individuals with deafness acquired at different stages of development. To this aim, we tested congenitally and late deaf cochlear implant ({CI}) recipients, age-matched with two groups of hearing controls, on an audio-tactile redundancy paradigm, in which reaction times to unimodal and crossmodal redundant signals were measured. Our results showed that both congenitally and late deaf {CI} recipients were able to integrate audio-tactile stimuli, suggesting that congenital and acquired deafness does not prevent the development and recovery of basic multisensory processing. However, we found that congenitally deaf {CI} recipients had a lower multisensory gain compared to their matched controls, which may be explained by their faster responses to tactile stimuli. We discuss this finding in the context of reorganisation of the sensory systems following sensory loss and the possibility that these changes cannot be “rewired” through auditory reafferentation.},
	pages = {e99606},
	number = {6},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Nava, Elena and Bottari, Davide and Villwock, Agnes and Fengler, Ineke and Büchner, Andreas and Lenarz, Thomas and Röder, Brigitte},
	urldate = {2019-01-22},
	date = {2014-06-11},
	langid = {english},
	keywords = {Vision, Reaction time, Deafness, Audio signal processing, Cataracts, Cognitive impairment, Sensory perception, Visual impairments},
	file = {Full Text PDF:/home/felix/Zotero/storage/HWE3G64P/Nava et al. - 2014 - Audio-Tactile Integration in Congenitally and Late.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/ZZBC4SHS/article.html:text/html}
}

@article{levanen_vibration-induced_1998-1,
	title = {Vibration-induced auditory-cortex activation in a congenitally deaf adult},
	volume = {8},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S096098220700348X},
	doi = {10.1016/S0960-9822(07)00348-X},
	abstract = {Considerable changes take place in the number of cerebral neurons, synapses and axons during development, mainly as a result of competition between different neural activities [1], [2], [3], [4]. Studies using animals suggest that when input from one sensory modality is deprived early in development, the affected neural structures have the potential to mediate functions for the remaining modalities [5], [6], [7], [8]. We now show that similar potential exists in the human auditory system: vibrotactile stimuli, applied on the palm and fingers of a congenitally deaf adult, activated his auditory cortices. The recorded magnetoencephalographic ({MEG}) signals also indicated that the auditory cortices were able to discriminate between the applied 180 Hz and 250 Hz vibration frequencies. Our findings suggest that human cortical areas, normally subserving hearing, may process vibrotactile information in the congenitally deaf.},
	pages = {869--872},
	number = {15},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Levänen, S. and Jousmäki, V. and Hari, R.},
	urldate = {2019-01-22},
	date = {1998-07-16},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/YB4NNUXS/Levänen et al. - 1998 - Vibration-induced auditory-cortex activation in a .pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/EHT3AUDQ/S096098220700348X.html:text/html}
}

@article{landry_audiotactile_2014,
	title = {Audiotactile interaction can change over time in cochlear implant users},
	volume = {8},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2014.00316/full},
	doi = {10.3389/fnhum.2014.00316},
	abstract = {Recent results suggest that audiotactile interactions are disturbed in cochlear implant ({CI}) users. However, further exploration regarding the factors responsible for such abnormal sensory processing is still required. Considering the temporal nature of a previously used multisensory task, it remains unclear whether any aberrant results were caused by the specificity of the interaction studied or rather if it reflects an overall abnormal interaction. Moreover, although duration of experience with a {CI} has often been linked with the recovery of auditory functions, its impact on multisensory performance remains uncertain. In the present study, we used the parchment-skin illusion, a robust illustration of sound-biased perception of touch based on changes in auditory frequencies, to investigate the specificities of audiotactile interactions in {CI} users. Whereas individuals with relatively little experience with the {CI} performed similarly to the control group, experienced {CI} users showed a significantly greater illusory percept. The overall results suggest that despite being able to ignore auditory distractors in a temporal audiotactile task, {CI} users develop to become greatly influenced by auditory input in a spectral audiotactile task. When considered with the existing body of research, these results confirm that normal sensory interaction processing can be compromised in {CI} users.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Landry, Simon P. and Guillemot, Jean-Paul and Champoux, François},
	urldate = {2019-01-22},
	date = {2014},
	keywords = {Deafness, audiotactile interaction, cochlear implant, crossmodal plasticity, Hearing Loss, Multisensory Interactions, parchment-skin illusion, Sensory Deprivation},
	file = {Full Text PDF:/home/felix/Zotero/storage/3SRWF9FK/Landry et al. - 2014 - Audiotactile interaction can change over time in c.pdf:application/pdf}
}

@article{auer_vibrotactile_2007,
	title = {Vibrotactile Activation of the Auditory Cortices in Deaf versus Hearing Adults},
	volume = {18},
	issn = {0959-4965},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1934619/},
	doi = {10.1097/WNR.0b013e3280d943b9},
	abstract = {Neuroplastic changes in auditory cortex as a result of lifelong perceptual experience were investigated. Adults with early-onset deafness and long-term hearing aid experience were hypothesized to have undergone auditory cortex plasticity due to somatosensory stimulation. Vibrations were presented on the hand of deaf and normal-hearing participants during functional magnetic resonance imaging ({fMRI}). Vibration stimuli were derived from speech or were a fixed frequency. Higher, more widespread activity was observed within auditory cortical regions of the deaf participants for both stimulus types. Life-long somatosensory stimulation due to hearing aid use could explain the greater activity observed with deaf participants.},
	pages = {645--648},
	number = {7},
	journaltitle = {Neuroreport},
	shortjournal = {Neuroreport},
	author = {Auer, Edward T. and Bernstein, Lynne E. and Sungkarat, Witaya and Singh, Manbir},
	urldate = {2019-01-22},
	date = {2007-05-07},
	pmid = {17426591},
	pmcid = {PMC1934619},
	file = {PubMed Central Full Text PDF:/home/felix/Zotero/storage/GTCFQ9P5/Auer et al. - 2007 - Vibrotactile Activation of the Auditory Cortices i.pdf:application/pdf}
}

@article{heming_sensory_2005,
	title = {Sensory temporal processing in adults with early hearing loss},
	volume = {59},
	issn = {0278-2626},
	url = {http://www.sciencedirect.com/science/article/pii/S027826260500093X},
	doi = {10.1016/j.bandc.2005.05.012},
	abstract = {This study examined tactile and visual temporal processing in adults with early loss of hearing. The tactile task consisted of punctate stimulations that were delivered to one or both hands by a mechanical tactile stimulator. Pairs of light emitting diodes were presented on a display for visual stimulation. Responses consisted of {YES} or {NO} judgments as to whether the onset of the pairs of stimuli was perceived simultaneously or non-simultaneously. Tactile and visual temporal thresholds were significantly higher for the deaf group when compared to controls. In contrast to controls, tactile and visual temporal thresholds for the deaf group did not differ when presentation locations were examined. Overall findings of this study support the notion that temporal processing is compromised following early deafness regardless of the spatial location in which the stimuli are presented.},
	pages = {173--182},
	number = {2},
	journaltitle = {Brain and Cognition},
	shortjournal = {Brain and Cognition},
	author = {Heming, Joanne E. and Brown, Lenora N.},
	urldate = {2019-01-22},
	date = {2005-11-01},
	keywords = {Early deafness, Hearing loss, Laterality, Sensory processing, Tactile thresholds, Temporal processing, Timing, Visual thresholds},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/53YBVGIX/Heming and Brown - 2005 - Sensory temporal processing in adults with early h.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/4UDTDXEC/S027826260500093X.html:text/html}
}

@article{caetano_evidence_2006,
	title = {Evidence of vibrotactile input to human auditory cortex},
	volume = {29},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905005045},
	doi = {10.1016/j.neuroimage.2005.07.023},
	abstract = {Low frequency vibrations can be detected by both tactile and auditory systems. The aim of the present study is to find out, by means of whole-scalp magnetoencephalography ({MEG}), whether vibrotactile stimulation alone would activate human auditory cortical areas. We recorded {MEG} signals from eleven normal-hearing adults to 200-Hz vibrations (on average 19.5 {dB} above the individual tactile detection threshold), delivered to right-hand fingertips. All subjects reported a perception of a sound when they touched the vibrating tube, and they reported to perceive nothing when not touching the tube. The vibrotactile stimuli elicited clear and reproducible vibrotactile evoked fields ({VTEFs}) in ten subjects, whereas no {MEG} responses were observed when the tube was not touched. First responses to the vibrotactile stimuli, peaking around 60 ms, originated in the primary somatosensory cortex in all subjects. They were followed by activations in the auditory cortices, either bilaterally (N = 5) or unilaterally (N = 5), and by activations in the secondary somatosensory ({SII}) cortex, either contralaterally (N = 3) or ipsilaterally (N = 4). Both the {SII} and auditory activations consisted of transient responses at 100–200 ms. Additional auditory sustained activation was identified in nine subjects, either bilaterally (N = 2) or ipsilaterally (N = 7), at 200–700 ms. Our results suggest convergence of vibrotactile input to the auditory cortex in normal-hearing adults, in agreement with results previously obtained in a congenitally deaf adult.},
	pages = {15--28},
	number = {1},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Caetano, Gina and Jousmäki, Veikko},
	urldate = {2019-01-22},
	date = {2006-01-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/PYSGXLM5/Caetano and Jousmäki - 2006 - Evidence of vibrotactile input to human auditory c.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/MQ8YCW9A/S1053811905005045.html:text/html}
}

@article{schurmann_touch_2006,
	title = {Touch activates human auditory cortex},
	volume = {30},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905024638},
	doi = {10.1016/j.neuroimage.2005.11.020},
	abstract = {Vibrotactile stimuli can facilitate hearing, both in hearing-impaired and in normally hearing people. Accordingly, the sounds of hands exploring a surface contribute to the explorer's haptic percepts. As a possible brain basis of such phenomena, functional brain imaging has identified activations specific to audiotactile interaction in secondary somatosensory cortex, auditory belt area, and posterior parietal cortex, depending on the quality and relative salience of the stimuli. We studied 13 subjects with non-invasive functional magnetic resonance imaging ({fMRI}) to search for auditory brain areas that would be activated by touch. Vibration bursts of 200 Hz were delivered to the subjects' fingers and palm and tactile pressure pulses to their fingertips. Noise bursts served to identify auditory cortex. Vibrotactile–auditory co-activation, addressed with minimal smoothing to obtain a conservative estimate, was found in an 85-mm3 region in the posterior auditory belt area. This co-activation could be related to facilitated hearing at the behavioral level, reflecting the analysis of sound-like temporal patterns in vibration. However, even tactile pulses (without any vibration) activated parts of the posterior auditory belt area, which therefore might subserve processing of audiotactile events that arise during dynamic contact between hands and environment.},
	pages = {1325--1331},
	number = {4},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Schürmann, Martin and Caetano, Gina and Hlushchuk, Yevhen and Jousmäki, Veikko and Hari, Riitta},
	urldate = {2019-01-22},
	date = {2006-05-01},
	keywords = {Multisensory, Audiotactile interaction, Auditory belt area, Functional magnetic resonance imaging ({fMRI}), Human auditory cortex, Vibrotactile stimuli},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/ZNRJUY2A/Schürmann et al. - 2006 - Touch activates human auditory cortex.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/4L6QVE7L/S1053811905024638.html:text/html}
}

@article{goldreich_tactile_2003,
	title = {Tactile Acuity is Enhanced in Blindness},
	volume = {23},
	rights = {Copyright © 2003 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/23/8/3439},
	doi = {10.1523/JNEUROSCI.23-08-03439.2003},
	abstract = {Functional imaging studies in blind subjects have shown tactile activation of cortical areas that normally subserve vision, but whether blind people have enhanced tactile acuity has long been controversial. We compared the passive tactile acuity of blind and sighted subjects on a fully automated grating orientation task and used multivariate Bayesian data analysis to determine predictors of acuity. Acuity was significantly superior in blind subjects, independently of the degree of childhood vision, light perception level, or Braille reading. Acuity was strongly dependent on the force of contact between the stimulus surface and the skin, declined with subject age, and was better in women than in men. Despite large intragroup variability, the difference between blind and sighted subjects was highly significant: the average blind subject had the acuity of an average sighted subject of the same gender but 23 years younger. The results suggest that crossmodal plasticity may underlie tactile acuity enhancement in blindness.},
	pages = {3439--3445},
	number = {8},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Goldreich, Daniel and Kanics, Ingrid M.},
	urldate = {2019-01-22},
	date = {2003-04-15},
	langid = {english},
	pmid = {12716952},
	keywords = {crossmodal plasticity, blind, Braille, grating orientation, sensory compensation, somatosensory psychophysics, tactile acuity},
	file = {Full Text PDF:/home/felix/Zotero/storage/CF6LPBUC/Goldreich and Kanics - 2003 - Tactile Acuity is Enhanced in Blindness.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/UKZBF3SK/3439.html:text/html}
}

@article{gougoux_neuropsychology:_2004,
	title = {Neuropsychology: Pitch discrimination in the early blind},
	volume = {430},
	rights = {2004 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/430309a},
	doi = {10.1038/430309a},
	shorttitle = {Neuropsychology},
	abstract = {Do blind people develop superior abilities in auditory perception to compensate for their lack of vision? They are known to be better than sighted people at orientating themselves by sound, but it is not clear whether this enhanced awareness extends to other auditory domains, such as listening to music or to voices. Here we show that blind people are better than sighted controls at judging the direction of pitch change between sounds, even when the speed of change is ten times faster than that perceived by the controls — but only if they became blind at an early age. The younger the onset of blindness, the better is the performance, which is in line with cerebral plasticity being optimal during the early years.},
	pages = {309},
	number = {6997},
	journaltitle = {Nature},
	author = {Gougoux, Frédéric and Lepore, Franco and Lassonde, Maryse and Voss, Patrice and Zatorre, Robert J. and Belin, Pascal},
	urldate = {2019-01-22},
	date = {2004-07},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/BB7BRTMT/Gougoux et al. - 2004 - Neuropsychology Pitch discrimination in the early.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/3QDNLR99/430309a.html:text/html}
}

@article{bavelier_visual_2000,
	title = {Visual attention to the periphery is enhanced in congenitally deaf individuals},
	volume = {20},
	issn = {0270-6474},
	url = {https://archive-ouverte.unige.ch/unige:103930},
	abstract = {We compared normally hearing individuals and congenitally deaf individuals as they monitored moving stimuli either in the periphery or in the center of the visual field. When participants monitored the peripheral visual field, greater recruitment (as measured by functional magnetic resonance imaging) of the motion-selective area {MT}/{MST} was observed in deaf than in hearing individuals, whereas the two groups were comparable when attending to the central visual field. This finding indicates an enhancement of visual attention to peripheral visual space in deaf individuals. Structural equation modeling was used to further characterize the nature of this plastic change in the deaf. The effective connectivity between {MT}/{MST} and the posterior parietal cortex was stronger in deaf than in hearing individuals during peripheral but not central attention. Thus, enhanced peripheral attention to moving stimuli in the deaf may be mediated by alterations of the connectivity between {MT}/{MST} and the parietal cortex, one of the primary centers for spatial representation and attention.},
	pages = {RC931--6},
	number = {17},
	journaltitle = {Journal of Neuroscience},
	author = {Bavelier, Daphne and Thomann, Andrea and Hutton, C. and Mitchell, Teresa and Corina, D. and Liu, Guoying and Neville, Helen},
	urldate = {2019-01-22},
	date = {2000},
	file = {Full Text PDF:/home/felix/Zotero/storage/F7RWNEJE/Bavelier et al. - 2000 - Visual attention to the periphery is enhanced in c.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/BEBPL42W/unige103930.html:text/html}
}

@article{dye_is_2009,
	title = {Is Visual Selective Attention in Deaf Individuals Enhanced or Deficient? The Case of the Useful Field of View},
	volume = {4},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0005640},
	doi = {10.1371/journal.pone.0005640},
	shorttitle = {Is Visual Selective Attention in Deaf Individuals Enhanced or Deficient?},
	abstract = {Background Early deafness leads to enhanced attention in the visual periphery. Yet, whether this enhancement confers advantages in everyday life remains unknown, as deaf individuals have been shown to be more distracted by irrelevant information in the periphery than their hearing peers. Here, we show that, in a complex attentional task, a performance advantage results for deaf individuals. Methodology/Principal Findings We employed the Useful Field of View ({UFOV}) which requires central target identification concurrent with peripheral target localization in the presence of distractors – a divided, selective attention task. First, the comparison of deaf and hearing adults with or without sign language skills establishes that deafness and not sign language use drives {UFOV} enhancement. Second, {UFOV} performance was enhanced in deaf children, but only after 11 years of age. Conclusions/Significance This work demonstrates that, following early auditory deprivation, visual attention resources toward the periphery slowly get augmented to eventually result in a clear behavioral advantage by pre-adolescence on a selective visual attention task.},
	pages = {e5640},
	number = {5},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Dye, Matthew W. G. and Hauser, Peter C. and Bavelier, Daphne},
	urldate = {2019-01-22},
	date = {2009-05-20},
	langid = {english},
	keywords = {Deafness, Age groups, Attention, Children, Hearing disorders, Language, Schools, Sign language},
	file = {Full Text PDF:/home/felix/Zotero/storage/PYCHK6J9/Dye et al. - 2009 - Is Visual Selective Attention in Deaf Individuals .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/WW6FN3VG/article.html:text/html}
}

@article{shiell_enhancement_2014,
	title = {Enhancement of Visual Motion Detection Thresholds in Early Deaf People},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090498},
	doi = {10.1371/journal.pone.0090498},
	abstract = {In deaf people, the auditory cortex can reorganize to support visual motion processing. Although this cross-modal reorganization has long been thought to subserve enhanced visual abilities, previous research has been unsuccessful at identifying behavioural enhancements specific to motion processing. Recently, research with congenitally deaf cats has uncovered an enhancement for visual motion detection. Our goal was to test for a similar difference between deaf and hearing people. We tested 16 early and profoundly deaf participants and 20 hearing controls. Participants completed a visual motion detection task, in which they were asked to determine which of two sinusoidal gratings was moving. The speed of the moving grating varied according to an adaptive staircase procedure, allowing us to determine the lowest speed necessary for participants to detect motion. Consistent with previous research in deaf cats, the deaf group had lower motion detection thresholds than the hearing. This finding supports the proposal that cross-modal reorganization after sensory deprivation will occur for supramodal sensory features and preserve the output functions.},
	pages = {e90498},
	number = {2},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Shiell, Martha M. and Champoux, François and Zatorre, Robert J.},
	urldate = {2019-01-22},
	date = {2014-02-28},
	langid = {english},
	keywords = {Vision, Deafness, Hearing disorders, Language, Behavior, Cats, Motion, Velocity},
	file = {Full Text PDF:/home/felix/Zotero/storage/N9MY2YZ3/Shiell et al. - 2014 - Enhancement of Visual Motion Detection Thresholds .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/PTGFNFRR/article.html:text/html}
}

@incollection{stein_chapter_2011,
	title = {Chapter 10 - Organization and plasticity in multisensory integration: early and late experience affects its governing principles},
	volume = {191},
	url = {http://www.sciencedirect.com/science/article/pii/B9780444537522000072},
	series = {Enhancing Performance for Action and Perception},
	shorttitle = {Chapter 10 - Organization and plasticity in multisensory integration},
	abstract = {Neurons in the midbrain superior colliculus ({SC}) have the ability to integrate information from different senses to profoundly increase their sensitivity to external events. This not only enhances an organism's ability to detect and localize these events, but to program appropriate motor responses to them. The survival value of this process of multisensory integration is self-evident, and its physiological and behavioral manifestations have been studied extensively in adult and developing cats and monkeys. These studies have revealed, that contrary to expectations based on some developmental theories this process is not present in the newborn's brain. The data show that is acquired only gradually during postnatal life as a consequence of at least two factors: the maturation of cooperative interactions between association cortex and the {SC}, and extensive experience with cross-modal cues. Using these factors, the brain is able to craft the underlying neural circuits and the fundamental principles that govern multisensory integration so that they are adapted to the ecological circumstances in which they will be used.},
	pages = {145--163},
	booktitle = {Progress in Brain Research},
	publisher = {Elsevier},
	author = {Stein, Barry E. and Rowland, Benjamin A.},
	editor = {Green, Andrea M. and Chapman, C. Elaine and Kalaska, John F. and Lepore, Franco},
	urldate = {2019-01-22},
	date = {2011-01-01},
	doi = {10.1016/B978-0-444-53752-2.00007-2},
	keywords = {somatosensory, auditory, cross-modal, development, visual},
	file = {Accepted Version:/home/felix/Zotero/storage/LYHRCML8/Stein and Rowland - 2011 - Chapter 10 - Organization and plasticity in multis.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/NIQJVW7X/B9780444537522000072.html:text/html}
}

@book{stein_merging_1993,
	location = {Cambridge, {MA}, {US}},
	title = {The merging of the senses},
	isbn = {978-0-262-19331-3},
	series = {The merging of the senses},
	abstract = {The study of how information from the different senses is integrated in the brain crosses boundaries between a variety of scientific disciplines. Thus, we have tried to aim the book at a variety of readers; some may still be students and others will have had very little experience with some of the techniques used in the experiments described here. . . . The primary purpose of this book is to describe the electrophysiological experiments that we have done on single neurons in the central nervous system that code information derived from more than one sensory system. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pagetotal = {xv, 211},
	publisher = {The {MIT} Press},
	author = {Stein, Barry E. and Meredith, M. Alex},
	date = {1993},
	keywords = {Neurons, Brain, Electrophysiology, Sensory Integration},
	file = {Snapshot:/home/felix/Zotero/storage/SVGWGXI5/1993-97278-000.html:text/html}
}

@book{calvert_handbook_2004,
	title = {The Handbook of Multisensory Processes},
	isbn = {978-0-262-03321-3},
	abstract = {A reference work for the emerging field of multisensory integration, covering multidisciplinary research that goes beyond the traditional "sense-by-sense" approach and recognizes that perception is fundamentally a multisensory experience. This landmark reference work brings together for the first time in one volume the most recent research from different areas of the emerging field of multisensory integration. After many years of using a modality-specific "sense-by-sense" approach, researchers across different disciplines in neuroscience and psychology now recognize that perception is fundamentally a multisensory experience. To understand how the brain synthesizes information from the different senses, we must study not only how information from each sensory modality is decoded but also how this information interacts with the sensory processing taking place within other sensory channels. The findings cited in The Handbook of Multisensory Processes suggest that there are broad underlying principles that govern this interaction, regardless of the specific senses involved. The book is organized thematically into eight sections; each of the 55 chapters presents a state-of-the-art review of its topic by leading researchers in the field. The key themes addressed include multisensory contributions to perception in humans; whether the sensory integration involved in speech perception is fundamentally different from other kinds of multisensory integration; multisensory processing in the midbrain and cortex in model species, including rat, cat, and monkey; behavioral consequences of multisensory integration; modern neuroimaging techniques, including {EEG}, {PET}, and {fMRI}, now being used to reveal the many sites of multisensory processing in the brain; multisensory processes that require postnatal sensory experience to emerge, with examples from multiple species; brain specialization and possible equivalence of brain regions; and clinical studies of such breakdowns of normal sensory integration as brain damage and synesthesia.},
	pagetotal = {966},
	publisher = {{MIT} Press},
	author = {Calvert, Gemma and Spence, Charles and Spence, Department of Experimental Psychology Charles and Stein, Barry E. and Stein, Professor \{and\} Chair Barry E.},
	date = {2004},
	langid = {english},
	note = {Google-Books-{ID}: {CZS}\_yDoFV7AC},
	keywords = {Medical / Neuroscience, Psychology / Neuropsychology, Psychology / Physiological Psychology}
}

@article{shimojo_sensory_2001,
	title = {Sensory modalities are not separate modalities: plasticity and interactions},
	volume = {11},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438800002415},
	doi = {10.1016/S0959-4388(00)00241-5},
	shorttitle = {Sensory modalities are not separate modalities},
	abstract = {Historically, perception has been viewed as a modular function, with the different sensory modalities operating independently of each other. Recent behavioral and brain imaging studies challenge this view, by suggesting that cross-modal interactions are the rule and not the exception in perception, and that the cortical pathways previously thought to be sensory-specific are modulated by signals from other modalities.},
	pages = {505--509},
	number = {4},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Shimojo, Shinsuke and Shams, Ladan},
	urldate = {2019-01-22},
	date = {2001-08-01},
	keywords = {crossmodal interactions, multimodal integration, multimodal interactions, multimodal perception, multisensory perception, perception, sensory modalities},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/XUDMJLGA/Shimojo and Shams - 2001 - Sensory modalities are not separate modalities pl.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/6ZS6VI6Y/S0959438800002415.html:text/html}
}

@article{shams_illusions:_2000,
	title = {Illusions: What you see is what you hear},
	volume = {408},
	rights = {2000 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/35048669},
	doi = {10.1038/35048669},
	shorttitle = {Illusions},
	abstract = {Vision is believed to dominate our multisensory perception of the world. Here we overturn this established view by showing that auditory information can qualitatively alter the perception of an unambiguous visual stimulus to create a striking visual illusion. Our findings indicate that visual perception can be manipulated by other sensory modalities.},
	pages = {788},
	number = {6814},
	journaltitle = {Nature},
	author = {Shams, Ladan and Kamitani, Yukiyasu and Shimojo, Shinsuke},
	urldate = {2019-01-22},
	date = {2000-12},
	langid = {english},
	file = {Shams et al. - 2000 - Illusions What you see is what you hear.pdf:/home/felix/Zotero/storage/4HML2FPB/Shams et al. - 2000 - Illusions What you see is what you hear.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/ZII9548X/35048669.html:text/html}
}

@online{noauthor_merging_nodate,
	title = {Merging the senses into a robust percept - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/pii/S1364661304000385},
	urldate = {2019-01-22},
	file = {Merging the senses into a robust percept - ScienceDirect:/home/felix/Zotero/storage/PVVE46XL/S1364661304000385.html:text/html}
}

@article{ernst_merging_2004,
	title = {Merging the senses into a robust percept},
	volume = {8},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661304000385},
	doi = {10.1016/j.tics.2004.02.002},
	abstract = {To perceive the external environment our brain uses multiple sources of sensory information derived from several different modalities, including vision, touch and audition. All these different sources of information have to be efficiently merged to form a coherent and robust percept. Here we highlight some of the mechanisms that underlie this merging of the senses in the brain. We show that, depending on the type of information, different combination and integration strategies are used and that prior knowledge is often required for interpreting the sensory signals.},
	pages = {162--169},
	number = {4},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Ernst, Marc O. and Bülthoff, Heinrich H.},
	urldate = {2019-01-22},
	date = {2004-04-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/FE43GBA2/Ernst and Bülthoff - 2004 - Merging the senses into a robust percept.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/2APF3MWT/S1364661304000385.html:text/html}
}

@article{jousmaki_parchment-skin_1998,
	title = {Parchment-skin illusion: sound-biased touch},
	volume = {8},
	issn = {09609822},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0960982298701204},
	doi = {10.1016/S0960-9822(98)70120-4},
	shorttitle = {Parchment-skin illusion},
	pages = {R190--R191},
	number = {6},
	journaltitle = {Current Biology},
	author = {Jousmäki, V and Hari, R},
	urldate = {2019-01-22},
	date = {1998-03},
	langid = {english},
	file = {Jousmäki and Hari - 1998 - Parchment-skin illusion sound-biased touch.pdf:/home/felix/Zotero/storage/2SBIQBJ8/Jousmäki and Hari - 1998 - Parchment-skin illusion sound-biased touch.pdf:application/pdf}
}

@online{noauthor_hearing_nodate,
	title = {Hearing lips and seeing voices {\textbar} Nature},
	url = {https://www.nature.com/articles/264746a0},
	urldate = {2019-01-22},
	file = {Hearing lips and seeing voices | Nature:/home/felix/Zotero/storage/LNFQNMMY/264746a0.html:text/html}
}

@article{mcgurk_hearing_1976,
	title = {Hearing lips and seeing voices},
	volume = {264},
	rights = {1976 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/264746a0},
	doi = {10.1038/264746a0},
	abstract = {{MOST} verbal communication occurs in contexts where the listener can see the speaker as well as hear him. However, speech perception is normally regarded as a purely auditory process. The study reported here demonstrates a previously unrecognised influence of vision upon speech perception. It stems from an observation that, on being shown a film of a young woman's talking head, in which repeated utterances of the syllable [ba] had been dubbed on to lip movements for [ga], normal adults reported hearing [da]. With the reverse dubbing process, a majority reported hearing [bagba] or [gaba]. When these subjects listened to the soundtrack from the film, without visual input, or when they watched untreated film, they reported the syllables accurately as repetitions of [ba] or [ga]. Subsequent replications confirm the reliability of these findings; they have important implications for the understanding of speech perception.},
	pages = {746--748},
	number = {5588},
	journaltitle = {Nature},
	author = {Mcgurk, Harry and Macdonald, John},
	urldate = {2019-01-22},
	date = {1976-12},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/IEHPBFSG/264746a0.html:text/html}
}

@article{rowland_temporal_2008,
	title = {Temporal profiles of response enhancement in multisensory integration},
	volume = {2},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.01.033.2008/full},
	doi = {10.3389/neuro.01.033.2008},
	abstract = {Animals have evolved multiple senses that transduce different forms of energy as a way of increasing their sensitivity to environmental events. Each sense provides a unique and independent perspective on the world, and very often a single event stimulates several of them. In order to make best use of the available information, the brain has also evolved the capacity to integrate information across the senses (\&ldquo;multisensory integration\&rdquo;). This facilitates the detection, localization, and identification of a given event, and has obvious survival value for the individual and the species. Multisensory responses in the superior colliculus ({SC}) evidence shorter latencies and are more robust at their onset. This is the phenomenon of initial response enhancement in multisensory integration, which is believed to a real time fusion of information across the senses. The present paper reviews two recent reports describing how the timing and robustness of sensory responses changes as a consequence of multisensory integration in the model system of the {SC}.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Rowland, Benjamin A. and Stein, Barry E.},
	urldate = {2019-01-22},
	date = {2008},
	keywords = {cross-modal, enhancement, latency, multisensory, superior colliculus, timing},
	file = {Full Text PDF:/home/felix/Zotero/storage/Z8C786K6/Rowland and Stein - 2008 - Temporal profiles of response enhancement in multi.pdf:application/pdf}
}

@article{champoux_early-_2011,
	title = {Early- and Late-Onset Blindness Both Curb Audiotactile Integration on the Parchment-Skin Illusion},
	volume = {22},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797610391099},
	doi = {10.1177/0956797610391099},
	abstract = {It has been shown that congenital blindness can lead to anomalies in the integration of auditory and tactile information, at least under certain conditions. In the present study, we used the parchment-skin illusion, a robust illustration of sound-biased perception of touch based on changes in frequency, to investigate the specificities of audiotactile interactions in early- and late-onset blind individuals. Blind individuals in both groups did not experience any illusory change in tactile perception when the frequency of the auditory signal was modified, whereas sighted individuals consistently experienced the illusion. This demonstration that blind individuals had reduced susceptibility to an auditory-tactile illusion suggests either that vision is necessary for the establishment of audiotactile interactions or that auditory and tactile information can be processed more independently in blind individuals than in sighted individuals. In addition, the results obtained in late-onset blind participants suggest that visual input may play a role in the maintenance of audiotactile integration.},
	pages = {19--25},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Champoux, François and Collignon, Olivier and Bacon, Benoit A. and Lepore, Franco and Zatorre, Robert J. and Théoret, Hugo},
	urldate = {2019-01-22},
	date = {2011-01-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/Y7J93QMD/Champoux et al. - 2011 - Early- and Late-Onset Blindness Both Curb Audiotac.pdf:application/pdf}
}

@book{calvert_handbook_2004-1,
	title = {The Handbook of Multisensory Processes},
	isbn = {978-0-262-03321-3},
	abstract = {A reference work for the emerging field of multisensory integration, covering multidisciplinary research that goes beyond the traditional "sense-by-sense" approach and recognizes that perception is fundamentally a multisensory experience. This landmark reference work brings together for the first time in one volume the most recent research from different areas of the emerging field of multisensory integration. After many years of using a modality-specific "sense-by-sense" approach, researchers across different disciplines in neuroscience and psychology now recognize that perception is fundamentally a multisensory experience. To understand how the brain synthesizes information from the different senses, we must study not only how information from each sensory modality is decoded but also how this information interacts with the sensory processing taking place within other sensory channels. The findings cited in The Handbook of Multisensory Processes suggest that there are broad underlying principles that govern this interaction, regardless of the specific senses involved. The book is organized thematically into eight sections; each of the 55 chapters presents a state-of-the-art review of its topic by leading researchers in the field. The key themes addressed include multisensory contributions to perception in humans; whether the sensory integration involved in speech perception is fundamentally different from other kinds of multisensory integration; multisensory processing in the midbrain and cortex in model species, including rat, cat, and monkey; behavioral consequences of multisensory integration; modern neuroimaging techniques, including {EEG}, {PET}, and {fMRI}, now being used to reveal the many sites of multisensory processing in the brain; multisensory processes that require postnatal sensory experience to emerge, with examples from multiple species; brain specialization and possible equivalence of brain regions; and clinical studies of such breakdowns of normal sensory integration as brain damage and synesthesia.},
	pagetotal = {966},
	publisher = {{MIT} Press},
	author = {Calvert, Gemma and Spence, Charles and Spence, Department of Experimental Psychology Charles and Stein, Barry E. and Stein, Professor \{and\} Chair Barry E.},
	date = {2004},
	langid = {english},
	note = {Google-Books-{ID}: {CZS}\_yDoFV7AC},
	keywords = {Medical / Neuroscience, Psychology / Neuropsychology, Psychology / Physiological Psychology},
	file = {Calvert et al. - 2004 - The handbook of multisensory processes.pdf:/home/felix/Zotero/storage/XDFNCFN2/Calvert et al. - 2004 - The handbook of multisensory processes.pdf:application/pdf}
}

@collection{calvert_handbook_2004-2,
	location = {Cambridge, Mass},
	title = {The handbook of multisensory processes},
	isbn = {978-0-262-03321-3},
	pagetotal = {915},
	publisher = {{MIT} Press},
	editor = {Calvert, Gemma and Spence, Charles and Stein, Barry E.},
	date = {2004},
	langid = {english},
	keywords = {Perception, Handbooks, manuals, etc, Intersensory effects, Physiological aspects Research, Research, Senses and sensation}
}

@online{noauthor_violentyev:_nodate,
	title = {Violentyev: Touch-induced visual illusion - Google Scholar},
	url = {https://scholar.google.com/scholar_lookup?title=Touch-induced%20visual%20illusion&publication_year=2005&author=A.%20Violentyev&author=S.%20Shimojo&author=L.%20Shams#d=gs_cit&u=%2Fscholar%3Fq%3Dinfo%3ACWqjtqQHztcJ%3Ascholar.google.com%2F%26output%3Dcite%26scirp%3D0%26hl%3Dde},
	urldate = {2019-01-22},
	file = {Violentyev\: Touch-induced visual illusion - Google Scholar:/home/felix/Zotero/storage/GF6MFC9Q/scholar_lookup.html:text/html}
}

@article{shams_crossmodal_2010,
	title = {Crossmodal influences on visual perception},
	volume = {7},
	issn = {1571-0645},
	url = {http://www.sciencedirect.com/science/article/pii/S1571064510000424},
	doi = {10.1016/j.plrev.2010.04.006},
	abstract = {Vision is generally considered the dominant sensory modality; self-contained and independent of other senses. In this article, we will present recent results that contradict this view, and show that visual perception can be strongly altered by sound and touch, and such alterations can occur even at early stages of processing, as early as primary visual cortex. We will first review the behavioral evidence demonstrating modulation of visual perception by other modalities. As extreme examples of such modulations, we will describe two visual illusions induced by sound, and a visual illusion induced by touch. Next, we will discuss studies demonstrating modulation of activity in visual areas by stimulation of other modalities, and discuss possible pathways that could underpin such interactions. This will be followed by a discussion of how crossmodal interactions can affect visual learning and adaptation. We will review several studies showing crossmodal effects on visual learning. We will conclude with a discussion of computational principles governing these crossmodal interactions, and review several recent studies that demonstrate that these interactions are statistically optimal.},
	pages = {269--284},
	number = {3},
	journaltitle = {Physics of Life Reviews},
	shortjournal = {Physics of Life Reviews},
	author = {Shams, Ladan and Kim, Robyn},
	urldate = {2019-01-22},
	date = {2010-09-01},
	keywords = {Multisensory integration, Multisensory perception, Visual learning, Visual perception},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/RCJVRWCD/Shams and Kim - 2010 - Crossmodal influences on visual perception.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/F6ZR4NDV/S1571064510000424.html:text/html}
}

@article{violentyev_touch-induced_nodate,
	title = {Touch-induced visual illusion},
	pages = {4},
	author = {Violentyev, Artem and Shimojo, Shinsuke and Shams, Ladan},
	langid = {english},
	file = {Violentyev et al. - Touch-induced visual illusion.pdf:/home/felix/Zotero/storage/KZAR87HB/Violentyev et al. - Touch-induced visual illusion.pdf:application/pdf}
}

@article{biederman_processing_1970,
	title = {Processing redundant information},
	volume = {83},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0028841},
	abstract = {When stimuli differing on 2 dimensions (size and brightness), either of which could furnish sufficient information for a correct response were presented to 40 undergraduates {RTs} were faster than when stimuli differed on only 1 dimension. This result held true even when individual differences in dimension preferences were taken into account. A model of parallel processing of the different dimensions is proposed and extended to M. I. Posner's (see 39:3) taxonomy of information-processing tasks. The model emphasizes S's ability to initiate a successive processing stage as soon as sufficient information for a correct response has been gathered. This ability enables S to capitalize on the variance of the times of the component processes by which the values of the different dimensions are determined. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {486--490},
	number = {3},
	journaltitle = {Journal of Experimental Psychology},
	author = {Biederman, Irving and Checkosky, Stephen F.},
	date = {1970},
	keywords = {Familiarity, Information, Models, Reaction Time, Size Discrimination},
	file = {Snapshot:/home/felix/Zotero/storage/AR3SM2T9/1970-07589-001.html:text/html}
}

@article{dykes_investigation_1978,
	title = {An investigation of the perceptual basis of redundancy gain and orthogonal interference for integral dimensions},
	volume = {23},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03214292},
	doi = {10.3758/BF03214292},
	abstract = {Redundancy gain and orthogonal interference for height and width were demonstrated in two experiments using a relative coding task with number of intertrial repetitions controlled. Orthogonal interference was shown to be perceptually based rather than simply an intertrial repetitions effect as suggested by Felfoldy (1974). These results from a relative coding task were discussed in terms of the previous multidimensional processing literature. It was concluded that Lockhead’s (1972t model has been applied too generally. An alternative model (a parallel, dimensional analysis stage followed by a stage in which dimensional information is integrated) was suggested.},
	pages = {36--42},
	number = {1},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Dykes, James R. and Cooper, Robert G.},
	urldate = {2019-01-23},
	date = {1978-01-01},
	langid = {english},
	keywords = {Dimensional Information, Psychological Space, Redundancy Gain, Response Interference, Stimulus Dimension},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/NYC5LTQJ/Dykes and Cooper - 1978 - An investigation of the perceptual basis of redund.pdf:application/pdf}
}

@article{gondan_multisensory_2005,
	title = {Multisensory processing in the redundant-target effect: A behavioral and event-related potential study},
	volume = {67},
	issn = {0031-5117, 1532-5962},
	url = {http://www.springerlink.com/index/10.3758/BF03193527},
	doi = {10.3758/BF03193527},
	shorttitle = {Multisensory processing in the redundant-target effect},
	pages = {713--726},
	number = {4},
	journaltitle = {Perception \& Psychophysics},
	author = {Gondan, Matthias and Niederhaus, Birgit and Rösler, Frank and Röder, Brigitte},
	urldate = {2019-01-23},
	date = {2005-05},
	langid = {english},
	file = {Gondan et al. - 2005 - Multisensory processing in the redundant-target ef.pdf:/home/felix/Zotero/storage/54TVQZUC/Gondan et al. - 2005 - Multisensory processing in the redundant-target ef.pdf:application/pdf}
}

@article{giard_auditory-visual_1999,
	title = {Auditory-Visual Integration during Multimodal Object Recognition in Humans: A Behavioral and Electrophysiological Study},
	volume = {11},
	issn = {0898-929X},
	url = {https://www.mitpressjournals.org/doi/10.1162/089892999563544},
	doi = {10.1162/089892999563544},
	shorttitle = {Auditory-Visual Integration during Multimodal Object Recognition in Humans},
	abstract = {The aim of this study was (1) to provide behavioral evidence for multimodal feature integration in an object recognition task in humans and (2) to characterize the processing stages and the neural structures where multisensory interactions take place. Event-related potentials ({ERPs}) were recorded from 30 scalp electrodes while subjects performed a forced-choice reaction-time categorization task: At each trial, the subjects had to indicate which of two objects was presented by pressing one of two keys. The two objects were defined by auditory features alone, visual features alone, or the combination of auditory and visual features. Subjects were more accurate and rapid at identifying multimodal than unimodal objects. Spatiotemporal analysis of {ERPs} and scalp current densities revealed several auditory-visual interaction components temporally, spatially, and functionally distinct before 200 msec poststimulus. The effects observed were (1) in visual areas, new neural activities (as early as 40 msec poststimulus) and modulation (amplitude decrease) of the N185 wave to unimodal visual stimulus, (2) in the auditory cortex, modulation (amplitude increase) of subcomponents of the unimodal auditory N1 wave around 90 to 110 msec, and (3) new neural activity over the right fronto-temporal area (140 to 165 msec). Furthermore, when the subjects were separated into two groups according to their dominant modality to perform the task in unimodal conditions (shortest reaction time criteria), the integration effects were found to be similar for the two groups over the nonspecific fronto-temporal areas, but they clearly differed in the sensory-specific cortices, affecting predominantly the sensory areas of the nondominant modality. Taken together, the results indicate that multisensory integration is mediated by flexible, highly adaptive physiological processes that can take place very early in the sensory processing chain and operate in both sensory-specific and nonspecific cortical structures in different ways.},
	pages = {473--490},
	number = {5},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Giard, M. H. and Peronnet, F.},
	urldate = {2019-01-23},
	date = {1999-09-01},
	file = {Snapshot:/home/felix/Zotero/storage/RC8J9CQ3/089892999563544.html:text/html}
}

@article{giard_auditory-visual_1999-1,
	title = {Auditory-Visual Integration during Multimodal Object Recognition in Humans: A Behavioral and Electrophysiological Study},
	volume = {11},
	issn = {0898-929X, 1530-8898},
	url = {http://www.mitpressjournals.org/doi/10.1162/089892999563544},
	doi = {10.1162/089892999563544},
	shorttitle = {Auditory-Visual Integration during Multimodal Object Recognition in Humans},
	pages = {473--490},
	number = {5},
	journaltitle = {Journal of Cognitive Neuroscience},
	author = {Giard, M. H. and Peronnet, F.},
	urldate = {2019-01-23},
	date = {1999-09},
	langid = {english},
	file = {Giard and Peronnet - 1999 - Auditory-Visual Integration during Multimodal Obje.pdf:/home/felix/Zotero/storage/A68JGISK/Giard and Peronnet - 1999 - Auditory-Visual Integration during Multimodal Obje.pdf:application/pdf}
}

@article{stein_multisensory_2008,
	title = {Multisensory integration: current issues from the perspective of the single neuron},
	volume = {9},
	rights = {2008 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn2331},
	doi = {10.1038/nrn2331},
	shorttitle = {Multisensory integration},
	abstract = {For thousands of years science philosophers have been impressed by how effectively the senses work together to enhance the salience of biologically meaningful events. However, they really had no idea how this was accomplished. Recent insights into the underlying physiological mechanisms reveal that, in at least one circuit, this ability depends on an intimate dialogue among neurons at multiple levels of the neuraxis; this dialogue cannot take place until long after birth and might require a specific kind of experience. Understanding the acquisition and usage of multisensory integration in the midbrain and cerebral cortex of mammals has been aided by a multiplicity of approaches. Here we examine some of the fundamental advances that have been made and some of the challenging questions that remain.},
	pages = {255--266},
	number = {4},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Stein, Barry E. and Stanford, Terrence R.},
	urldate = {2019-01-23},
	date = {2008-04},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/6VC5M7KY/nrn2331.html:text/html}
}

@article{keil_neural_2018,
	title = {Neural Oscillations Orchestrate Multisensory Processing},
	volume = {24},
	issn = {1073-8584},
	url = {https://doi.org/10.1177/1073858418755352},
	doi = {10.1177/1073858418755352},
	abstract = {At any given moment, we receive input through our different sensory systems, and this information needs to be processed and integrated. Multisensory processing requires the coordinated activity of distinct cortical areas. Key mechanisms implicated in these processes include local neural oscillations and functional connectivity between distant cortical areas. Evidence is now emerging that neural oscillations in distinct frequency bands reflect different mechanisms of multisensory processing. Moreover, studies suggest that aberrant neural oscillations contribute to multisensory processing deficits in clinical populations, such as schizophrenia. In this article, we review recent literature on the neural mechanisms underlying multisensory processing, focusing on neural oscillations. We derive a framework that summarizes findings on (1) stimulus-driven multisensory processing, (2) the influence of top-down information on multisensory processing, and (3) the role of predictions for the formation of multisensory perception. We propose that different frequency band oscillations subserve complementary mechanisms of multisensory processing. These processes can act in parallel and are essential for multisensory processing.},
	pages = {609--626},
	number = {6},
	journaltitle = {The Neuroscientist},
	shortjournal = {Neuroscientist},
	author = {Keil, Julian and Senkowski, Daniel},
	urldate = {2019-01-23},
	date = {2018-12-01},
	langid = {english}
}

@article{rowland_multisensory_2007,
	title = {Multisensory Integration Shortens Physiological Response Latencies},
	volume = {27},
	rights = {Copyright © 2007 Society for Neuroscience 0270-6474/07/275879-06\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/27/22/5879},
	doi = {10.1523/JNEUROSCI.4986-06.2007},
	abstract = {Individual superior colliculus ({SC}) neurons integrate information from multiple sensory sources to enhance their physiological response. The response of an {SC} neuron to a cross-modal stimulus combination can not only exceed the best component unisensory response but can also exceed their arithmetic sum (i.e., superadditivity). The present experiments were designed to investigate the temporal profile of multisensory integration in this model system. We found that cross-modal stimuli frequently shortened physiological response latencies (mean shift, 6.2 ms) and that response enhancement was greatest in the initial phase of the response (the phenomenon of initial response enhancement). The vast majority of the responses studied evidenced superadditive computations, most often at the beginning of the multisensory response.},
	pages = {5879--5884},
	number = {22},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Rowland, Benjamin A. and Quessy, Stephan and Stanford, Terrence R. and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {2007-05-30},
	langid = {english},
	pmid = {17537958},
	keywords = {cross-modal, latency, multisensory, superior colliculus, audition, vision},
	file = {Full Text PDF:/home/felix/Zotero/storage/8T942IXT/Rowland et al. - 2007 - Multisensory Integration Shortens Physiological Re.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/MKYCYUJC/tab-figures-data.html:text/html}
}

@article{rowland_model_2014,
	title = {A model of the temporal dynamics of multisensory enhancement},
	volume = {41},
	issn = {0149-7634},
	url = {http://www.sciencedirect.com/science/article/pii/S014976341300300X},
	doi = {10.1016/j.neubiorev.2013.12.003},
	series = {Multisensory integration, sensory substitution and visual rehabilitation},
	abstract = {The senses transduce different forms of environmental energy, and the brain synthesizes information across them to enhance responses to salient biological events. We hypothesize that the potency of multisensory integration is attributable to the convergence of independent and temporally aligned signals derived from cross-modal stimulus configurations onto multisensory neurons. The temporal profile of multisensory integration in neurons of the deep superior colliculus ({SC}) is consistent with this hypothesis. The responses of these neurons to visual, auditory, and combinations of visual–auditory stimuli reveal that multisensory integration takes place in real-time; that is, the input signals are integrated as soon as they arrive at the target neuron. Interactions between cross-modal signals may appear to reflect linear or nonlinear computations on a moment-by-moment basis, the aggregate of which determines the net product of multisensory integration. Modeling observations presented here suggest that the early nonlinear components of the temporal profile of multisensory integration can be explained with a simple spiking neuron model, and do not require more sophisticated assumptions about the underlying biology. A transition from nonlinear “super-additive” computation to linear, additive computation can be accomplished via scaled inhibition. The findings provide a set of design constraints for artificial implementations seeking to exploit the basic principles and potency of biological multisensory integration in contexts of sensory substitution or augmentation.},
	pages = {78--84},
	journaltitle = {Neuroscience \& Biobehavioral Reviews},
	shortjournal = {Neuroscience \& Biobehavioral Reviews},
	author = {Rowland, Benjamin A. and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {2014-04-01},
	keywords = {Multisensory, Cross-modal, Enhancement, Modeling, Temporal dynamics},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/YKL7GAWG/Rowland and Stein - 2014 - A model of the temporal dynamics of multisensory e.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/8HTJVCH4/S014976341300300X.html:text/html}
}

@article{stein_multisensory_2008-1,
	title = {Multisensory integration: current issues from the perspective of the single neuron},
	volume = {9},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn2331},
	doi = {10.1038/nrn2331},
	shorttitle = {Multisensory integration},
	abstract = {For thousands of years science philosophers have been impressed by how effectively the senses work together to enhance the salience of biologically meaningful events. However, they really had no idea how this was accomplished. Recent insights into the underlying physiological mechanisms reveal that, in at least one circuit, this ability depends on an intimate dialogue among neurons at multiple levels of the neuraxis; this dialogue cannot take place until long after birth and might require a specific kind of experience. Understanding the acquisition and usage of multisensory integration in the midbrain and cerebral cortex of mammals has been aided by a multiplicity of approaches. Here we examine some of the fundamental advances that have been made and some of the challenging questions that remain.},
	pages = {255--266},
	number = {4},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Stein, Barry E. and Stanford, Terrence R.},
	urldate = {2019-01-23},
	date = {2008-04},
	langid = {english},
	file = {Stein and Stanford - 2008 - Multisensory integration current issues from the .pdf:/home/felix/Zotero/storage/QBMJVZNG/Stein and Stanford - 2008 - Multisensory integration current issues from the .pdf:application/pdf}
}

@article{meredith_interactions_1983,
	title = {Interactions among converging sensory inputs in the superior colliculus},
	volume = {221},
	rights = {© 1983},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/221/4608/389},
	doi = {10.1126/science.6867718},
	abstract = {The responses of superior colliculus cells to a given sensory stimulus were influenced by the presence or absence of other sensory cues. By pooling sensory inputs, many superior colliculus cells seem to amplify the effects of subtle environmental cues in certain conditions, whereas in others, responses to normally effective stimuli can be blocked. The observations illustrate the dynamic, interactive nature of the multisensory inputs which characterize the deeper laminae of the superior colliculus.},
	pages = {389--391},
	number = {4608},
	journaltitle = {Science},
	author = {Meredith, M. A. and Stein, B. E.},
	urldate = {2019-01-23},
	date = {1983-07-22},
	langid = {english},
	pmid = {6867718},
	file = {Full Text PDF:/home/felix/Zotero/storage/4JNPPQ5L/Meredith and Stein - 1983 - Interactions among converging sensory inputs in th.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/XJISYDYV/389.html:text/html}
}

@article{rowland_multisensory_2007-1,
	title = {Multisensory Integration Shortens Physiological Response Latencies},
	volume = {27},
	rights = {Copyright © 2007 Society for Neuroscience 0270-6474/07/275879-06\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/27/22/5879},
	doi = {10.1523/JNEUROSCI.4986-06.2007},
	abstract = {Individual superior colliculus ({SC}) neurons integrate information from multiple sensory sources to enhance their physiological response. The response of an {SC} neuron to a cross-modal stimulus combination can not only exceed the best component unisensory response but can also exceed their arithmetic sum (i.e., superadditivity). The present experiments were designed to investigate the temporal profile of multisensory integration in this model system. We found that cross-modal stimuli frequently shortened physiological response latencies (mean shift, 6.2 ms) and that response enhancement was greatest in the initial phase of the response (the phenomenon of initial response enhancement). The vast majority of the responses studied evidenced superadditive computations, most often at the beginning of the multisensory response.},
	pages = {5879--5884},
	number = {22},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Rowland, Benjamin A. and Quessy, Stephan and Stanford, Terrence R. and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {2007-05-30},
	langid = {english},
	pmid = {17537958},
	keywords = {cross-modal, latency, multisensory, superior colliculus, audition, vision},
	file = {Full Text PDF:/home/felix/Zotero/storage/THSCI47S/Rowland et al. - 2007 - Multisensory Integration Shortens Physiological Re.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/TPQ9ET89/5879.html:text/html}
}

@article{sprague_role_1965,
	title = {The role of the superior colliculus in visually guided behavior},
	volume = {11},
	issn = {0014-4886},
	url = {http://www.sciencedirect.com/science/article/pii/0014488665900269},
	doi = {10.1016/0014-4886(65)90026-9},
	abstract = {Unilateral lesions in the superior colliculus of the cat which do not involve the tegmentum result in two major behavioral signs: an homonymous field defect with complete or relative neglect of stimuli in the visual fields contralateral to the lesion, seen particularly in extinction of the contralateral response when rival stimuli are used; and a motor deficit in appropriate movements of eyes, head and body, expressed in ipsiversive forced circling and an heightened compulsive response to ipsilateral stimuli. These signs are not related to changes in pupils or in accommodation. Associated with these are abnormal responses to contralateral acoustic, tactile and sometimes nociceptive stimuli, appearing primarily as inappropriate localization of the stimuli rather than as changes in sensory threshold. The two major deficits are separable by means of smaller lesions in various parts of the afferent and efferent tectal pathways. Lesions of the tectospinal tract result in the motor deficit without the visual neglect. Involvement of the brachium of the superior colliculus and of parts of the tectothalamic system yield a contralateral visual neglect without the motor deficit. Bilateral collicular lesions result in apparent initial blindness and enduring deficits in visual following, in localization of stationary stimulus objects, in a disability to look up and in poor localization to tactile stimulation of the hind legs. We conclude that the functions of the superior colliculus include that of visual attention and perception as well as the classically accepted control of the movements of head and eyes.},
	pages = {115--146},
	number = {1},
	journaltitle = {Experimental Neurology},
	shortjournal = {Experimental Neurology},
	author = {Sprague, James M. and Meikle, Thomas H.},
	urldate = {2019-01-23},
	date = {1965-01-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/XVPTRBQU/Sprague and Meikle - 1965 - The role of the superior colliculus in visually gu.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/6JYYD3UF/0014488665900269.html:text/html}
}

@article{wallace_multisensory_1998,
	title = {Multisensory Integration in the Superior Colliculus of the Alert Cat},
	volume = {80},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.1998.80.2.1006},
	doi = {10.1152/jn.1998.80.2.1006},
	abstract = {Wallace, Mark T., M. Alex Meredith, and Barry E. Stein. Multisensory integration in the superior colliculus of the alert cat. J. Neurophysiol. 80: 1006–1010, 1998. The modality convergence patterns, sensory response properties, and principles governing multisensory integration in the superior colliculus ({SC}) of the alert cat were found to have fundamental similarities to those in anesthetized animals. Of particular interest was the observation that, in a manner indistinguishable from the anesthetized animal, combinations of two different sensory stimuli significantly enhanced the responses of {SC} neurons above those evoked by either unimodal stimulus. These observations are consistent with the speculation that there is a functional link among multisensory integration in individual {SC} neurons and cross-modality attentive and orientation behaviors.},
	pages = {1006--1010},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Wallace, Mark T. and Meredith, M. Alex and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {1998-08-01},
	file = {Snapshot:/home/felix/Zotero/storage/GTKMBS3X/jn.1998.80.2.html:text/html;Wallace et al. - 1998 - Multisensory Integration in the Superior Colliculu.pdf:/home/felix/Zotero/storage/LGGYYMSH/Wallace et al. - 1998 - Multisensory Integration in the Superior Colliculu.pdf:application/pdf}
}

@article{altman_fiber_1961,
	title = {Fiber projections of the superior colliculus in the cat},
	volume = {116},
	rights = {Copyright © 1961 The Wistar Institute of Anatomy and Biology},
	issn = {1096-9861},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.901160206},
	doi = {10.1002/cne.901160206},
	pages = {157--177},
	number = {2},
	journaltitle = {Journal of Comparative Neurology},
	author = {Altman, Joseph and Carpenter, Malcolm B.},
	urldate = {2019-01-23},
	date = {1961},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/VXIEWEB9/cne.html:text/html}
}

@article{stein_neurons_1988,
	title = {Neurons and behavior: the same rules of multisensory integration apply},
	volume = {448},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/0006899388912760},
	doi = {10.1016/0006-8993(88)91276-0},
	shorttitle = {Neurons and behavior},
	abstract = {Combinations of different sensory cues (e.g. auditory and visual) that are coincident in space enhance the responses of multisensory superior colliculus neurons, while the responses of these same neurons are depressed if the stimuli are separated in space. Using a behavioral paradigm modeled after that used in physiological studies, the present experiments demonstrate that the rules governing multisensory integration at the level of the single neuron also predict the responses to these stimuli in the intact behaving animal.},
	pages = {355--358},
	number = {2},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Stein, Barry E. and Scott Huneycutt, W. and Alex Meredith, M.},
	urldate = {2019-01-23},
	date = {1988-05-17},
	keywords = {Audition, Vision, Behavior, Neurophysiology, Orientation},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/XX63D55A/Stein et al. - 1988 - Neurons and behavior the same rules of multisenso.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/VACBKKKR/0006899388912760.html:text/html}
}

@article{jiang_multisensory_2007,
	title = {Multisensory Orientation Behavior Is Disrupted by Neonatal Cortical Ablation},
	volume = {97},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00591.2006},
	doi = {10.1152/jn.00591.2006},
	abstract = {The integration of visual and auditory information can significantly amplify the sensory responses of superior colliculus ({SC}) neurons and the behaviors that depend on them. This response amplification depends on the development of {SC} inputs that are derived from two regions of cortex: the anterior ectosylvian sulcus ({AES}) and the rostral lateral suprasylvian sulcus ({rLS}). Neonatal ablation of these cortico-collicular areas has been shown to disrupt the development of the multisensory enhancement capabilities of {SC} neurons and the present results demonstrate that it also precludes the development of the normal multisensory enhancements in orientation behavior. Animals with neonatal ablation of {AES} and {rLS} were tested at maturity and found unable to benefit from the combination of visual and auditory cues in their efforts to localize targets in contralesional space. In contrast, their ipsilesional multisensory orientation capabilities were indistinguishable from those of normal animals. However, when only one of these cortical areas was removed during early life, later behavioral consequences were negligible. Whether similar compensatory processes would occur in adult animals remains to be determined. These observations, coupled with those from previous studies, also suggest that a surprisingly high proportion of {SC} neurons capable of multisensory integration must be present for orientation behavior benefits to be realized. Compensatory mechanisms can achieve this if early lesions spare either {AES} or {rLS}, but even the impressive plasticity of the neonatal brain cannot compensate for the early loss of both of them.},
	pages = {557--562},
	number = {1},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Jiang, Wan and Jiang, Huai and Rowland, Benjamin A. and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {2007-01-01},
	file = {Snapshot:/home/felix/Zotero/storage/YUSMYDFR/jn.00591.html:text/html}
}

@article{burnett_superior_2004,
	title = {Superior colliculus lesions preferentially disrupt multisensory orientation},
	volume = {124},
	issn = {0306-4522},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452203009382},
	doi = {10.1016/j.neuroscience.2003.12.026},
	abstract = {The general involvement of the superior colliculus ({SC}) in orientation behavior and the striking parallels between the multisensory responses of {SC} neurons and overt orientation behaviors have led to assumptions that these neural and behavioral changes are directly linked. However, deactivation of two areas of cortex which also contain multisensory neurons, the anterior ectosylvian sulcus and rostral lateral suprasylvian sulcus have been shown to eliminate multisensory orientation behaviors, suggesting that this behavior may not involve the {SC}. To determine whether the {SC} contributes to this behavior, cats were tested in a multisensory (i.e. visual-auditory) orientation task before and after excitotoxic lesions of the {SC}. For unilateral {SC} lesions, modality-specific (i.e. visual or auditory) orientation behaviors had returned to pre-lesion levels after several weeks of recovery. In contrast, the enhancements and depressions in behavior normally seen with multisensory stimuli were severely compromised in the contralesional hemifield. No recovery of these behaviors was observed within the 6 month testing period. Immunohistochemical labeling of the {SC} revealed a preferential loss of parvalbumin-immunoreactive pyramidal neurons in the intermediate layers, a presumptive multisensory population that targets premotor areas of the brainstem and spinal cord. These results highlight the importance of the {SC} for multisensory behaviors, and suggest that the multisensory orientation deficits produced by cortical lesions are a result of the loss of cortical influences on multisensory {SC} neurons.},
	pages = {535--547},
	number = {3},
	journaltitle = {Neuroscience},
	shortjournal = {Neuroscience},
	author = {Burnett, L. R and Stein, B. E and Chaponis, D and Wallace, M. T},
	urldate = {2019-01-23},
	date = {2004-01-01},
	keywords = {auditory, cross-modal, visual, corticotectal, excitotoxins, ibotenic acid, lesions},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/J7DTSZWV/Burnett et al. - 2004 - Superior colliculus lesions preferentially disrupt.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/KXTQ4ZNG/S0306452203009382.html:text/html}
}

@article{jiang_two_2002,
	title = {Two Corticotectal Areas Facilitate Multisensory Orientation Behavior},
	volume = {14},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/089892902760807230},
	doi = {10.1162/089892902760807230},
	abstract = {It had previously been shown that influences from two cortical areas, the anterior ectosylvian sulcus ({AES}) and the rostral lateral suprasylvian sulcus ({rLS}), play critical roles in rendering superior colliculus ({SC}) neurons capable of synthesizing their cross-modal inputs. The present studies examined the consequences of selectively eliminating these cortical influences on {SC}-mediated orientation responses to cross-modal stimuli. Cats were trained to orient to a low-intensity modality-specific cue (visual) in the presence or absence of a neutral cue from another modality (auditory). The visual target could appear at various locations within 45° of the midline, and the stimulus effectiveness was varied to yield an average of correct orientation responses of approximately 45\%. Response enhancement and depression were observed when the auditory cue was coupled with the target stimulus: A substantially enhanced probability in correct responses was evident when the cross-modal stimuli were spatially coincident, and a substantially decreased response probability was obtained when the stimuli were spatially disparate. Cryogenic blockade of either {AES} or {rLS} disrupted these behavioral effects, thereby eliminating the enhanced performance in response to spatially coincident cross-modal cues and degrading the depressed performance in response to spatially disparate cross-modal cues. These disruptive effects on targets contralateral to the deactivated cortex were restricted to multisensory interactive processes. Orientation to modality-specific targets was unchanged. Furthermore, the pattern of orientation errors was unaffected by cortical deactivation. These data bear striking similarities to the effects of {AES} and {rLS} deactivation on multisensory integration at the level of individual {SC} neurons. Presumably, eliminating the critical influences from {AES} or {rLS} cortex disrupts {SC} multisensory synthesis that, in turn, disables {SC}-mediated multisensory orientation behaviors.},
	pages = {1240--1255},
	number = {8},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Jiang, Wan and Jiang, Huai and Stein, Barry E.},
	urldate = {2019-01-23},
	date = {2002-11-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/9IQ6GCTX/Jiang et al. - 2002 - Two Corticotectal Areas Facilitate Multisensory Or.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/CSRV392G/089892902760807230.html:text/html}
}

@article{bell_crossmodal_2005,
	title = {Crossmodal Integration in the Primate Superior Colliculus Underlying the Preparation and Initiation of Saccadic Eye Movements},
	volume = {93},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.01214.2004},
	doi = {10.1152/jn.01214.2004},
	abstract = {Saccades to combined audiovisual stimuli often have reduced saccadic reaction times ({SRTs}) compared with those to unimodal stimuli. Neurons in the intermediate/deep layers of the superior colliculus ({dSC}) are capable of integrating converging sensory inputs to influence the time to saccade initiation. To identify how neural processing in the {dSC} contributes to reducing {SRTs} to audiovisual stimuli, we recorded activity from {dSC} neurons while monkeys generated saccades to visual or audiovisual stimuli. To evoke crossmodal interactions of varying strength, we used auditory and visual stimuli of different intensities, presented either in spatial alignment or to opposite hemifields. Spatially aligned audiovisual stimuli evoked the shortest {SRTs}. In the case of low-intensity stimuli, the response to the auditory component of the aligned audiovisual target increased the activity preceding the response to the visual component, accelerating the onset of the visual response and facilitating the generation of shorter-latency saccades. In the case of high-intensity stimuli, the auditory and visual responses occurred much closer together in time and so there was little opportunity for the auditory stimulus to influence previsual activity. Instead, the reduction in {SRT} for high-intensity, aligned audiovisual stimuli was correlated with increased premotor activity (activity after visual burst but preceding saccade-aligned burst). These data provide a link between changes in neural activity related to stimulus modality with changes in behavior. They further demonstrate how crossmodal interactions are not limited to the initial sensory activity but can also influence premotor activity in the {SC}.},
	pages = {3659--3673},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Bell, Andrew H. and Meredith, M. Alex and Van Opstal, A. John and Munoz, Douglas P.},
	urldate = {2019-01-23},
	date = {2005-06-01},
	file = {Snapshot:/home/felix/Zotero/storage/N9BX4S89/jn.01214.html:text/html}
}

@article{wallace_integration_1992,
	title = {Integration of multiple sensory modalities in cat cortex},
	volume = {91},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/BF00227844},
	doi = {10.1007/BF00227844},
	abstract = {{SummaryThe} results of this study show that the different receptive fields of multisensory neurons in the cortex of the cat anterior ectosylvian sulcus ({AES}) were in spatial register, and it is this register that determined the manner in which these neurons integrated multiple sensory stimuli. The functional properties of multisensory neurons in {AES} cortex bore fundamental similarities to those in other cortical and subcortical structures. These constancies in the principles of multisensory integration are likely to provide a basis for spatial coherence in information processing throughout the nervous system.},
	pages = {484--488},
	number = {3},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Wallace, Mark T. and Meredith, M. Alex and Stein, Barry E.},
	urldate = {2019-01-24},
	date = {1992-11-01},
	langid = {english},
	keywords = {Somatosensory, Visual, Multisensory integration, Anterior ectosylvian sulcus, Auditory},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/YXYIDX5L/Wallace et al. - 1992 - Integration of multiple sensory modalities in cat .pdf:application/pdf}
}

@article{ghazanfar_multisensory_2005,
	title = {Multisensory Integration of Dynamic Faces and Voices in Rhesus Monkey Auditory Cortex},
	volume = {25},
	rights = {Copyright © 2005 Society for Neuroscience 0270-6474/05/255004-09.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/25/20/5004},
	doi = {10.1523/JNEUROSCI.0799-05.2005},
	abstract = {In the social world, multiple sensory channels are used concurrently to facilitate communication. Among human and nonhuman primates, faces and voices are the primary means of transmitting social signals (Adolphs, 2003; Ghazanfar and Santos, 2004). Primates recognize the correspondence between species-specific facial and vocal expressions (Massaro, 1998; Ghazanfar and Logothetis, 2003; Izumi and Kojima, 2004), and these visual and auditory channels can be integrated into unified percepts to enhance detection and discrimination. Where and how such communication signals are integrated at the neural level are poorly understood. In particular, it is unclear what role “unimodal” sensory areas, such as the auditory cortex, may play. We recorded local field potential activity, the signal that best correlates with human imaging and event-related potential signals, in both the core and lateral belt regions of the auditory cortex in awake behaving rhesus monkeys while they viewed vocalizing conspecifics. We demonstrate unequivocally that the primate auditory cortex integrates facial and vocal signals through enhancement and suppression of field potentials in both the core and lateral belt regions. The majority of these multisensory responses were specific to face/voice integration, and the lateral belt region shows a greater frequency of multisensory integration than the core region. These multisensory processes in the auditory cortex likely occur via reciprocal interactions with the superior temporal sulcus.},
	pages = {5004--5012},
	number = {20},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Ghazanfar, Asif A. and Maier, Joost X. and Hoffman, Kari L. and Logothetis, Nikos K.},
	urldate = {2019-01-24},
	date = {2005-05-18},
	langid = {english},
	pmid = {15901781},
	keywords = {bimodal, crossmodal, speech, superior temporal sulcus, temporal lobe, vocalization},
	file = {Full Text PDF:/home/felix/Zotero/storage/5XSC4LNW/Ghazanfar et al. - 2005 - Multisensory Integration of Dynamic Faces and Voic.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/B3AH9PQR/5004.html:text/html}
}

@article{ghazanfar_is_2006,
	title = {Is neocortex essentially multisensory?},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306001045},
	doi = {10.1016/j.tics.2006.04.008},
	abstract = {Although sensory perception and neurobiology are traditionally investigated one modality at a time, real world behaviour and perception are driven by the integration of information from multiple sensory sources. Mounting evidence suggests that the neural underpinnings of multisensory integration extend into early sensory processing. This article examines the notion that neocortical operations are essentially multisensory. We first review what is known about multisensory processing in higher-order association cortices and then discuss recent anatomical and physiological findings in presumptive unimodal sensory areas. The pervasiveness of multisensory influences on all levels of cortical processing compels us to reconsider thinking about neural processing in unisensory terms. Indeed, the multisensory nature of most, possibly all, of the neocortex forces us to abandon the notion that the senses ever operate independently during real-world cognition.},
	pages = {278--285},
	number = {6},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Ghazanfar, Asif A. and Schroeder, Charles E.},
	urldate = {2019-01-24},
	date = {2006-06-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/9MBND54M/Ghazanfar and Schroeder - 2006 - Is neocortex essentially multisensory.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/WFWI9LCH/S1364661306001045.html:text/html}
}

@article{schroeder_timing_2002,
	title = {The timing and laminar profile of converging inputs to multisensory areas of the macaque neocortex},
	volume = {14},
	issn = {0926-6410},
	url = {http://www.sciencedirect.com/science/article/pii/S0926641002000733},
	doi = {10.1016/S0926-6410(02)00073-3},
	series = {Multisensory Proceedings},
	abstract = {Two fundamental requirements for multisensory integration are convergence of unisensory (e.g. visual and auditory) inputs and temporal alignment of the neural responses to convergent inputs. We investigated the anatomic mechanisms of multisensory convergence by examining three areas in which convergence occurs, posterior auditory association cortex, superior temporal polysensory area ({STP}) and ventral intraparietal sulcus area ({VIP}). The first of these was recently shown to be a site of multisensory convergence and the latter two are more well known as ‘classic’ multisensory regions. In each case, we focused on defining the laminar profile of response to the unisensory inputs. This information is useful because two major types of connection, feedforward and feedback, have characteristic differences in laminar termination patterns, which manifest physiologically. In the same multisensory convergence areas we also examined the timing of the unisensory inputs using the same standardized stimuli across all recordings. Our findings indicate that: (1) like somatosensory input [J. Neurophysiol., 85 (2001) 1322], visual input is available at very early stages of auditory processing, (2) convergence occurs through feedback, as well as feedforward anatomical projections and (3) input timing may be an asset, as well as a constraint in multisensory processing.},
	pages = {187--198},
	number = {1},
	journaltitle = {Cognitive Brain Research},
	shortjournal = {Cognitive Brain Research},
	author = {Schroeder, Charles E and Foxe, John J},
	urldate = {2019-01-24},
	date = {2002-06-01},
	keywords = {Multisensory, Current source density, {ERP}, Feedback, Temporal coincidence},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/N4GRRTNW/Schroeder and Foxe - 2002 - The timing and laminar profile of converging input.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/5PAZRBM4/S0926641002000733.html:text/html}
}

@article{park_integration_2010,
	title = {Integration of cross-modal emotional information in the human brain: An {fMRI} study},
	volume = {46},
	issn = {0010-9452},
	url = {http://www.sciencedirect.com/science/article/pii/S001094520800172X},
	doi = {10.1016/j.cortex.2008.06.008},
	shorttitle = {Integration of cross-modal emotional information in the human brain},
	abstract = {The interaction of information derived from the voice and facial expression of a speaker contributes to the interpretation of the emotional state of the speaker and to the formation of inferences about information that may have been merely implied in the verbal communication. Therefore, we investigated the brain processes responsible for the integration of emotional information originating from different sources. Although several studies have reported possible sites for integration, further investigation using a neutral emotional condition is required to locate emotion-specific networks. Using functional magnetic resonance imaging ({fMRI}), we explored the brain regions involved in the integration of emotional information from different modalities in comparison to those involved in integrating emotionally neutral information. There was significant activation in the superior temporal gyrus ({STG}); inferior frontal gyrus ({IFG}); and parahippocampal gyrus, including the amygdala, under the bimodal versus the unimodal condition, irrespective of the emotional content. We confirmed the results of previous studies by finding that the bimodal emotional condition elicited strong activation in the left middle temporal gyrus ({MTG}), and we extended this finding to locate the effects of emotional factors by using a neutral condition in the experimental design. We found anger-specific activation in the posterior cingulate, fusiform gyrus, and cerebellum, whereas we found happiness-specific activation in the {MTG}, parahippocampal gyrus, hippocampus, claustrum, inferior parietal lobule, cuneus, middle frontal gyrus ({MFG}), {IFG}, and anterior cingulate. These emotion-specific activations suggest that each emotion uses a separate network to integrate bimodal information and shares a common network for cross-modal integration.},
	pages = {161--169},
	number = {2},
	journaltitle = {Cortex},
	shortjournal = {Cortex},
	author = {Park, Ji-Young and Gu, Bon-Mi and Kang, Do-Hyung and Shin, Yong-Wook and Choi, Chi-Hoon and Lee, Jong-Min and Kwon, Jun Soo},
	urldate = {2019-01-24},
	date = {2010-02-01},
	keywords = {Functional magnetic resonance imaging ({fMRI}), Bimodal integration, Emotion, Interaction analysis},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/QJH6SFCW/Park et al. - 2010 - Integration of cross-modal emotional information i.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/U7PKKV9M/S001094520800172X.html:text/html}
}

@article{laurienti_deactivation_2002,
	title = {Deactivation of Sensory-Specific Cortex by Cross-Modal Stimuli},
	volume = {14},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/089892902317361930},
	doi = {10.1162/089892902317361930},
	abstract = {Visual and auditory cortices traditionally have been considered to be “modality-specific.” Thus, their activity has been thought to be unchanged by information in other sensory modalities. However, using functional magnetic resonance imaging ({fMRI}), the present experiments revealed that ongoing activity in the visual cortex could be modulated by auditory information and ongoing activity in the auditory cortex could be modulated by visual information. In both cases, this cross-modal modulation of activity took the form of deactivation. Yet, the deactivation response was not evident in either cortical area during the paired presentation of visual and auditory stimuli. These data suggest that cross-modal inhibitory processes operate within traditional modality-specific cortices and that these processes can be switched on or off in different circumstances.},
	pages = {420--429},
	number = {3},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Laurienti, Paul J. and Burdette, Jonathan H. and Wallace, Mark T. and Yen, Yi-Fen and Field, Aaron S. and Stein, Barry E.},
	urldate = {2019-01-24},
	date = {2002-04-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/YSHWUYXH/Laurienti et al. - 2002 - Deactivation of Sensory-Specific Cortex by Cross-M.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/KEI2HRJH/089892902317361930.html:text/html}
}

@online{noauthor_two_nodate,
	title = {Two Cortical Areas Mediate Multisensory Integration in Superior Colliculus Neurons {\textbar} Journal of Neurophysiology},
	url = {https://www.physiology.org/doi/full/10.1152/jn.2001.85.2.506},
	urldate = {2019-01-24},
	file = {Two Cortical Areas Mediate Multisensory Integration in Superior Colliculus Neurons | Journal of Neurophysiology:/home/felix/Zotero/storage/N48ZAA8Y/jn.2001.85.2.html:text/html}
}

@article{jiang_two_2001,
	title = {Two Cortical Areas Mediate Multisensory Integration in Superior Colliculus Neurons},
	volume = {85},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.2001.85.2.506},
	doi = {10.1152/jn.2001.85.2.506},
	abstract = {The majority of multisensory neurons in the cat superior colliculus ({SC}) are able to synthesize cross-modal cues (e.g., visual and auditory) and thereby produce responses greater than those elicited by the most effective single modality stimulus and, sometimes, greater than those predicted by the arithmetic sum of their modality-specific responses. The present study examined the role of corticotectal inputs from two cortical areas, the anterior ectosylvian sulcus ({AES}) and the rostral aspect of the lateral suprasylvian sulcus ({rLS}), in producing these response enhancements. This was accomplished by evaluating the multisensory properties of individual {SC} neurons during reversible deactivation of these cortices individually and in combination using cryogenic deactivation techniques. Cortical deactivation eliminated the characteristic multisensory response enhancement of nearly all {SC} neurons but generally had little or no effect on a neuron's modality-specific responses. Thus, the responses of {SC} neurons to combinations of cross-modal stimuli were now no different from those evoked by one or the other of these stimuli individually. Of the two cortical areas, {AES} had a much greater impact on {SC} multisensory integrative processes, with nearly half the {SC} neurons sampled dependent on it alone. In contrast, only a small number of {SC} neurons depended solely on {rLS}. However, most {SC} neurons exhibited dual dependencies, and their multisensory enhancement was mediated by either synergistic or redundant influences from {AES} and {rLS}. Corticotectal synergy was evident when deactivating either cortical area compromised the multisensory enhancement of an {SC} neuron, whereas corticotectal redundancy was evident when deactivation of both cortical areas was required to produce this effect. The results suggest that, although multisensory {SC} neurons can be created as a consequence of a variety of converging tectopetal afferents that are derived from a host of subcortical and cortical structures, the ability to synthesize cross-modal inputs, and thereby produce an enhanced multisensory response, requires functional inputs from the {AES}, the {rLS}, or both.},
	pages = {506--522},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Jiang, Wan and Wallace, Mark T. and Jiang, Huai and Vaughan, J. William and Stein, Barry E.},
	urldate = {2019-01-24},
	date = {2001-02-01},
	file = {Snapshot:/home/felix/Zotero/storage/P6Z579R3/jn.2001.85.2.html:text/html}
}

@article{avillac_multisensory_2007,
	title = {Multisensory Integration in the Ventral Intraparietal Area of the Macaque Monkey},
	volume = {27},
	rights = {Copyright © 2007 Society for Neuroscience 0270-6474/07/271922-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/27/8/1922},
	doi = {10.1523/JNEUROSCI.2646-06.2007},
	abstract = {The goal of this study was to characterize multisensory interaction patterns in cortical ventral intraparietal area ({VIP}). We recorded single-unit activity in two alert monkeys during the presentation of visual (drifting gratings) and tactile (low-pressure air puffs) stimuli. One stimulus was always positioned inside the receptive field of the neuron. The other stimulus was defined so as to manipulate the spatial and temporal disparity between the two stimuli. More than 70\% of {VIP} cells showed a significant modulation of their response by bimodal stimulations. These cells included both bimodal cells, i.e., cells responsive to both tested modalities, and seemingly unimodal cells, i.e., cells responding to only one of the two tested modalities. This latter observation suggests that postsynaptic latent mechanisms are involved in multisensory integration. In both cell categories, neuronal responses are either enhanced or depressed and reflect nonlinear sub-, super-, or additive mechanisms. The occurrence of these observations is maximum when stimuli are in temporal synchrony and spatially congruent. Interestingly, introducing spatial or temporal disparities between stimuli does not affect the sign or the magnitude of interactions but rather their occurrence. Multisensory stimulation also affects the neuronal response latencies of bimodal stimuli. For a given neuron, these are on average intermediate between the two unimodal response latencies, again suggesting latent postsynaptic mechanisms. In summary, we show that the majority of {VIP} neurons perform multisensory integration, following general rules (e.g., spatial congruency and temporal synchrony) that are closely similar to those described in other cortical and subcortical regions.},
	pages = {1922--1932},
	number = {8},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Avillac, Marie and Hamed, Suliann Ben and Duhamel, Jean-René},
	urldate = {2019-01-24},
	date = {2007-02-21},
	langid = {english},
	pmid = {17314288},
	keywords = {neurophysiology, tactile, visual, macaque monkey, multisensory integration, posterior parietal cortex},
	file = {Full Text PDF:/home/felix/Zotero/storage/7XDJNS5V/Avillac et al. - 2007 - Multisensory Integration in the Ventral Intraparie.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/8LQJ8II9/1922.html:text/html}
}

@article{barraclough*_integration_2005,
	title = {Integration of Visual and Auditory Information by Superior Temporal Sulcus Neurons Responsive to the Sight of Actions},
	volume = {17},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/0898929053279586},
	doi = {10.1162/0898929053279586},
	abstract = {Processing of complex visual stimuli comprising facial movements, hand actions, and body movements is known to occur in the superior temporal sulcus ({STS}) of humans and nonhuman primates. The {STS} is also thought to play a role in the integration of multimodal sensory input. We investigated whether {STS} neurons coding the sight of actions also integrated the sound of those actions. For 23\% of neurons responsive to the sight of an action, the sound of that action significantly modulated the visual response. The sound of the action increased or decreased the visually evoked response for an equal number of neurons. In the neurons whose visual response was increased by the addition of sound (but not those neurons whose responses were decreased), the audiovisual integration was dependent upon the sound of the action matching the sight of the action. These results suggest that neurons in the {STS} form multisensory representations of observed actions.},
	pages = {377--391},
	number = {3},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Barraclough*, Nick E. and Xiao*, Dengke and Baker, Chris I. and Oram, Mike W. and Perrett, David I.},
	urldate = {2019-01-24},
	date = {2005-03-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/7AUDG6HX/Barraclough et al. - 2005 - Integration of Visual and Auditory Information by .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/8WREIIYM/0898929053279586.html:text/html}
}

@article{sugihara_integration_2006,
	title = {Integration of Auditory and Visual Communication Information in the Primate Ventrolateral Prefrontal Cortex},
	volume = {26},
	rights = {Copyright © 2006 Society for Neuroscience 0270-6474/06/2611138-10\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/26/43/11138},
	doi = {10.1523/JNEUROSCI.3550-06.2006},
	abstract = {The integration of auditory and visual stimuli is crucial for recognizing objects, communicating effectively, and navigating through our complex world. Although the frontal lobes are involved in memory, communication, and language, there has been no evidence that the integration of communication information occurs at the single-cell level in the frontal lobes. Here, we show that neurons in the macaque ventrolateral prefrontal cortex ({VLPFC}) integrate audiovisual communication stimuli. The multisensory interactions included both enhancement and suppression of a predominantly auditory or a predominantly visual response, although multisensory suppression was the more common mode of response. The multisensory neurons were distributed across the {VLPFC} and within previously identified unimodal auditory and visual regions (O'Scalaidhe et al., 1997; Romanski and Goldman-Rakic, 2002). Thus, our study demonstrates, for the first time, that single prefrontal neurons integrate communication information from the auditory and visual domains, suggesting that these neurons are an important node in the cortical network responsible for communication.},
	pages = {11138--11147},
	number = {43},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Sugihara, Tadashi and Diltz, Mark D. and Averbeck, Bruno B. and Romanski, Lizabeth M.},
	urldate = {2019-01-24},
	date = {2006-10-25},
	langid = {english},
	pmid = {17065454},
	keywords = {vocalization, cortex, face, frontal lobe, language, sensory integration},
	file = {Full Text PDF:/home/felix/Zotero/storage/NWXE27I8/Sugihara et al. - 2006 - Integration of Auditory and Visual Communication I.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/E6TDUTRG/11138.html:text/html}
}

@article{calvert_detection_2001,
	title = {Detection of Audio-Visual Integration Sites in Humans by Application of Electrophysiological Criteria to the {BOLD} Effect},
	volume = {14},
	issn = {10538119},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1053811901908122},
	doi = {10.1006/nimg.2001.0812},
	pages = {427--438},
	number = {2},
	journaltitle = {{NeuroImage}},
	author = {Calvert, Gemma A. and Hansen, Peter C. and Iversen, Susan D. and Brammer, Michael J.},
	urldate = {2019-01-24},
	date = {2001-08},
	langid = {english},
	file = {Calvert et al. - 2001 - Detection of Audio-Visual Integration Sites in Hum.pdf:/home/felix/Zotero/storage/JF8Z2H8H/Calvert et al. - 2001 - Detection of Audio-Visual Integration Sites in Hum.pdf:application/pdf}
}

@article{beauchamp_integration_2004,
	title = {Integration of Auditory and Visual Information about Objects in Superior Temporal Sulcus},
	volume = {41},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627304000704},
	doi = {10.1016/S0896-6273(04)00070-4},
	abstract = {Two categories of objects in the environment—animals and man-made manipulable objects (tools)—are easily recognized by either their auditory or visual features. Although these features differ across modalities, the brain integrates them into a coherent percept. In three separate {fMRI} experiments, posterior superior temporal sulcus and middle temporal gyrus ({pSTS}/{MTG}) fulfilled objective criteria for an integration site. {pSTS}/{MTG} showed signal increases in response to either auditory or visual stimuli and responded more to auditory or visual objects than to meaningless (but complex) control stimuli. {pSTS}/{MTG} showed an enhanced response when auditory and visual object features were presented together, relative to presentation in a single modality. Finally, {pSTS}/{MTG} responded more to object identification than to other components of the behavioral task. We suggest that {pSTS}/{MTG} is specialized for integrating different types of information both within modalities (e.g., visual form, visual motion) and across modalities (auditory and visual).},
	pages = {809--823},
	number = {5},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Beauchamp, Michael S and Lee, Kathryn E and Argall, Brenna D and Martin, Alex},
	urldate = {2019-01-24},
	date = {2004-03-04},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/S9I9S4K4/Beauchamp et al. - 2004 - Integration of Auditory and Visual Information abo.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/24X9FJX5/S0896627304000704.html:text/html}
}

@article{giard_auditory-visual_1999-2,
	title = {Auditory-Visual Integration during Multimodal Object Recognition in Humans: A Behavioral and Electrophysiological Study},
	volume = {11},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/089892999563544},
	doi = {10.1162/089892999563544},
	shorttitle = {Auditory-Visual Integration during Multimodal Object Recognition in Humans},
	abstract = {The aim of this study was (1) to provide behavioral evidence for multimodal feature integration in an object recognition task in humans and (2) to characterize the processing stages and the neural structures where multisensory interactions take place. Event-related potentials ({ERPs}) were recorded from 30 scalp electrodes while subjects performed a forced-choice reaction-time categorization task: At each trial, the subjects had to indicate which of two objects was presented by pressing one of two keys. The two objects were defined by auditory features alone, visual features alone, or the combination of auditory and visual features. Subjects were more accurate and rapid at identifying multimodal than unimodal objects. Spatiotemporal analysis of {ERPs} and scalp current densities revealed several auditory-visual interaction components temporally, spatially, and functionally distinct before 200 msec poststimulus. The effects observed were (1) in visual areas, new neural activities (as early as 40 msec poststimulus) and modulation (amplitude decrease) of the N185 wave to unimodal visual stimulus, (2) in the auditory cortex, modulation (amplitude increase) of subcomponents of the unimodal auditory N1 wave around 90 to 110 msec, and (3) new neural activity over the right fronto-temporal area (140 to 165 msec). Furthermore, when the subjects were separated into two groups according to their dominant modality to perform the task in unimodal conditions (shortest reaction time criteria), the integration effects were found to be similar for the two groups over the nonspecific fronto-temporal areas, but they clearly differed in the sensory-specific cortices, affecting predominantly the sensory areas of the nondominant modality. Taken together, the results indicate that multisensory integration is mediated by flexible, highly adaptive physiological processes that can take place very early in the sensory processing chain and operate in both sensory-specific and nonspecific cortical structures in different ways.},
	pages = {473--490},
	number = {5},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Giard, M. H. and Peronnet, F.},
	urldate = {2019-01-24},
	date = {1999-09-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/X9AHVBJN/Giard and Peronnet - 1999 - Auditory-Visual Integration during Multimodal Obje.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/BF5YH3QL/089892999563544.html:text/html}
}

@incollection{stein_multisensory_2009,
	location = {Oxford},
	title = {Multisensory Convergence and Integration},
	isbn = {978-0-08-045046-9},
	url = {http://www.sciencedirect.com/science/article/pii/B9780080450469011128},
	abstract = {In the past two decades there has been considerable work directed toward understanding how the brain is able to synthesize information from different senses to enhance its information about external events. Neurons in a midbrain structure, the superior colliculus, have served as an effective model for understanding the principles underlying this multisensory integration capability and how the resulting enhancement and depression of activity at the level of the single superior colliculus neuron in animals is reflected in overt behavior. This information, as well as related information from studies of multisensory integration in human subjects, are discussed.},
	pages = {1119--1124},
	booktitle = {Encyclopedia of Neuroscience},
	publisher = {Academic Press},
	author = {Stein, B. E. and Rowland, B. and Laurienti, P. and Stanford, T. R.},
	editor = {Squire, Larry R.},
	urldate = {2019-01-24},
	date = {2009-01-01},
	doi = {10.1016/B978-008045046-9.01112-8},
	keywords = {Touch, Multisensory, Cross-modal, Superior colliculus, Vision, Association cortex, Cat, Hearing, Midbrain, Monkey, Multimodal, Polysensory, Unisensory},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/YAU5JBCQ/B9780080450469011128.html:text/html}
}

@incollection{stein_cross-modal_2001,
	location = {Oxford},
	title = {Cross-modal (Multi-sensory) Integration},
	isbn = {978-0-08-043076-8},
	url = {http://www.sciencedirect.com/science/article/pii/B0080430767035385},
	abstract = {One of the most important tasks the brain must perform is decoding and interpreting sensory information. Both individual survival and evolutionary success often depend on the speed and accuracy with which such information is processed and transformed into appropriate behaviors. Detecting and interpreting external stimuli is markedly facilitated by the brain's ability to synthesize information from different sensory systems, and the perceptual consequences of this ‘multisensory integration’ have intrigued philosophers of science since the time of ancient Greece. But it is only recently that we have come to understand some of the principles by which individual neurons combine cross-modal information. This endeavor has been facilitated by a model, the multi-sensory neuron in the superior colliculus ({SC}). In general, the sensory-evoked activity of the same {SC} neuron can be markedly enhanced or depressed, depending on the spatial and temporal relationships among the cross-modal stimuli and the organization of its own receptive fields. Furthermore, these determinants of multi-sensory integration at the single-neuron level are closely paralleled at the level of {SC}-mediated overt attentive and orientation behaviors. The cross-species similarities in the principles of multisensory integration suggest a remarkable adaptability and evolutionary conservation in this process.},
	pages = {3008--3015},
	booktitle = {International Encyclopedia of the Social \& Behavioral Sciences},
	publisher = {Pergamon},
	author = {Stein, B. E. and Wallace, M. T. and Stanford, T. R.},
	editor = {Smelser, Neil J. and Baltes, Paul B.},
	urldate = {2019-01-24},
	date = {2001-01-01},
	doi = {10.1016/B0-08-043076-7/03538-5},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/ZTZ4D55B/B0080430767035385.html:text/html}
}

@article{meredith_descending_1985,
	title = {Descending efferents from the superior colliculus relay integrated multisensory information},
	volume = {227},
	rights = {© 1985},
	issn = {0036-8075, 1095-9203},
	url = {http://science.sciencemag.org/content/227/4687/657},
	doi = {10.1126/science.3969558},
	abstract = {By means of their efferent projections to motor and premotor structures, the cells in the deep superior colliculus are intimately involved in behaviors that control the orientation of the eyes, pinnae, and head. These same efferent cells receive multiple sensory inputs, thereby apparently enabling an animal to orient its receptor organs in response to a wide variety of cues. This sensory convergence also provides a system in which motor responses need not be immutably linked to individual stimuli but can vary in reaction to the multitude of stimuli present in the environment at any given moment.},
	pages = {657--659},
	number = {4687},
	journaltitle = {Science},
	author = {Meredith, M. A. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1985-02-08},
	langid = {english},
	pmid = {3969558},
	file = {Full Text PDF:/home/felix/Zotero/storage/YV4Z73T3/Meredith and Stein - 1985 - Descending efferents from the superior colliculus .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/7IQJFKQ5/657.html:text/html}
}

@article{kadunce_influence_2001,
	title = {The influence of visual and auditory receptive field organization on multisensory integration in the superior colliculus},
	volume = {139},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s002210100772},
	doi = {10.1007/s002210100772},
	abstract = {. The spatial register of the different receptive fields of multisensory neurons in the superior colliculus ({SC}) plays a significant role in determining the responses of these neurons to cross-modal stimulus combinations. Spatially coincident visual-auditory stimuli fall within these overlapping receptive fields and generally produce response enhancements that exceed the individual modality-specific responses and can exceed their sum. Yet, in this context, it has not been clear how "spatial coincidence" is operationally defined. Given the large size of {SC} receptive fields, visual and auditory stimuli could be within their respective receptive fields even when there are substantial spatial disparities between them. Indeed, previous observations have raised the possibility that there may be a second level of determinism in how {SC} neurons deal with the relative spatial locations of within-field cross-modal stimuli; specifically, that multisensory response enhancements become progressively weaker as the within-field visual and auditory stimuli become increasingly disparate. While the present experiments demonstrated that {SC} multisensory neurons have heterogeneous receptive fields, and that the greatest number of impulses evoked were by stimuli that fell within the area of cross-modal receptive field overlap, they also indicate that there is no systematic relationship between cross-modal stimulus disparity and the magnitude of multisensory response enhancement. Thus, two within-field cross-modal stimuli produced the same proportionate change (i.e., multisensory response enhancement) when they were widely disparate as they did when they overlapped one another in space. These observations indicate that cross-modal spatial coincidence can be defined operationally by the borders of an {SC} neuron's receptive fields regardless of the size of those receptive fields and/or the absolute spatial disparity between within-field cross-modal stimuli.},
	pages = {303--310},
	number = {3},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Kadunce, Daniel C. and Vaughan, William J. and Wallace, Mark T. and Stein, Barry E.},
	urldate = {2019-01-24},
	date = {2001-08-01},
	langid = {english},
	keywords = {Multimodal Polysensory Cross-modal Intersensory Physiology Cat},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/RPQ9MSGS/Kadunce et al. - 2001 - The influence of visual and auditory receptive fie.pdf:application/pdf}
}

@article{meredith_spatial_1996,
	title = {Spatial determinants of multisensory integration in cat superior colliculus neurons},
	volume = {75},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1996.75.5.1843},
	doi = {10.1152/jn.1996.75.5.1843},
	abstract = {1. Although a representation of multisensory space is contained in the superior colliculus, little is known about the spatial requirements of multisensory stimuli that influence the activity of neurons here. Critical to this problem is an assessment of the registry of the different receptive fields within individual multisensory neurons. The present study was initiated to determine how closely the receptive fields of individual multisensory neurons are aligned, the physiological role of that alignment, and the possible functional consequences of inducing receptive-field misalignment. 2. Individual multisensory neurons in the superior colliculus of anesthetized, paralyzed cats were studied with the use of standard extracellular recording techniques. The receptive fields of multisensory neurons were large, as reported previously, but exhibited a surprisingly high degree of spatial coincidence. The average proportion of receptive-field overlap was 86\% for the population of visual-auditory neurons sampled. 3. Because of this high degree of intersensory receptive-field correspondence, combined-modality stimuli that were coincident in space tended to fall within the excitatory regions of the receptive fields involved. The result was a significantly enhanced neuronal response in 88\% of the multisensory neurons studied. If stimuli were spatially disparate, so that one fell outside its receptive field, either a decreased response occurred (56\%), or no intersensory effect was apparent (44\%). 4. The normal alignment of the different receptive fields of a multisensory neuron could be disrupted by passively displacing the eyes, pinnae, or limbs/body. In no case was a shift in location or size observed in a neuron's other receptive field(s) to compensate for this displacement. The physiological result of receptive-field misalignment was predictable and based on the location of the stimuli relative to the new positions of their respective receptive fields. Now, for example, one component of a spatially coincident pair of stimuli might fall outside its receptive field and inhibit the other's effects. 5. These data underscore the dependence of multisensory integrative responses on the relationship of the different stimuli to their corresponding receptive fields rather than to the spatial relationship of the stimuli to one another. Apparently, the alignment of different receptive fields for individual multisensory neurons ensures that responses to combinations of stimuli derived from the same event are integrated to increase the salience of that event. Therefore the maintenance of receptive-field alignment is critical for the appropriate integration of converging sensory signals and, ultimately, elicitation of adaptive behaviors.},
	pages = {1843--1857},
	number = {5},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Meredith, M. A. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1996-05-01},
	file = {Snapshot:/home/felix/Zotero/storage/EKS49SJH/jn.1996.75.5.html:text/html}
}

@article{alex_meredith_spatial_1986,
	title = {Spatial factors determine the activity of multisensory neurons in cat superior colliculus},
	volume = {365},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/0006899386916483},
	doi = {10.1016/0006-8993(86)91648-3},
	abstract = {The responses of a neuron to stimuli from one sensory modality can be profoundly influenced by inputs from other sensory modalities. The present experiments demonstrate that the nature and the magnitude of these multisensory interactions depend on the positions of the stimuli in relation to their respective receptive fields. The spatial rules governing these interactions underscore the significance of the alignment of sensory maps in the brain.},
	pages = {350--354},
	number = {2},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Alex Meredith, M. and Stein, Barry E.},
	urldate = {2019-01-24},
	date = {1986-02-19},
	keywords = {superior colliculus, multisensory interaction, sensorimotor integration, sensory map},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/LSPSKCAZ/Alex Meredith and Stein - 1986 - Spatial factors determine the activity of multisen.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/CMC7YLNW/0006899386916483.html:text/html}
}

@article{meredith_determinants_1987,
	title = {Determinants of multisensory integration in superior colliculus neurons. I. Temporal factors},
	volume = {7},
	rights = {© 1987 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/7/10/3215},
	doi = {10.1523/JNEUROSCI.07-10-03215.1987},
	abstract = {One of the most impressive features of the central nervous system is its ability to process information from a variety of stimuli to produce an integrated, comprehensive representation of the external world. In the present study, the temporal disparity among combinations of different sensory stimuli was shown to be a critical factor influencing the integration of multisensory stimuli by superior colliculus neurons. Several temporal principles that govern multisensory integration were revealed: (1) maximal levels of response enhancement were generated by overlapping the peak discharge periods evoked by each modality; (2) the magnitude of this enhancement decayed monotonically to zero as the peak discharge periods became progressively more temporally disparate; (3) with further increases in temporal disparity, the same stimulus combinations that previously produced enhancement could often produce depression; and (4) these kinds of interactions could frequently be predicted from the discharge trains initiated by each stimulus alone. Since multisensory superior colliculus neurons project to premotor areas of the brain stem and spinal cord that control the orientation of the receptor organs (eyes, pinnae, head), they are believed to influence attentive and orientation behaviors. Therefore, it is likely that the temporal relationships of different environmental stimuli that control the activity of these neurons are also a powerful determinant of superior colliculus-mediated attentive and orientation behaviors.},
	pages = {3215--3229},
	number = {10},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Meredith, M. A. and Nemitz, J. W. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1987-10-01},
	langid = {english},
	pmid = {3668625},
	file = {Full Text PDF:/home/felix/Zotero/storage/QW6EH8N2/Meredith et al. - 1987 - Determinants of multisensory integration in superi.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/7GBZ7TG2/3215.html:text/html}
}

@article{recanzone_auditory_2003,
	title = {Auditory Influences on Visual Temporal Rate Perception},
	volume = {89},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00706.2002},
	doi = {10.1152/jn.00706.2002},
	abstract = {Visual stimuli are known to influence the perception of auditory stimuli in spatial tasks, giving rise to the ventriloquism effect. These influences can persist in the absence of visual input following a period of exposure to spatially disparate auditory and visual stimuli, a phenomenon termed the ventriloquism aftereffect. It has been speculated that the visual dominance over audition in spatial tasks is due to the superior spatial acuity of vision compared with audition. If that is the case, then the auditory system should dominate visual perception in a manner analogous to the ventriloquism effect and aftereffect if one uses a task in which the auditory system has superior acuity. To test this prediction, the interactions of visual and auditory stimuli were measured in a temporally based task in normal human subjects. The results show that the auditory system has a pronounced influence on visual temporal rate perception. This influence was independent of the spatial location, spectral bandwidth, and intensity of the auditory stimulus. The influence was, however, strongly dependent on the disparity in temporal rate between the two stimulus modalities. Further, aftereffects were observed following approximately 20 min of exposure to temporally disparate auditory and visual stimuli. These results show that the auditory system can strongly influence visual perception and are consistent with the idea that bimodal sensory conflicts are dominated by the sensory system with the greater acuity for the stimulus parameter being discriminated.},
	pages = {1078--1093},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Recanzone, Gregg H.},
	urldate = {2019-01-24},
	date = {2003-02-01},
	file = {Snapshot:/home/felix/Zotero/storage/VJYWX2IR/jn.00706.html:text/html}
}

@article{meredith_visual_1986,
	title = {Visual, auditory, and somatosensory convergence on cells in superior colliculus results in multisensory integration},
	volume = {56},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1986.56.3.640},
	doi = {10.1152/jn.1986.56.3.640},
	abstract = {Convergence of inputs from different sensory modalities onto individual neurons is a phenomenon that occurs widely throughout the brain at many phyletic levels and appears to represent a basic neural mechanism by which an organism integrates complex environmental stimuli. In the present study, neurons in the superior colliculus ({SC}) were used as a model to examine how single neurons deal with simultaneous cues from different sensory modalities (e.g., visual, auditory, somatosensory). The functional result of multisensory convergence on an individual cell was determined by comparing the responses evoked from it by a combined-modality (multimodal) stimulus with those elicited by each (unimodal) component of that stimulus presented alone. Superior colliculus cells exhibited profound changes in their activity when individual sensory stimuli were combined. These "multisensory interactions" were found to be widespread among deep laminae cells and fell into one of two functional categories: response enhancement, characterized by a significant increase in the number of discharges evoked; and response depression, characterized by a significant decrease in the discharges elicited. Multisensory response interactions most often reflected a multiplicative, rather than summative, change in activity. Their absolute magnitude varied from cell to cell and, when stimulus conditions were altered, within the same cell. However, the percentage change of enhanced interactions was generally inversely related to the vigor of the responses that could be evoked by presenting each unimodal stimulus alone and suggest that the potential for response amplification was greatest when responses evoked by individual stimuli were weakest. The majority of cells exhibiting multi-sensory characteristics were demonstrated to have descending efferent projections and thus had access to premotor and motor areas of the brain stem and spinal cord involved in {SC}-mediated attentive and orientation behaviors. These data show that multisensory convergence provides the descending efferent cells of the {SC} with a dynamic response character. The responses of these cells and the {SC}-mediated behaviors that they underlie need not be immutably tied to the presence of any single stimulus, but can vary in response to the particular complex of stimuli present in the environment at any given moment.},
	pages = {640--662},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Meredith, M. A. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1986-09-01},
	file = {Snapshot:/home/felix/Zotero/storage/ZPHBDRRU/jn.1986.56.3.html:text/html}
}

@article{wallace_representation_1996,
	title = {Representation and integration of multiple sensory inputs in primate superior colliculus},
	volume = {76},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1996.76.2.1246},
	doi = {10.1152/jn.1996.76.2.1246},
	abstract = {1. The properties of visual-, auditory-, and somatosensory-responsive neurons, as well as of neurons responsive to multiple sensory cues (i.e., multisensory), were examined in the superior colliculus of the rhesus monkey. Although superficial layer neurons responded exclusively to visual stimuli and visual inputs predominated in deeper layers, there was also a rich nonvisual and multisensory representation in the superior colliculus. More than a quarter (27.8\%) of the deep layer population responded to stimuli from more than a single sensory modality. In contrast, 37\% responded only to visual cues, 17.6\% to auditory cues, and 17.6\% to somatosensory cues. Unimodal- and multisensory-responsive neurons were clustered by modality. Each of these modalities was represented in map-like fashion, and the different representations were in alignment with one another. 2. Most deep layer visually responsive neurons were binocular and exhibited poor selectivity for such stimulus characteristics as orientation, velocity, and direction of movement. Similarly, most auditory-responsive neurons had contralateral receptive fields and were binaural, but had little frequency selectivity and preferred complex, broad-band sounds. Somatosensory-responsive neurons were overwhelmingly contralateral, high velocity, and rapidly adapting. Only rarely did somatosensory-responsive neurons require distortion of subcutaneous tissue for activation. 3. The spatial congruence among the different receptive fields of multisensory neurons was a critical feature underlying their ability to synthesize cross-modal information. 4. Combinations of stimuli could have very different consequences in the same neuron, depending on their temporal and spatial relationships. Generally, multisensory interactions were evident when pairs of stimuli were separated from one another by {\textless} 500 ms, and the products of these interactions far exceeded the sum of their unimodal components. Whether the combination of stimuli produced response enhancement, response depression, or no interaction depended on the location of the stimuli relative to one another and to their respective receptive fields. Maximal response enhancements were observed when stimuli originated from similar locations in space (as when derived from the same event) because they fell within the excitatory receptive fields of the same multisensory neurons. If, however, the stimuli were spatially disparate such that one fell beyond the excitatory borders of its receptive field, either no interaction was produced or this stimulus depressed the effectiveness of the other. Furthermore, maximal response interactions were seen with the pairing of weakly effective unimodal stimuli. As the individual unimodal stimuli became increasingly effective, the levels of response enhancement to stimulus combinations declined, a principle referred to as inverse effectiveness. Many of the integrative principles seen here in the primate superior colliculus are strikingly similar to those observed in the cat. These observations indicate that a set of common principles of multisensory integration is adaptable in widely divergent species living in very different ecological situations. 5. Surprisingly, a few multisensory neurons had individual receptive fields that were not in register with one another. This has not been noted in multisensory neurons of other species, and these "anomalous" receptive fields could present a daunting problem: stimuli originating from the same general location in space cannot simultaneously fall within their respective receptive fields, a stimulus pairing that may result in response depression. Conversely, stimuli that originate from separate events and disparate locations (and fall within their receptive fields) may result in response enhancement. However, the spatial principle of multisensory integration did not apply in these cases. ({ABSTRACT} {TRUNCATED})},
	pages = {1246--1266},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Wallace, M. T. and Wilkinson, L. K. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1996-08-01},
	file = {Snapshot:/home/felix/Zotero/storage/DTH8HRRZ/jn.1996.76.2.html:text/html}
}

@article{perrault_superior_2005,
	title = {Superior Colliculus Neurons Use Distinct Operational Modes in the Integration of Multisensory Stimuli},
	volume = {93},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00926.2004},
	doi = {10.1152/jn.00926.2004},
	abstract = {Many neurons in the superior colliculus ({SC}) integrate sensory information from multiple modalities, giving rise to significant response enhancements. Although enhanced multisensory responses have been shown to depend on the spatial and temporal relationships of the stimuli as well as on their relative effectiveness, these factors alone do not appear sufficient to account for the substantial heterogeneity in the magnitude of the multisensory products that have been observed. Toward this end, the present experiments have revealed that there are substantial differences in the operations used by different multisensory {SC} neurons to integrate their cross-modal inputs, suggesting that intrinsic differences in these neurons may also play an important deterministic role in multisensory integration. In addition, the integrative operation employed by a given neuron was found to be well correlated with the neuron's dynamic range. In total, four categories of {SC} neurons were identified based on how their multisensory responses changed relative to the predicted addition of the two unisensory inputs as stimulus effectiveness was altered. Despite the presence of these categories, a general rule was that the most robust multisensory enhancements were seen with combinations of the least effective unisensory stimuli. Together, these results provide a better quantitative picture of the integrative operations performed by multisensory {SC} neurons and suggest mechanistic differences in the way in which these neurons synthesize cross-modal information.},
	pages = {2575--2586},
	number = {5},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Perrault, Thomas J. and Vaughan, J. William and Stein, Barry E. and Wallace, Mark T.},
	urldate = {2019-01-24},
	date = {2005-05-01},
	file = {Snapshot:/home/felix/Zotero/storage/CZXIN8QR/jn.00926.html:text/html}
}

@article{wallace_converging_1993,
	title = {Converging influences from visual, auditory, and somatosensory cortices onto output neurons of the superior colliculus},
	volume = {69},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/abs/10.1152/jn.1993.69.6.1797},
	doi = {10.1152/jn.1993.69.6.1797},
	abstract = {1. Physiological methods were used to examine the pattern of inputs from different sensory cortices onto individual superior colliculus neurons. 2. Visual, auditory, and somatosensory influences from anterior ectosylvian sulcus ({AES}) and visual influences from lateral suprasylvian ({LS}) cortex were found to converge onto individual multisensory neurons in the cat superior colliculus. An excellent topographic relationship was found between the different sensory cortices and their target neurons in the superior colliculus. 3. Corticotectal inputs were derived solely from unimodal neurons. Multisensory neurons in {AES} and {LS} were not antidromically activated from the superior colliculus. 4. Orthodromic and antidromic latencies were consistent with monosynaptic corticotectal inputs arising from {LS} and the three subdivisions of {AES} ({SIV}, Field {AES}, and {AEV}). 5. Superior colliculus neurons that received convergent cortical inputs formed a principal component of the tecto-reticulospinal tract. Thus there appears to be extensive cortical control over the output neurons through which the superior colliculus mediates attentive and orientation behaviors. 6. Two other multisensory circuits were identified. A population of multisensory superior colliculus neurons was found, which neither received convergent cortical input nor projected into the tecto-reticulo-spinal tract. In addition, multisensory neurons in {AES} and {LS} proved to be independent of the superior colliculus (i.e., they were not corticotectal). While it is likely that these three distinct multisensory neural circuits have different functional roles, their constituent neurons appear to integrate their various sensory inputs in much the same way.},
	pages = {1797--1809},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Wallace, M. T. and Meredith, M. A. and Stein, B. E.},
	urldate = {2019-01-24},
	date = {1993-06-01},
	file = {Snapshot:/home/felix/Zotero/storage/QKSZUN6F/jn.1993.69.6.html:text/html}
}

@article{stein_behavioral_1989,
	title = {Behavioral Indices of Multisensory Integration: Orientation to Visual Cues is Affected by Auditory Stimuli},
	volume = {1},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn.1989.1.1.12},
	doi = {10.1162/jocn.1989.1.1.12},
	shorttitle = {Behavioral Indices of Multisensory Integration},
	abstract = {Physiological studies have demonstrated that inputs from different sensory modalities converge on, and are integrated by, individual superior colliculus neurons and that this integration is governed by specific spatial rules. The present experiments were an attempt to relate these neural processes to overt behavior by determining if behaviors believed to involve the circuitry of the superior colliculus would show similar multisensory dependencies and be subject to the same rules of integration. The neurophysiological-behavioral parallels proved to be striking. The effectiveness of a stimulus of one modality in eliciting attentive and orientation behaviors was dramatically affected by the presence of a stimulus from another modality in each of the three behavioral paradigms used here. Animals trained to approach a low intensity visual cue had their performance significantly enhanced when a brief, low intensity auditory stimulus was presented at the same location as the visual cue, but their performance was significantly depressed when the auditory stimulus was disparate to it. These effects were independent of the animals' experience with the modifying (i.e. auditory) stimulus and exceeded what might have been predicted statistically based on the animals' performance with each single-modality cue. The multiplicative nature of these multisensory interactions and their dependence on the relative positions and intensities of the two stimuli were all very similar to those observed physiologically for single cells. The few differences that were observed appeared to reflect the fact that understanding integration at the level of the single cell requires reference to the individual cell's multisensory receptive field properties, while at the behavioral level populations of receptive fields must be evaluated. These data illustrate that the rules governing multisensory integration at the level of the single cell also predict responses to these stimuli in the intact behaving organism.},
	pages = {12--24},
	number = {1},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Stein, Barry E. and Meredith, M. Alex and Huneycutt, W. Scott and {McDade}, Lawrence},
	urldate = {2019-01-24},
	date = {1989-01-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/N7QX42D8/Stein et al. - 1989 - Behavioral Indices of Multisensory Integration Or.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/3PVZ9BTD/jocn.1989.1.1.html:text/html}
}

@article{wallace_sensory_2001,
	title = {Sensory and Multisensory Responses in the Newborn Monkey Superior Colliculus},
	volume = {21},
	rights = {Copyright © 2001 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/21/22/8886},
	doi = {10.1523/JNEUROSCI.21-22-08886.2001},
	abstract = {Superior colliculus ({SC}) neurons have the ability to synthesize information from different sensory modalities, resulting in enhancements (or depressions) of their activity. This physiological capacity is, in turn, closely tied to changes in overt attentive and orientation responses. The present study shows that, in contrast to more altricial species, many deep layer {SC} neurons in the rhesus monkey are multisensory at birth. Such neurons can respond to stimuli from different sensory modalities, and all convergence patterns seen in the adult are represented. Nevertheless, these neurons cannot yet synthesize their multisensory inputs. Rather, they respond to combinations of cross-modal stimuli much like they respond to their individual modality-specific components. This immature property of multisensory neurons is in contrast to many of the surprisingly sophisticated modality-specific response properties of these neurons and of their modality-specific neighbors. Thus, although deep {SC} neurons in the newborn have longer latencies and larger receptive fields than their adult counterparts, they are already highly active and are distributed in the typical adult admixture of visual, auditory, somatosensory, and multisensory neurons. Furthermore, the receptive fields of these neurons are already ordered into well organized topographic maps, and the different receptive fields of the same multisensory neurons show a good degree of cross-modal spatial register. These data, coupled with those from cat, suggest that the capacity to synthesize multisensory information does not simply appear in {SC} neurons at a prescribed maturational stage but rather develops only after substantial experience with cross-modal cues.},
	pages = {8886--8894},
	number = {22},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Wallace, Mark T. and Stein, Barry E.},
	urldate = {2019-01-25},
	date = {2001-11-15},
	langid = {english},
	pmid = {11698600},
	keywords = {somatosensory, auditory, cross-modal, visual, superior colliculus, multisensory integration, sensory development},
	file = {Full Text PDF:/home/felix/Zotero/storage/DR9UFPPU/Wallace and Stein - 2001 - Sensory and Multisensory Responses in the Newborn .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/UA5QBTR8/8886.html:text/html}
}

@article{king_integration_1985,
	title = {Integration of visual and auditory information in bimodal neurones in the guinea-pig superior colliculus},
	volume = {60},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/BF00236934},
	doi = {10.1007/BF00236934},
	abstract = {{SummaryWe} have investigated the responses of neurones in the guinea-pig superior colliculus to combinations of visual and auditory stimuli. When these stimuli were presented separately, some of these neurones responded only to one modality, others to both and a few neurones reliably to neither. To bimodal stimulation, many of these neurones exhibited some form of cross-modality interaction, the degree and nature of which depended on the relative timing and location of the two stimuli. Facilitatory and inhibitory interactions were observed and, occasionally, both effects were found in the same neurone at different inter-stimulus intervals. Neurones whose responses to visual stimuli were enhanced by an auditory stimulus were found in the superficial layers. Although visual-enhanced and visual-depressed auditory neurones were found throughout the deep layers, the majority of them were recorded in the stratum griseum profundum. Neurones that responded to both visual and auditory stimuli presented separately and gave enhanced or depressed responses to bimodal stimulation were found throughout the deep layers, but were concentrated in the stratum griseum intermediale and extended into the stratum opticum.},
	pages = {492--500},
	number = {3},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {King, A. J. and Palmer, A. R.},
	urldate = {2019-01-25},
	date = {1985-11-01},
	langid = {english},
	keywords = {Visual, Superior colliculus, Auditory, Bimodal interaction, Sensory convergence},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/M5RS7775/King and Palmer - 1985 - Integration of visual and auditory information in .pdf:application/pdf}
}

@article{diederich_bimodal_2004,
	title = {Bimodal and trimodal multisensory enhancement: Effects of stimulus onset and intensity on reaction time},
	volume = {66},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03195006},
	doi = {10.3758/BF03195006},
	shorttitle = {Bimodal and trimodal multisensory enhancement},
	abstract = {Manual reaction times to visual, auditory, and tactile stimuli presented simultaneously, or with a delay, were measured to test for multisensory interaction effects in a simple detection task with redundant signals. Responses to trimodal stimulus combinations were faster than those to bimodal combinations, which in turn were faster than reactions to unimodal stimuli. Response enhancement increased with decreasing auditory and tactile stimulus intensity and was a U-shaped function of stimulus onset asynchrony. Distribution inequality tests indicated that the multisensory interaction effects were larger than predicted by separate activation models, including the difference between bimodal and trimodal response facilitation. The results are discussed with respect to previous findings in a focused attention task and are compared with multisensory integration rules observed in bimodal and trimodal superior colliculus neurons in the cat and monkey.},
	pages = {1388--1404},
	number = {8},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Diederich, Adele and Colonius, Hans},
	urldate = {2019-01-25},
	date = {2004-11-01},
	langid = {english},
	keywords = {Tactile Stimulus, Multisensory Integration, Stimulus Combination, Stimulus Onset Asynchrony, Superior Colliculus},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/MX9CNBRF/Diederich and Colonius - 2004 - Bimodal and trimodal multisensory enhancement Eff.pdf:application/pdf}
}

@article{hughes_visual-auditory_nodate,
	title = {Visual-Auditory Interactions in Sensorimotor Processing: Saccades Versus Manual Responses},
	pages = {23},
	author = {Hughes, Howard C and Reuter-Lorenz, Patricia A and Nozawa, George and Fendrich, Robert},
	langid = {english}
}

@article{nozawa_parallel_1994,
	title = {Parallel and serial processes in the human oculomotor system: bimodal integration and express saccades},
	volume = {72},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/BF00206235},
	doi = {10.1007/BF00206235},
	shorttitle = {Parallel and serial processes in the human oculomotor system},
	abstract = {Saccadic reaction times ({SRTs}) were analyzed in the context of stochastic models of information processing (e.g., Townsend and Ashby 1983) to reveal the processing architecture(s) underlying integrative interactions between visual and auditory inputs and the mechanisms of express saccades. The results support the following conclusions. Bimodal (visual + auditory) targets are processed in parallel, and facilitate {SRT} to an extent that exceeds levels attainable by probability summation. This strongly implies neural summation between elements responding to spatially aligned visual and auditory inputs in the human oculomotor system. Second, express saccades are produced within a separable processing stage that is organized in series with that responsible for intersensory integration. A model is developed that implements this combination of parallel and serial processing. The activity in parallel input channels is summed within a sensory stage which is organized in series with a pre-motor and motor stage. The time course of each subprocess is considered a random variable, and different experimental manipulations can selectively influence different stages. Parallels between the model and physiological data are explored.},
	pages = {19--34},
	number = {1},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol. Cybern.},
	author = {Nozawa, G. and Reuter-Lorenz, P. A. and Hughes, H. C.},
	urldate = {2019-01-25},
	date = {1994-11-01},
	langid = {english},
	keywords = {Input Channel, Physiological Data, Processing Stage, Serial Process, Stochastic Model},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/YKJ6ENPV/Nozawa et al. - 1994 - Parallel and serial processes in the human oculomo.pdf:application/pdf}
}

@article{rowland_multisensory_2007-2,
	title = {Multisensory Integration Shortens Physiological Response Latencies},
	volume = {27},
	rights = {Copyright © 2007 Society for Neuroscience 0270-6474/07/275879-06\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/27/22/5879},
	doi = {10.1523/JNEUROSCI.4986-06.2007},
	abstract = {Individual superior colliculus ({SC}) neurons integrate information from multiple sensory sources to enhance their physiological response. The response of an {SC} neuron to a cross-modal stimulus combination can not only exceed the best component unisensory response but can also exceed their arithmetic sum (i.e., superadditivity). The present experiments were designed to investigate the temporal profile of multisensory integration in this model system. We found that cross-modal stimuli frequently shortened physiological response latencies (mean shift, 6.2 ms) and that response enhancement was greatest in the initial phase of the response (the phenomenon of initial response enhancement). The vast majority of the responses studied evidenced superadditive computations, most often at the beginning of the multisensory response.},
	pages = {5879--5884},
	number = {22},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Rowland, Benjamin A. and Quessy, Stephan and Stanford, Terrence R. and Stein, Barry E.},
	urldate = {2019-01-25},
	date = {2007-05-30},
	langid = {english},
	pmid = {17537958},
	keywords = {cross-modal, latency, multisensory, superior colliculus, audition, vision},
	file = {Full Text PDF:/home/felix/Zotero/storage/CH7UJ9ZF/Rowland et al. - 2007 - Multisensory Integration Shortens Physiological Re.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/WR7MZDR5/5879.html:text/html}
}

@article{stein_behavioral_1989-1,
	title = {Behavioral Indices of Multisensory Integration: Orientation to Visual Cues is Affected by Auditory Stimuli},
	volume = {1},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn.1989.1.1.12},
	doi = {10.1162/jocn.1989.1.1.12},
	shorttitle = {Behavioral Indices of Multisensory Integration},
	abstract = {Physiological studies have demonstrated that inputs from different sensory modalities converge on, and are integrated by, individual superior colliculus neurons and that this integration is governed by specific spatial rules. The present experiments were an attempt to relate these neural processes to overt behavior by determining if behaviors believed to involve the circuitry of the superior colliculus would show similar multisensory dependencies and be subject to the same rules of integration. The neurophysiological-behavioral parallels proved to be striking. The effectiveness of a stimulus of one modality in eliciting attentive and orientation behaviors was dramatically affected by the presence of a stimulus from another modality in each of the three behavioral paradigms used here. Animals trained to approach a low intensity visual cue had their performance significantly enhanced when a brief, low intensity auditory stimulus was presented at the same location as the visual cue, but their performance was significantly depressed when the auditory stimulus was disparate to it. These effects were independent of the animals' experience with the modifying (i.e. auditory) stimulus and exceeded what might have been predicted statistically based on the animals' performance with each single-modality cue. The multiplicative nature of these multisensory interactions and their dependence on the relative positions and intensities of the two stimuli were all very similar to those observed physiologically for single cells. The few differences that were observed appeared to reflect the fact that understanding integration at the level of the single cell requires reference to the individual cell's multisensory receptive field properties, while at the behavioral level populations of receptive fields must be evaluated. These data illustrate that the rules governing multisensory integration at the level of the single cell also predict responses to these stimuli in the intact behaving organism.},
	pages = {12--24},
	number = {1},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Stein, Barry E. and Meredith, M. Alex and Huneycutt, W. Scott and {McDade}, Lawrence},
	urldate = {2019-01-25},
	date = {1989-01-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/3WJRYCE5/Stein et al. - 1989 - Behavioral Indices of Multisensory Integration Or.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/R6B8CRHB/jocn.1989.1.1.html:text/html}
}

@article{hershenson_reaction_1962,
	title = {Reaction time as a measure of intersensory facilitation},
	volume = {63},
	issn = {0022-1015(Print)},
	doi = {10.1037/h0039516},
	abstract = {An experiment is reported in which reaction times ({RTs}) were measured to light and sound presented singly and in combination. The chief experimental variable was stimulus onset asynchrony. The results may be summarized as follows: (a) Intersensory facilitation was demonstrated in that, for certain asynchronies, {RTs} were faster to the combination than to either stimulus alone. (b) Maximum facilitation occurred at or just beyond the point at which the asynchrony was equal to the difference in {RT} to the single stimuli. (c) Varying the intensity of the stimuli differentially affected the magnitude of facilitation. Reducing the light intensity resulted in less facilitation whereas reducing the sound intensity had no effect. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {289--293},
	number = {3},
	journaltitle = {Journal of Experimental Psychology},
	author = {Hershenson, Maurice},
	date = {1962},
	keywords = {Reaction Time, Auditory Stimulation, Illumination, Intersensory Processes, Stimulus Onset},
	file = {Snapshot:/home/felix/Zotero/storage/ECI39SC4/2006-00785-012.html:text/html}
}

@article{miller_divided_1982,
	title = {Divided attention: Evidence for coactivation with redundant signals},
	volume = {14},
	issn = {0010-0285},
	url = {http://www.sciencedirect.com/science/article/pii/001002858290010X},
	doi = {10.1016/0010-0285(82)90010-X},
	shorttitle = {Divided attention},
	abstract = {Many models of divided attention assume that signals presented on different channels produce separate activations, any one of which can initiate a response. According to these models, detection responses are especially fast when signals are presented on two channels at the same time because the system can detect a signal in either of two ways. Such models predict a testable relation among reaction time distributions for conditions in which a single signal is presented as compared with a condition in which two signals are presented, and this prediction is tested in two tasks. A bimodal detection task required a simple speeded response to either a visual or an auditory signal. A letter search task required a choice response depending on whether or not a two-letter display included the signal letter “A.” Data from both tasks are inconsistent with the prediction. When two signals are presented, responses are faster than separate-activation models can explain. The results favor “coactivation” models, in which signals presented on different channels contribute to a common pool of activation that initiates a response.},
	pages = {247--279},
	number = {2},
	journaltitle = {Cognitive Psychology},
	shortjournal = {Cognitive Psychology},
	author = {Miller, Jeff},
	urldate = {2019-01-25},
	date = {1982-04-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/PV83AABD/Miller - 1982 - Divided attention Evidence for coactivation with .pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/LNTZFQM9/001002858290010X.html:text/html}
}

@article{raab_division_1962,
	title = {Division of Psychology: Statistical Facilitation of Simple Reaction Times*},
	volume = {24},
	rights = {1962 The New York Academy of Sciences},
	issn = {2164-0947},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.2164-0947.1962.tb01433.x},
	doi = {10.1111/j.2164-0947.1962.tb01433.x},
	shorttitle = {Division of Psychology},
	pages = {574--590},
	number = {5},
	journaltitle = {Transactions of the New York Academy of Sciences},
	author = {Raab, David H.},
	urldate = {2019-01-25},
	date = {1962},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/4XZ7UBD2/j.2164-0947.1962.tb01433.html:text/html}
}

@online{schmidt_locus_1984,
	title = {The locus of intersensory facilitation of reaction time},
	rights = {Open Access (free)},
	url = {http://dspace.library.uu.nl/handle/1874/23771},
	abstract = {When an imperative visual stimulus is paired with an auditory (accessory) stimulus, {RT} is generally faster than with the imperative stimulus alone. Three experiments using additive-factors logic tested an energy-summation view of the accessory, where effects are due to increased rate of information build-up in sensory stages, and a preparation-enhancement view which holds that the accessory serves an alerting function. Experiment 1 found no interaction between the accessory presence and (visual) stimulus brightness, suggesting no role of the accessory in stimulus identification. Experiment 2 found no interaction between accessory presence and spatial S-R compatibility, arguing that the accessory operated in stage(s) other than response selection. Experiment 3 produced an interaction between the accessory and movement complexity, arguing for accessory effects in a response-programming stage. The data generally favored preparation-enhancement, and offered no support for an energy-summation view.},
	titleaddon = {57},
	type = {Article},
	author = {Schmidt, R. A. and Gielen, Stan C. A. M. and Heuvel, P. J. M. van den},
	urldate = {2019-01-25},
	date = {1984},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/9KBQ44NZ/Schmidt et al. - 1984 - The locus of intersensory facilitation of reaction.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/BARTFY7J/23771.html:text/html}
}

@article{schroger_speeded_1998,
	title = {Speeded responses to audiovisual signal changes result from bimodal integration},
	volume = {35},
	rights = {Copyright © 2003 Society for Psychophysiological Research},
	issn = {1469-8986},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1469-8986.3560755},
	doi = {10.1111/1469-8986.3560755},
	abstract = {Integration of auditory and visual information was studied in humans detecting targets (i.e., location changes of the auditory, the visual, or both parts of a repetitively presented audiovisual stimulus). Behavioral results suggest that the time advantage to bimodal compared with unimodal targets was due to combined rather than separate processing of the auditory and the visual target information. Event-related brain potential results revealed strong audiovisual interactions supporting interactive and not independent coactivation models. The time course of this interaction suggests that the audiovisual integration occurred after low-level, sensory processing but well before the execution of the motor response.},
	pages = {755--759},
	number = {6},
	journaltitle = {Psychophysiology},
	author = {Schröger, Erich and Widmann, Andreas},
	urldate = {2019-01-25},
	date = {1998},
	langid = {english},
	keywords = {Redundant target effect, Audiovisual integration, Crossmodal interaction},
	file = {Snapshot:/home/felix/Zotero/storage/VMZ74PTA/1469-8986.html:text/html}
}

@article{stein_neurons_1988-1,
	title = {Neurons and behavior: the same rules of multisensory integration apply},
	volume = {448},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/0006899388912760},
	doi = {10.1016/0006-8993(88)91276-0},
	shorttitle = {Neurons and behavior},
	abstract = {Combinations of different sensory cues (e.g. auditory and visual) that are coincident in space enhance the responses of multisensory superior colliculus neurons, while the responses of these same neurons are depressed if the stimuli are separated in space. Using a behavioral paradigm modeled after that used in physiological studies, the present experiments demonstrate that the rules governing multisensory integration at the level of the single neuron also predict the responses to these stimuli in the intact behaving animal.},
	pages = {355--358},
	number = {2},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Stein, Barry E. and Scott Huneycutt, W. and Alex Meredith, M.},
	urldate = {2019-01-25},
	date = {1988-05-17},
	keywords = {Audition, Vision, Behavior, Neurophysiology, Orientation},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/9BPSP24F/Stein et al. - 1988 - Neurons and behavior the same rules of multisenso.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/QA2K5RMB/0006899388912760.html:text/html}
}

@article{stein_behavioral_1989-2,
	title = {Behavioral Indices of Multisensory Integration: Orientation to Visual Cues is Affected by Auditory Stimuli},
	volume = {1},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn.1989.1.1.12},
	doi = {10.1162/jocn.1989.1.1.12},
	shorttitle = {Behavioral Indices of Multisensory Integration},
	abstract = {Physiological studies have demonstrated that inputs from different sensory modalities converge on, and are integrated by, individual superior colliculus neurons and that this integration is governed by specific spatial rules. The present experiments were an attempt to relate these neural processes to overt behavior by determining if behaviors believed to involve the circuitry of the superior colliculus would show similar multisensory dependencies and be subject to the same rules of integration. The neurophysiological-behavioral parallels proved to be striking. The effectiveness of a stimulus of one modality in eliciting attentive and orientation behaviors was dramatically affected by the presence of a stimulus from another modality in each of the three behavioral paradigms used here. Animals trained to approach a low intensity visual cue had their performance significantly enhanced when a brief, low intensity auditory stimulus was presented at the same location as the visual cue, but their performance was significantly depressed when the auditory stimulus was disparate to it. These effects were independent of the animals' experience with the modifying (i.e. auditory) stimulus and exceeded what might have been predicted statistically based on the animals' performance with each single-modality cue. The multiplicative nature of these multisensory interactions and their dependence on the relative positions and intensities of the two stimuli were all very similar to those observed physiologically for single cells. The few differences that were observed appeared to reflect the fact that understanding integration at the level of the single cell requires reference to the individual cell's multisensory receptive field properties, while at the behavioral level populations of receptive fields must be evaluated. These data illustrate that the rules governing multisensory integration at the level of the single cell also predict responses to these stimuli in the intact behaving organism.},
	pages = {12--24},
	number = {1},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Stein, Barry E. and Meredith, M. Alex and Huneycutt, W. Scott and {McDade}, Lawrence},
	urldate = {2019-01-25},
	date = {1989-01-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/YDN9WD2U/Stein et al. - 1989 - Behavioral Indices of Multisensory Integration Or.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/U8I5RUM3/jocn.1989.1.1.html:text/html}
}

@article{ohare_perceptual_1991,
	title = {Perceptual Integration},
	volume = {81},
	issn = {0043-0439},
	url = {https://www.jstor.org/stable/24536134},
	abstract = {[The concept of perceptual integration and evidence for that phenomenon is assessed with a review of representative experimental studies with complex activities in the areas of haptic, auditory, and visual performance by human observers. The phenomenon can be defined as a process of the sensory input systems that facilitates object recognition both within and across modalities. It is concluded that there are a sufficient number of positive behavioral findings in support of an integrative process, and experimental techniques are available that show promise for the direct observation of it mechanisms.]},
	pages = {44--59},
	number = {1},
	journaltitle = {Journal of the Washington Academy of Sciences},
	author = {O'Hare, John J.},
	urldate = {2019-01-25},
	date = {1991}
}

@article{ohare_perceptual_1991-1,
	title = {Perceptual Integration},
	volume = {81},
	issn = {0043-0439},
	url = {https://www.jstor.org/stable/24536134},
	abstract = {[The concept of perceptual integration and evidence for that phenomenon is assessed with a review of representative experimental studies with complex activities in the areas of haptic, auditory, and visual performance by human observers. The phenomenon can be defined as a process of the sensory input systems that facilitates object recognition both within and across modalities. It is concluded that there are a sufficient number of positive behavioral findings in support of an integrative process, and experimental techniques are available that show promise for the direct observation of it mechanisms.]},
	pages = {44--59},
	number = {1},
	journaltitle = {Journal of the Washington Academy of Sciences},
	author = {O'Hare, John J.},
	urldate = {2019-01-25},
	date = {1991}
}

@article{roeber_auditory_2003,
	title = {Auditory distraction by duration and location deviants: a behavioral and event-related potential study},
	volume = {17},
	issn = {0926-6410},
	url = {http://www.sciencedirect.com/science/article/pii/S0926641003001368},
	doi = {10.1016/S0926-6410(03)00136-8},
	shorttitle = {Auditory distraction by duration and location deviants},
	abstract = {Auditory distractibility was investigated using four noise stimuli that differed in their duration and/or sound source. In the duration-task/location-deviant condition, participants were asked to discriminate between equiprobable short and long stimuli. Mostly, stimuli were presented from one location (Standards), but, infrequently, a stimulus was presented from another location (Deviant). In the location-task/duration-deviant condition, participants had to discriminate between stimuli presented equiprobably from the speaker in front of them or to their left. Here, most stimuli were of equal duration (Standards), but, infrequently, a stimulus duration changed (Deviant). The rare deviations in location and duration were irrelevant for the actual task. Whether they affected processes related to the actual task was assessed with performance- and event-related potential ({ERP}) measures. In both conditions, responses to Deviants were slowed compared to responses to Standards. Deviants elicited {ERP} components mismatch negativity ({MMN}), P3a and reorienting negativity ({RON}). These results show that the processing of both a sound’s duration and a sound’s location can be distracted by rare, but irrelevant, changes in its location and duration, respectively. Behavioral distraction effects were markedly smaller with duration Deviants. It is suggested that duration Deviants interfere with task-related processing at later stages than location Deviants, as the processing of task-relevant information (i.e. stimulus location) commences before deviation in the location-task/duration-deviant condition occurs. Interestingly, distraction effects also prevail in the first Standard stimulus after a Deviant, as indicated by the prolonged response times and late negativity in the {ERPs}.},
	pages = {347--357},
	number = {2},
	journaltitle = {Cognitive Brain Research},
	shortjournal = {Cognitive Brain Research},
	author = {Roeber, Urte and Widmann, Andreas and Schröger, Erich},
	urldate = {2019-01-25},
	date = {2003-07-15},
	keywords = {Auditory distraction, Duration deviant, Involuntary attention, Location deviant, {MMN}, P3a, {RON}},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/UX2ALDTP/Roeber et al. - 2003 - Auditory distraction by duration and location devi.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/WPJBLCIK/S0926641003001368.html:text/html}
}

@online{noauthor_speeded_nodate,
	title = {Speeded responses to audiovisual signal changes result from bimodal integration - Schröger - 1998 - Psychophysiology - Wiley Online Library},
	url = {https://onlinelibrary-wiley-com.ezproxy.ub.unimaas.nl/doi/abs/10.1111/1469-8986.3560755},
	urldate = {2019-01-25},
	file = {Speeded responses to audiovisual signal changes result from bimodal integration - Schröger - 1998 - Psychophysiology - Wiley Online Library:/home/felix/Zotero/storage/VD3Y8IL3/1469-8986.html:text/html}
}

@article{schroger_speeded_1998-1,
	title = {Speeded responses to audiovisual signal changes result from bimodal integration},
	volume = {35},
	rights = {Copyright © 2003 Society for Psychophysiological Research},
	issn = {1469-8986},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1111/1469-8986.3560755},
	doi = {10.1111/1469-8986.3560755},
	abstract = {Integration of auditory and visual information was studied in humans detecting targets (i.e., location changes of the auditory, the visual, or both parts of a repetitively presented audiovisual stimulus). Behavioral results suggest that the time advantage to bimodal compared with unimodal targets was due to combined rather than separate processing of the auditory and the visual target information. Event-related brain potential results revealed strong audiovisual interactions supporting interactive and not independent coactivation models. The time course of this interaction suggests that the audiovisual integration occurred after low-level, sensory processing but well before the execution of the motor response.},
	pages = {755--759},
	number = {6},
	journaltitle = {Psychophysiology},
	author = {Schröger, Erich and Widmann, Andreas},
	urldate = {2019-01-25},
	date = {1998},
	langid = {english},
	keywords = {Redundant target effect, Audiovisual integration, Crossmodal interaction},
	file = {Full Text PDF:/home/felix/Zotero/storage/MDHWWZJ3/Schröger and Widmann - 1998 - Speeded responses to audiovisual signal changes re.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/H9SQUCY9/1469-8986.html:text/html}
}

@book{todd_reaction_1912,
	title = {Reaction to multiple stimuli},
	series = {Reaction to multiple stimuli},
	abstract = {The questions of reaction to simultaneous and to successive stimuli have received but little attention. They are important as they furnish more or less definite solutions to the older problems concerning the nature of the sensory-motor event in the various responses to stimuli, and suggest new problems for investigation. They also throw a side-light on the questions of the relation between intensities of stimuli, types of attention, and reaction-time. This book examines the reaction to stimuli. It looks at the production of stimuli, the reaction to simultaneous stimuli and successive stimuli, and reenforcement and inhibition. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pagetotal = {iii, 65},
	publisher = {The Science Press},
	author = {Todd, John Welhoff},
	date = {1912},
	doi = {10.1037/13053-000},
	keywords = {Reaction Time, Reinforcement, Stimulation},
	file = {Snapshot:/home/felix/Zotero/storage/DD5UQY7I/2008-13876-000.html:text/html;Submitted Version:/home/felix/Zotero/storage/3XH37EMS/Todd - 1912 - Reaction to multiple stimuli.pdf:application/pdf}
}

@article{kinchla_detecting_1974,
	title = {Detecting target elements in multielement arrays: A confusability model},
	volume = {15},
	issn = {0031-5117, 1532-5962},
	url = {http://www.springerlink.com/index/10.3758/BF03205843},
	doi = {10.3758/BF03205843},
	shorttitle = {Detecting target elements in multielement arrays},
	pages = {149--158},
	number = {1},
	journaltitle = {Perception \& Psychophysics},
	author = {Kinchla, R. A.},
	urldate = {2019-01-27},
	date = {1974-01},
	langid = {english},
	file = {Kinchla - 1974 - Detecting target elements in multielement arrays .pdf:/home/felix/Zotero/storage/CG8CG65I/Kinchla - 1974 - Detecting target elements in multielement arrays .pdf:application/pdf}
}

@article{colonius_race_2006,
	title = {The race model inequality: Interpreting a geometric measure of the amount of violation.},
	volume = {113},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/0033-295X.113.1.148},
	doi = {10.1037/0033-295X.113.1.148},
	shorttitle = {The race model inequality},
	abstract = {An inequality by J. O. Miller (1982) has become the standard tool to test the race model for redundant signals reaction times ({RTs}), as an alternative to a neural summation mechanism. It stipulates that the {RT} distribution function to redundant stimuli is never larger than the sum of the distribution functions for 2 single stimuli. When many different experimental conditions are to be compared, a numerical index of violation is very desirable. Widespread practice is to take a certain area with contours defined by the distribution functions for single and redundant stimuli. Here this area is shown to equal the difference between 2 mean {RT} values. This result provides an intuitive interpretation of the index and makes it amenable to simple statistical testing. An extension of this approach to 3 redundant signals is presented.},
	pages = {148--154},
	number = {1},
	journaltitle = {Psychological Review},
	author = {Colonius, Hans and Diederich, Adele},
	urldate = {2019-01-28},
	date = {2006},
	langid = {english},
	file = {Colonius and Diederich - 2006 - The race model inequality Interpreting a geometri.pdf:/home/felix/Zotero/storage/PMAKY7F3/Colonius and Diederich - 2006 - The race model inequality Interpreting a geometri.pdf:application/pdf}
}

@article{diederich_probability_1992,
	title = {Probability inequalities for testing separate activation models of divided attention},
	volume = {52},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03211708},
	doi = {10.3758/BF03211708},
	abstract = {A test for separate activation models of reaction time proposed by Miller (1982) is generalized to apply to situations with more than two redundant targets.},
	pages = {714--716},
	number = {6},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Diederich, Adelei},
	urldate = {2019-01-28},
	date = {1992-11-01},
	langid = {english},
	keywords = {Coactivation Model, Intersensory Facilitation, Multiple Stimulus, Redundant Target, Separate Activation},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/HX8YHQHT/Diederich - 1992 - Probability inequalities for testing separate acti.pdf:application/pdf}
}

@article{gondan_testing_2008,
	title = {Testing the race inequality: A simple correction procedure for fast guesses},
	volume = {52},
	issn = {0022-2496},
	url = {http://www.sciencedirect.com/science/article/pii/S002224960800076X},
	doi = {10.1016/j.jmp.2008.08.002},
	shorttitle = {Testing the race inequality},
	abstract = {In speeded response tasks with redundant signals, parallel processing of the redundant signals is generally tested using the so-called race inequality. The race inequality states that the distribution of fast responses for a redundant stimulus never exceeds the summed distributions of fast responses for the single stimuli. It has been pointed out that fast guesses (e.g. anticipatory responses) interfere with this test, and a correction procedure (‘kill-the-twin’ procedure) has been suggested. In this note we formally derive this procedure and extend it to the case in which redundant stimuli are presented with onset asynchrony. We demonstrate how the kill-the-twin procedure is used in a statistical test of the race model prediction.},
	pages = {322--325},
	number = {5},
	journaltitle = {Journal of Mathematical Psychology},
	shortjournal = {Journal of Mathematical Psychology},
	author = {Gondan, Matthias and Heckel, Andreas},
	urldate = {2019-01-28},
	date = {2008-10-01},
	keywords = {Multisensory processing, Divided attention, Race model},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/QWV6KSDL/Gondan and Heckel - 2008 - Testing the race inequality A simple correction p.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/RD8KB48H/S002224960800076X.html:text/html}
}

@article{sperdin_behavioral_2010,
	title = {The behavioral relevance of multisensory neural response interactions},
	volume = {3},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/neuro.01.009.2010/full},
	doi = {10.3389/neuro.01.009.2010},
	abstract = {Sensory information can interact to impact perception and behavior. Foods are appreciated according to their appearance, smell, taste, and texture. Athletes and dancers combine visual, auditory, and somatosensory information to coordinate their movements. Under laboratory settings, detection and discrimination are likewise facilitated by multisensory signals. Research over the past several decades has shown both that the requisite anatomy exists to support interactions between sensory systems in regions canonically designated as exclusively unisensory in their function and more recently that neural response interactions occur within these same regions, including even primary cortices and thalamic nuclei, at early post-stimulus latencies. Here, we review evidence concerning direct links between early, low-level neural response interactions and behavioral measures of multisensory integration.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Sperdin, Holger F. and Cappe, Céline and Murray, Micah M.},
	urldate = {2019-01-28},
	date = {2010},
	keywords = {Brain, multisensory, Reaction Time, Neurophysiology, crossmodal, brain imaging, event-related potential ({ERP}), human},
	file = {Full Text PDF:/home/felix/Zotero/storage/JPXCW6R9/Sperdin et al. - 2010 - The behavioral relevance of multisensory neural re.pdf:application/pdf}
}

@article{molholm_multisensory_2002,
	title = {Multisensory auditory–visual interactions during early sensory processing in humans: a high-density electrical mapping study},
	volume = {14},
	issn = {0926-6410},
	url = {http://www.sciencedirect.com/science/article/pii/S0926641002000666},
	doi = {10.1016/S0926-6410(02)00066-6},
	series = {Multisensory Proceedings},
	shorttitle = {Multisensory auditory–visual interactions during early sensory processing in humans},
	abstract = {Integration of information from multiple senses is fundamental to perception and cognition, but when and where this is accomplished in the brain is not well understood. This study examined the timing and topography of cortical auditory–visual interactions using high-density event-related potentials ({ERPs}) during a simple reaction-time ({RT}) task. Visual and auditory stimuli were presented alone and simultaneously. {ERPs} elicited by the auditory and visual stimuli when presented alone were summed (‘sum’ {ERP}) and compared to the {ERP} elicited when they were presented simultaneously (‘simultaneous’ {ERP}). Divergence between the ‘simultaneous’ and ‘sum’ {ERP} indicated auditory–visual ({AV}) neural response interactions. There was a surprisingly early right parieto-occipital {AV} interaction, consistent with the finding of an earlier study [J. Cogn. Neurosci. 11 (1999) 473]. The timing of onset of this effect (46 ms) was essentially simultaneous with the onset of visual cortical processing, as indexed by the onset of the visual C1 component, which is thought to represent the earliest cortical visual evoked potential. The coincident timing of the early {AV} interaction and C1 strongly suggests that {AV} interactions can affect early visual sensory processing. Additional {AV} interactions were found within the time course of sensory processing (up to 200 ms post stimulus onset). In total, this system of {AV} effects over the scalp was suggestive of both activity unique to multisensory processing, and the modulation of ‘unisensory’ activity. {RTs} to the stimuli when presented simultaneously were significantly faster than when they were presented alone. This {RT} facilitation could not be accounted for by probability summation, as evidenced by violation of the ‘race’ model, providing compelling evidence that auditory–visual neural interactions give rise to this {RT} effect.},
	pages = {115--128},
	number = {1},
	journaltitle = {Cognitive Brain Research},
	shortjournal = {Cognitive Brain Research},
	author = {Molholm, Sophie and Ritter, Walter and Murray, Micah M and Javitt, Daniel C and Schroeder, Charles E and Foxe, John J},
	urldate = {2019-01-28},
	date = {2002-06-01},
	keywords = {Multisensory, Visual, Electrophysiology, Auditory, {ERPs}},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/LAME3IBU/Molholm et al. - 2002 - Multisensory auditory–visual interactions during e.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/E2N7XBYY/S0926641002000666.html:text/html}
}

@article{hughes_visual-auditory_1994,
	title = {Visual-auditory interactions in sensorimotor processing: saccades versus manual responses},
	volume = {20},
	issn = {0096-1523},
	shorttitle = {Visual-auditory interactions in sensorimotor processing},
	abstract = {Reaction times ({RTs}) to bimodal (visual and auditory) stimuli were examined using 3 different response systems: saccades, directed manual responses, and simple manual responses. The observed levels of intersensory facilitation exceeded race model predictions and therefore support summation (coactivation) models of bimodal processing. However, response-dependent differences suggest that the processing of bimodal targets also depends on the relevant sensorimotor pathways and requirements of the task. Coactivation of response mechanisms might account for the effects found using simple {RTs}. The results for saccades are consistent with known patterns of auditory-visual convergence in the oculomotor system.},
	pages = {131--153},
	number = {1},
	journaltitle = {Journal of Experimental Psychology. Human Perception and Performance},
	shortjournal = {J Exp Psychol Hum Percept Perform},
	author = {Hughes, H. C. and Reuter-Lorenz, P. A. and Nozawa, G. and Fendrich, R.},
	date = {1994-02},
	pmid = {8133219},
	keywords = {Reaction Time, Acoustic Stimulation, Female, Humans, Male, Photic Stimulation, Saccades, Visual Perception},
	file = {Hughes et al. - Visual-Auditory Interactions in Sensorimotor Proce.pdf:/home/felix/Zotero/storage/IIKW2NJZ/Hughes et al. - Visual-Auditory Interactions in Sensorimotor Proce.pdf:application/pdf}
}

@article{miller_timecourse_1986,
	title = {Timecourse of coactivation in bimodal divided attention},
	volume = {40},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03203025},
	doi = {10.3758/BF03203025},
	abstract = {Reaction time distributions were obtained from practiced subjects in a go/no-go detection task with attention divided across the visual and auditory modalities. Redundant signals were sometimes presented asynchronously on the two modalities, with the time between signals varying from 0 to 167 msec. An extension of the inequality derived by Miller (1982) was used to test between separate-decisions models, in which the response is initiated solely by whichever signal is detected first, and coactivation models, in which both signals contribute to the activation of a single response. As in previous studies with bimodal detection tasks, the results contradicted separate-decisions models and favored coactivation models. The largest violations of separate-decisions models were observed when the visual signal was presented 67–100 msec before the auditory signal. A new inequality was also derived to discriminate between two classes of coactivation models that differ about whether responses are generated by processes combining activation across time as well as across signals. Violations of this inequality ruled out exponential coactivation models, in which activation processes are sensitive only to the instantaneous properties of the signal(s). Instead, the results require an accumulation model of coactivation, in which both signals provide input to a process that accumulates activation over a considerable period of time, even if signal conditions change during that time.},
	pages = {331--343},
	number = {5},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Miller, Jeff},
	urldate = {2019-01-28},
	date = {1986-09-01},
	langid = {english},
	keywords = {Accumulation Model, Auditory Signal, Catch Trial, Race Model, Visual Signal},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/IB7GQELT/Miller - 1986 - Timecourse of coactivation in bimodal divided atte.pdf:application/pdf}
}

@article{nava_audio-tactile_2014-1,
	title = {Audio-Tactile Integration in Congenitally and Late Deaf Cochlear Implant Users},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0099606},
	doi = {10.1371/journal.pone.0099606},
	abstract = {Several studies conducted in mammals and humans have shown that multisensory processing may be impaired following congenital sensory loss and in particular if no experience is achieved within specific early developmental time windows known as sensitive periods. In this study we investigated whether basic multisensory abilities are impaired in hearing-restored individuals with deafness acquired at different stages of development. To this aim, we tested congenitally and late deaf cochlear implant ({CI}) recipients, age-matched with two groups of hearing controls, on an audio-tactile redundancy paradigm, in which reaction times to unimodal and crossmodal redundant signals were measured. Our results showed that both congenitally and late deaf {CI} recipients were able to integrate audio-tactile stimuli, suggesting that congenital and acquired deafness does not prevent the development and recovery of basic multisensory processing. However, we found that congenitally deaf {CI} recipients had a lower multisensory gain compared to their matched controls, which may be explained by their faster responses to tactile stimuli. We discuss this finding in the context of reorganisation of the sensory systems following sensory loss and the possibility that these changes cannot be “rewired” through auditory reafferentation.},
	pages = {e99606},
	number = {6},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Nava, Elena and Bottari, Davide and Villwock, Agnes and Fengler, Ineke and Büchner, Andreas and Lenarz, Thomas and Röder, Brigitte},
	urldate = {2019-01-28},
	date = {2014-06-11},
	langid = {english},
	keywords = {Vision, Reaction time, Deafness, Audio signal processing, Cataracts, Cognitive impairment, Sensory perception, Visual impairments},
	file = {Full Text PDF:/home/felix/Zotero/storage/RBI9VDQF/Nava et al. - 2014 - Audio-Tactile Integration in Congenitally and Late.pdf:application/pdf}
}

@online{noauthor_tactile_nodate-1,
	title = {Tactile Functions of Mechanoreceptive Afferents Innervating the Hand {\textbar} Ovid},
	url = {https://oce.ovid.com/article/00004691-200011000-00002/HTML},
	urldate = {2019-01-28},
	file = {Tactile Functions of Mechanoreceptive Afferents Innervating the Hand | Ovid:/home/felix/Zotero/storage/INWJFRG2/HTML.html:text/html}
}

@article{johnson_tactile_2000,
	title = {Tactile functions of mechanoreceptive afferents innervating the hand},
	volume = {17},
	issn = {0736-0258},
	abstract = {Four types of mechanoreceptive afferents innervate the glabrous skin of the hand. Evidence from more than three decades of combined psychophysical and neurophysiological research supports the idea that each afferent type serves a distinctly different sensory function and that these functions explain most of tactual perceptual function. The available evidence supports the following hypotheses: (1) The slowly adapting type 1 system provides the information on which form and texture perception are based. (2) The cutaneous rapidly adapting system provides information about minute skin motion and, thereby, plays a critical role in grip control. (3) The Pacinian system is responsible for the detection and perception of distant events by vibrations transmitted through objects, probes, and tools held in the hand. (4) The slowly adapting type 2 system provides information for the perception of hand conformation and for the perception of forces acting on the hand. The authors review the evidence on which these hypotheses are based. They also review the role of proprioceptive afferents in the perception of hand conformation because they appear to play a significant role along with cutaneous afferents.},
	pages = {539--558},
	number = {6},
	journaltitle = {Journal of Clinical Neurophysiology: Official Publication of the American Electroencephalographic Society},
	shortjournal = {J Clin Neurophysiol},
	author = {Johnson, K. O. and Yoshioka, T. and Vega-Bermudez, F.},
	date = {2000-11},
	pmid = {11151974},
	keywords = {Hand, Perception, Humans, Afferent Pathways, Animals, Discrimination Learning, Mechanoreceptors, Pacinian Corpuscles, Proprioception}
}

@article{ulrich_testing_2007,
	title = {Testing the race model inequality: An algorithm and computer programs},
	volume = {39},
	issn = {1554-3528},
	url = {https://doi.org/10.3758/BF03193160},
	doi = {10.3758/BF03193160},
	shorttitle = {Testing the race model inequality},
	abstract = {In divided-attention tasks, responses are faster when two target stimuli are presented, and thus one is redundant, than when only a single target stimulus is presented. Raab (1962) suggested an account of this redundanttargets effect in terms of a race model in which the response to redundant target stimuli is initiated by the faster of two separate target detection processes. Such models make a prediction about the probability distributions of reaction times that is often calledthe race model inequality, and it is often of interest to test this prediction. In this article, we describe a precise algorithm that can be used to test the race model inequality and present {MATLAB} routines and a Pascal program that implement this algorithm.},
	pages = {291--302},
	number = {2},
	journaltitle = {Behavior Research Methods},
	shortjournal = {Behavior Research Methods},
	author = {Ulrich, Rolf and Miller, Jeff and Schröter, Hannes},
	urldate = {2019-02-05},
	date = {2007-05-01},
	langid = {english},
	keywords = {Redundancy Gain, Race Model, Reaction Time Distribution, Specific Software Requirement, Stimulus Condition},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/H68689QU/Ulrich et al. - 2007 - Testing the race model inequality An algorithm an.pdf:application/pdf}
}

@book{goldstein_sensation_2016,
	location = {Boston, {MA}},
	edition = {Tenth edition.},
	title = {Sensation and perception},
	isbn = {978-1-305-58029-9 978-1-305-67404-2},
	pagetotal = {xix, 460},
	publisher = {Cengage Learning},
	author = {Goldstein, E. Bruce and Brockmole, James R.},
	date = {2016}
}

@article{lange_perception_2011,
	title = {Perception of the touch-induced visual double-flash illusion correlates with changes of rhythmic neuronal activity in human visual and somatosensory areas},
	volume = {54},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811910012127},
	doi = {10.1016/j.neuroimage.2010.09.031},
	abstract = {A single brief visual stimulus accompanied by two brief tactile stimuli is frequently perceived incorrectly as two flashes, a phenomenon called double-flash illusion ({DFI}). We investigated whether the {DFI} is accompanied by changes in rhythmic neuronal activity, using magnetoencephalography in human subjects. Twenty-two subjects received visuo-tactile stimulation and reported the number of perceived visual stimuli. We sorted trials with identical physical stimulation according to the reported subjective percept and assessed differences in spectral power in somatosensory and occipital sensors. In {DFI} trials, occipital sensors displayed a contralateral enhancement of gamma-band (80–140Hz) activity in response to stimulation. In somatosensory sensors, the {DFI} was associated with an increase of spectral power for low frequencies (5–17.5Hz) around stimulation and a decrease of spectral power in the 22.5–30Hz range between 450 and 750ms post-stimulation. In summary, several components of rhythmic activity predicted variable subjective experience for constant physical stimulation. Notably, the enhanced occipital gamma-band activity during {DFI} was similar in time and frequency extent to the somatosensory gamma-band response to tactile stimulation. We speculate that the {DFI} might therefore occur when the somatosensory gamma-response is transmitted to visual cortex. This transmission might be supported by the observed modulations in low-frequency activity.},
	pages = {1395--1405},
	number = {2},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Lange, Joachim and Oostenveld, Robert and Fries, Pascal},
	urldate = {2019-02-10},
	date = {2011-01-15},
	keywords = {Somatosensory, Visual, Illusion, {MEG}, Oscillation},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/QEXUTMEW/S1053811910012127.html:text/html}
}

@article{violentyev_touch-induced_2005,
	title = {Touch-induced visual illusion},
	volume = {5},
	issn = {1534-7362},
	url = {https://jov.arvojournals.org/article.aspx?articleid=2132543},
	doi = {10.1167/5.8.754},
	pages = {754--754},
	number = {8},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Violentyev, Artem and Shimojo, Shinsuke and Shams, Ladan},
	urldate = {2019-02-10},
	date = {2005-09-01},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/3YYEAWVY/article.html:text/html;Submitted Version:/home/felix/Zotero/storage/WCDFVY26/Violentyev et al. - 2005 - Touch-induced visual illusion.pdf:application/pdf}
}

@article{karns_altered_2012-1,
	title = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults: A Visual-Somatosensory {fMRI} Study with a Double-Flash Illusion},
	volume = {32},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.6488-11.2012},
	doi = {10.1523/JNEUROSCI.6488-11.2012},
	shorttitle = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults},
	pages = {9626--9638},
	number = {28},
	journaltitle = {Journal of Neuroscience},
	author = {Karns, C. M. and Dow, M. W. and Neville, H. J.},
	urldate = {2019-02-10},
	date = {2012-07-11},
	langid = {english},
	file = {Karns et al. - 2012 - Altered Cross-Modal Processing in the Primary Audi.pdf:/home/felix/Zotero/storage/EQVXNSAI/Karns et al. - 2012 - Altered Cross-Modal Processing in the Primary Audi.pdf:application/pdf}
}

@article{hotting_hearing_2004,
	title = {Hearing Cheats Touch, but Less in Congenitally Blind Than in Sighted Individuals},
	volume = {15},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/j.0963-7214.2004.01501010.x},
	doi = {10.1111/j.0963-7214.2004.01501010.x},
	abstract = {The principles of cross-modal integration were investigated with an auditory-tactile illusion in sighted and con-genitally blind adults. Participants had to judge the number of rapidly presented tactile stimuli, which were presented together with task-irrelevant sounds. When one tactile stimulus was accompanied by more than one tone, participants reported perceiving more than a single touch. This illusion was more pronounced in sighted than congenitally blind participants. Given that the congenitally blind were more precise in judging the number of tactile stimuli in a control condition without tones, the present data are in accordance with a modality-appropriateness account suggesting that interference by a task-irrelevant modality is reduced if processing accuracy of the task-relevant modality is high.},
	pages = {60--64},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Hötting, Kirsten and Röder, Brigitte},
	urldate = {2019-02-10},
	date = {2004-01-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/AEIRCYQ7/Hötting and Röder - 2004 - Hearing Cheats Touch, but Less in Congenitally Bli.pdf:application/pdf}
}

@article{gilley_influence_2010,
	title = {The influence of a sensitive period for auditory-visual integration in children with cochlear implants},
	volume = {28},
	issn = {0922-6028},
	url = {https://content.iospress.com/articles/restorative-neurology-and-neuroscience/rnn00525},
	doi = {10.3233/RNN-2010-0525},
	abstract = {Purpose: Children who experience long periods of auditory deprivation are susceptible to large-scale reorganization of auditory cortical areas responsible for the perception of speech and language. One consequence of this reorganization is that integ},
	pages = {207--218},
	number = {2},
	journaltitle = {Restorative Neurology and Neuroscience},
	author = {Gilley, Phillip M. and Sharma, Anu and Mitchell, Teresa V. and Dorman, Michael F.},
	urldate = {2019-02-10},
	date = {2010-01-01},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/7YUMRMEQ/rnn00525.html:text/html}
}

@article{landry_temporary_2013-1,
	title = {Temporary Deafness Can Impair Multisensory Integration: A Study of Cochlear-Implant Users},
	volume = {24},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797612471142},
	doi = {10.1177/0956797612471142},
	shorttitle = {Temporary Deafness Can Impair Multisensory Integration},
	abstract = {Previous investigations suggest that temporary deafness can have a dramatic impact on audiovisual speech processing. The aim of this study was to test whether temporary deafness disturbs other multisensory processes in adults. A nonspeech task involving an audiotactile illusion was administered to a group of normally hearing individuals and a group of individuals who had been temporarily auditorily deprived. Members of this latter group had their auditory detection thresholds restored to normal levels through the use of a cochlear implant. Control conditions revealed that auditory and tactile discrimination capabilities were identical in the two groups. However, whereas normally hearing individuals integrated auditory and tactile information, so that they experienced the audiotactile illusion, individuals who had been temporarily deprived did not. Given the basic nature of the task, failure to integrate multisensory information could not be explained by the use of the cochlear implant. Thus, the results suggest that normally anticipated audiotactile interactions are disturbed following temporary deafness.},
	pages = {1260--1268},
	number = {7},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Landry, Simon P. and Guillemot, Jean-Paul and Champoux, François},
	urldate = {2019-02-10},
	date = {2013-07-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/ICEXIYIJ/Landry et al. - 2013 - Temporary Deafness Can Impair Multisensory Integra.pdf:application/pdf}
}

@online{noauthor_two-way_nodate,
	title = {Two-way {ANOVA} in {SPSS} Statistics - Step-by-step procedure including testing of assumptions {\textbar} Laerd Statistics},
	url = {https://statistics.laerd.com/spss-tutorials/two-way-anova-using-spss-statistics.php},
	urldate = {2019-02-10},
	file = {Two-way ANOVA in SPSS Statistics - Step-by-step procedure including testing of assumptions | Laerd Statistics:/home/felix/Zotero/storage/RF6RSHQC/two-way-anova-using-spss-statistics.html:text/html}
}

@article{goldreich_tactile_2003-1,
	title = {Tactile Acuity is Enhanced in Blindness},
	volume = {23},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.23-08-03439.2003},
	doi = {10.1523/JNEUROSCI.23-08-03439.2003},
	pages = {3439--3445},
	number = {8},
	journaltitle = {The Journal of Neuroscience},
	author = {Goldreich, Daniel and Kanics, Ingrid M.},
	urldate = {2019-05-02},
	date = {2003-04-15},
	langid = {english},
	file = {Goldreich and Kanics - 2003 - Tactile Acuity is Enhanced in Blindness.pdf:/home/felix/Zotero/storage/B2RSR3J3/Goldreich and Kanics - 2003 - Tactile Acuity is Enhanced in Blindness.pdf:application/pdf}
}

@article{norman_blindness_2011,
	title = {Blindness enhances tactile acuity and haptic 3-D shape discrimination},
	volume = {73},
	issn = {1943-393X},
	url = {https://doi.org/10.3758/s13414-011-0160-4},
	doi = {10.3758/s13414-011-0160-4},
	abstract = {This study compared the sensory and perceptual abilities of the blind and sighted. The 32 participants were required to perform two tasks: tactile grating orientation discrimination (to determine tactile acuity) and haptic three-dimensional (3-D) shape discrimination. The results indicated that the blind outperformed their sighted counterparts (individually matched for both age and sex) on both tactile tasks. The improvements in tactile acuity that accompanied blindness occurred for all blind groups (congenital, early, and late). However, the improvements in haptic 3-D shape discrimination only occurred for the early-onset and late-onset blindness groups; the performance of the congenitally blind was no better than that of the sighted controls. The results of the present study demonstrate that blindness does lead to an enhancement of tactile abilities, but they also suggest that early visual experience may play a role in facilitating haptic 3-D shape discrimination.},
	pages = {2323--2331},
	number = {7},
	journaltitle = {Attention, Perception, \& Psychophysics},
	shortjournal = {Atten Percept Psychophys},
	author = {Norman, J. Farley and Bartholomew, Ashley N.},
	urldate = {2019-05-02},
	date = {2011-10-01},
	langid = {english},
	keywords = {Blindness, Haptics, Shape perception},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/QWXLKXXP/Norman and Bartholomew - 2011 - Blindness enhances tactile acuity and haptic 3-D s.pdf:application/pdf}
}

@article{wong_tactile_2011,
	title = {Tactile Spatial Acuity Enhancement in Blindness: Evidence for Experience-Dependent Mechanisms},
	volume = {31},
	rights = {Copyright © 2011 the authors 0270-6474/11/317028-10\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/31/19/7028},
	doi = {10.1523/JNEUROSCI.6461-10.2011},
	shorttitle = {Tactile Spatial Acuity Enhancement in Blindness},
	abstract = {Tactile spatial acuity is enhanced in blindness, according to several studies, but the cause of this enhancement has been controversial. Two competing hypotheses are the tactile experience hypothesis (reliance on the sense of touch drives tactile-acuity enhancement) and the visual deprivation hypothesis (the absence of vision itself drives tactile-acuity enhancement). Here, we performed experiments to distinguish between these two hypotheses. We used force-controlled grating orientation tasks to compare the passive (finger stationary) tactile spatial acuity of 28 profoundly blind and 55 normally sighted humans on the index, middle, and ring fingers of each hand, and on the lips. The tactile experience hypothesis predicted that blind participants would outperform the sighted on the fingers, and that Braille reading would correlate with tactile acuity. The visual deprivation hypothesis predicted that blind participants would outperform the sighted on fingers and lips. Consistent with the tactile experience hypothesis, the blind significantly outperformed the sighted on all fingers, but not on the lips. Additionally, among blind participants, proficient Braille readers on their preferred reading index finger outperformed nonreaders. Finally, proficient Braille readers performed better with their preferred reading index finger than with the opposite index finger, and their acuity on the preferred reading finger correlated with their weekly reading time. These results clearly implicate reliance on the sense of touch as the trigger for tactile spatial acuity enhancement in the blind, and suggest the action of underlying experience-dependent neural mechanisms such as somatosensory and/or cross-modal cortical plasticity.},
	pages = {7028--7037},
	number = {19},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Wong, Michael and Gnanakumaran, Vishi and Goldreich, Daniel},
	urldate = {2019-05-02},
	date = {2011-05-11},
	langid = {english},
	pmid = {21562264},
	file = {Full Text PDF:/home/felix/Zotero/storage/M7TPCELI/Wong et al. - 2011 - Tactile Spatial Acuity Enhancement in Blindness E.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/YZ9GYLI2/7028.html:text/html}
}

@article{alary_tactile_2008,
	title = {Tactile acuity in the blind: a psychophysical study using a two-dimensional angle discrimination task},
	volume = {187},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-008-1327-7},
	doi = {10.1007/s00221-008-1327-7},
	shorttitle = {Tactile acuity in the blind},
	abstract = {Growing evidence suggests that blind subjects outperform the sighted on certain tactile discrimination tasks depending on cutaneous inputs. The purpose of this study was to compare the performance of blind (n = 14) and sighted (n = 15) subjects in a haptic angle discrimination task, depending on both cutaneous and proprioceptive feedback. Subjects actively scanned their right index finger over pairs of two-dimensional (2-D) angles (standard 90°; comparison 91–103°), identifying the larger one. Two exploratory strategies were tested: arm straight or arm flexed at the elbow so that joint movement was, respectively, mainly proximal (shoulder) or distal (wrist, finger). The mean discrimination thresholds for the sighted subjects (vision occluded) were similar for both exploratory strategies (5.7 and 5.8°, respectively). Exploratory strategy likewise did not modify threshold in the blind subjects (proximal 4.3°; distal 4.9°), but thresholds were on average lower than for the sighted subjects. A between-group comparison indicated that blind subjects had significantly lower thresholds than did the sighted subjects, but only for the proximal condition. The superior performance of the blind subjects likely represents heightened sensitivity to haptic inputs in response to visual deprivation, which, in these subjects, occurred prior to 14 years of age.},
	pages = {587--594},
	number = {4},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Alary, Flamine and Goldstein, Rachel and Duquette, Marco and Chapman, C. Elaine and Voss, Patrice and Lepore, Franco},
	urldate = {2019-05-02},
	date = {2008-06-01},
	langid = {english},
	keywords = {Human psychophysics, Haptic discrimination, Shape}
}

@article{levanen_feeling_2001-1,
	title = {Feeling vibrations: enhanced tactile sensitivity in congenitally deaf humans},
	volume = {301},
	issn = {0304-3940},
	url = {http://www.sciencedirect.com/science/article/pii/S030439400101597X},
	doi = {10.1016/S0304-3940(01)01597-X},
	shorttitle = {Feeling vibrations},
	abstract = {The human nervous system displays remarkable functional plasticity following long-term sensory deprivation. For example, the auditory cortex of congenitally deaf humans may start to process tactile information. To further explore this type of cross-modal plasticity, we examined the tactile accuracy of congenitally deaf and normal hearing subjects in frequency discrimination and in detection of random suprathreshold frequency changes within a monotonous sequence of vibratory stimuli. We found that congenital deafness can enhance the accuracy of suprathreshold tactile change detection while tactile frequency discrimination is not significantly changed, although there is a trend toward reduced thresholds. The enhanced tactile sensitivity in the deaf probably reflects both neural plasticity and increased attention directed to the stimuli. Whatever the underlying neural mechanisms might be, functional compensation following early sensory loss apparently leads the remaining sensory modalities to develop capacities exceeding those of the normal functional systems.},
	pages = {75--77},
	number = {1},
	journaltitle = {Neuroscience Letters},
	shortjournal = {Neuroscience Letters},
	author = {Levänen, Sari and Hamdorf, Dorothea},
	urldate = {2019-05-02},
	date = {2001-03-23},
	keywords = {Congenital deafness, Cross-modal processing, Intramodal processing, Tactile change detection, Tactile frequency discrimination},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/EWC6ZSRD/S030439400101597X.html:text/html}
}

@article{dewey_cortical_2015,
	title = {Cortical cross-modal plasticity following deafness measured using functional near-infrared spectroscopy},
	volume = {325},
	issn = {0378-5955},
	url = {http://www.sciencedirect.com/science/article/pii/S0378595515000726},
	doi = {10.1016/j.heares.2015.03.007},
	abstract = {Evidence from functional neuroimaging studies suggests that the auditory cortex can become more responsive to visual and somatosensory stimulation following deafness, and that this occurs predominately in the right hemisphere. Extensive cross-modal plasticity in prospective cochlear implant recipients is correlated with poor speech outcomes following implantation, highlighting the potential impact of central auditory plasticity on subsequent aural rehabilitation. Conversely, the effects of hearing restoration with a cochlear implant on cortical plasticity are less well understood, since the use of most neuroimaging techniques in {CI} recipients is either unsafe or problematic due to the electromagnetic artefacts generated by {CI} stimulation. Additionally, techniques such as functional magnetic resonance imaging ({fMRI}) are confounded by acoustic noise produced by the scanner that will be perceived more by hearing than by deaf individuals. Subsequently it is conceivable that auditory responses to acoustic noise produced by the {MR} scanner may mask auditory cortical responses to non-auditory stimulation, and render inter-group comparisons less significant. Uniquely, functional near-infrared spectroscopy ({fNIRS}) is a silent neuroimaging technique that is non-invasive and completely unaffected by the presence of a {CI}. Here, we used {fNIRS} to study temporal-lobe responses to auditory, visual and somatosensory stimuli in thirty profoundly-deaf participants and thirty normally-hearing controls. Compared with silence, acoustic noise stimuli elicited a significant group {fNIRS} response in the temporal region of normally-hearing individuals, which was not seen in profoundly-deaf participants. Visual motion elicited a larger group response within the right temporal lobe of profoundly-deaf participants, compared with normally-hearing controls. However, bilateral temporal lobe {fNIRS} activation to somatosensory stimulation was comparable in both groups. Using {fNIRS} these results confirm that auditory deprivation is associated with cross-modal plasticity of visual inputs to auditory cortex. Although we found no evidence for plasticity of somatosensory inputs, it is possible that our recordings may have included activation of somatosensory cortex that masked any group differences in auditory cortical responses due to the limited spatial resolution associated with {fNIRS}.},
	pages = {55--63},
	journaltitle = {Hearing Research},
	shortjournal = {Hearing Research},
	author = {Dewey, Rebecca S. and Hartley, Douglas E. H.},
	urldate = {2019-05-02},
	date = {2015-07-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/76WKFCNN/Dewey and Hartley - 2015 - Cortical cross-modal plasticity following deafness.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/9MHYPQ2A/S0378595515000726.html:text/html}
}

@article{lee_cross-modal_2015,
	title = {Cross-modal synaptic plasticity in adult primary sensory cortices},
	volume = {35},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438815001294},
	doi = {10.1016/j.conb.2015.08.002},
	series = {Circuit plasticity and memory},
	abstract = {Sensory loss leads to widespread adaptation of brain circuits to allow an organism to navigate its environment with its remaining senses, which is broadly referred to as cross-modal plasticity. Such adaptation can be observed even in the primary sensory cortices, and falls into two distinct categories: recruitment of the deprived sensory cortex for processing the remaining senses, which we term ‘cross-modal recruitment’, and experience-dependent refinement of the spared sensory cortices referred to as ‘compensatory plasticity.’ Here we will review recent studies demonstrating that cortical adaptation to sensory loss involves {LTP}/{LTD} and homeostatic synaptic plasticity. Cross-modal synaptic plasticity is observed in adults, hence cross-modal sensory deprivation may be an effective way to promote plasticity in adult primary sensory cortices.},
	pages = {119--126},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Lee, Hey-Kyoung and Whitt, Jessica L},
	urldate = {2019-05-02},
	date = {2015-12-01},
	file = {Accepted Version:/home/felix/Zotero/storage/3J5ZUHK9/Lee and Whitt - 2015 - Cross-modal synaptic plasticity in adult primary s.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/MEAY699G/S0959438815001294.html:text/html}
}

@article{papagno_deaf_2016,
	title = {Deaf, blind or deaf-blind: Is touch enhanced?},
	volume = {234},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-015-4488-1},
	doi = {10.1007/s00221-015-4488-1},
	shorttitle = {Deaf, blind or deaf-blind},
	abstract = {When someone looses one type of sensory input, s/he may compensate by using the sensory information conveyed by other senses. To verify whether loosing a sense or two has consequences on a spared sensory modality, namely touch, and whether these consequences depend on the type of sensory loss, we investigated the effects of deafness and blindness on temporal and spatial tactile tasks in deaf, blind and deaf-blind people. Deaf and deaf-blind people performed the spatial tactile task better than the temporal one, while blind and controls showed the opposite pattern. Deaf and deaf-blind participants were impaired in temporal discrimination as compared to controls, while deaf-blind individuals outperformed blind participants in the spatial tactile task. Overall, sensory-deprived participants did not show an enhanced tactile performance. We speculate that discriminative touch is not so relevant in humans, while social touch is. Probably, more complex tactile tasks would have revealed an increased performance in sensory-deprived people.},
	pages = {627--636},
	number = {2},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Papagno, Costanza and Cecchetto, Carlo and Pisoni, Alberto and Bolognini, Nadia},
	urldate = {2019-05-02},
	date = {2016-02-01},
	langid = {english},
	keywords = {Deafness, Blindness, Deaf-blind, Tactile spatial discrimination, Tactile temporal discrimination},
	file = {Papagno et al. - 2016 - Deaf, blind or deaf-blind Is touch enhanced.pdf:/home/felix/Zotero/storage/Z36PZN3G/Papagno et al. - 2016 - Deaf, blind or deaf-blind Is touch enhanced.pdf:application/pdf}
}

@article{heimler_response_2014,
	title = {Response speed advantage for vision does not extend to touch in early deaf adults},
	volume = {232},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-014-3852-x},
	doi = {10.1007/s00221-014-3852-x},
	abstract = {Early deaf adults typically respond faster than hearing controls when performing a speeded simple detection on visual targets. Whether this response time advantage can generalise to another intact modality (touch) or it is instead specific to visual processing remained unexplored. We tested eight early deaf adults and twelve hearing controls in a simple detection task, with visual or tactile targets delivered on the arms and occupying the same locations in external space. Catch trials were included in the experimental paradigm. Results revealed a response time advantage in deaf adults compared to hearing controls, selectively for visual targets. This advantage did not extend to touch. The number of anticipation errors was negligible and comparable in both groups. The present findings strengthen the notion that response time advantage in deaf adults emerges as a consequence of changes specific to visual processing. They also exclude the involvement of sensory-unspecific cognitive mechanisms in this improvement (e.g. increased impulsivity in initiation of response, longer-lasting sustained attention or higher motivation to perform the task). Finally, they provide initial evidence that the intact sensory modalities can reorganise independently from each other following early auditory deprivation.},
	pages = {1335--1341},
	number = {4},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Heimler, Benedetta and Pavani, Francesco},
	urldate = {2019-05-02},
	date = {2014-04-01},
	langid = {english},
	keywords = {Touch, Plasticity, Vision, Reaction time, Bilateral deafness},
	file = {Heimler and Pavani - 2014 - Response speed advantage for vision does not exten.pdf:/home/felix/Zotero/storage/JSGVDE64/Heimler and Pavani - 2014 - Response speed advantage for vision does not exten.pdf:application/pdf}
}

@article{collignon_further_2009,
	title = {Further evidence that congenitally blind participants react faster to auditory and tactile spatial targets},
	volume = {63},
	issn = {1878-7290(Electronic),1196-1961(Print)},
	doi = {10.1037/a0015415},
	abstract = {Congenital blindness is one of the rare human models to explore the role of experience-driven cross-modal compensation after early sensory deprivation. We re-examined spatial attention abilities in congenitally blind participants and sighted controls using a paradigm comparable to the one of our previous study (Collignon, Renier, Bruyer, Tranduy, \& Veraart, 2006), except that this time the auditory and tactile stimuli were now presented in sequence. Although both groups performed the task with similar accuracy, we observed that blind participants had shorter reaction times than sighted controls for the detection of spatial targets in both sensory modalities. Moreover, this finding held true for both the selective and divided attention conditions. These results not only confirm previous reports on the superiority of the blind during auditory and tactile attention tasks, but also broaden our knowledge of the mechanisms underlying cross-modal compensation. ({PsycINFO} Database Record (c) 2016 {APA}, all rights reserved)},
	pages = {287--293},
	number = {4},
	journaltitle = {Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale},
	author = {Collignon, Olivier and De Volder, Anne G.},
	date = {2009},
	keywords = {Blind, Psychophysics, Sensory Deprivation, Auditory Stimulation, Tactual Stimulation},
	file = {Snapshot:/home/felix/Zotero/storage/7K5P2E8Q/2009-24371-004.html:text/html}
}

@article{heming_sensory_2005-1,
	title = {Sensory temporal processing in adults with early hearing loss},
	volume = {59},
	issn = {0278-2626},
	url = {http://www.sciencedirect.com/science/article/pii/S027826260500093X},
	doi = {10.1016/j.bandc.2005.05.012},
	abstract = {This study examined tactile and visual temporal processing in adults with early loss of hearing. The tactile task consisted of punctate stimulations that were delivered to one or both hands by a mechanical tactile stimulator. Pairs of light emitting diodes were presented on a display for visual stimulation. Responses consisted of {YES} or {NO} judgments as to whether the onset of the pairs of stimuli was perceived simultaneously or non-simultaneously. Tactile and visual temporal thresholds were significantly higher for the deaf group when compared to controls. In contrast to controls, tactile and visual temporal thresholds for the deaf group did not differ when presentation locations were examined. Overall findings of this study support the notion that temporal processing is compromised following early deafness regardless of the spatial location in which the stimuli are presented.},
	pages = {173--182},
	number = {2},
	journaltitle = {Brain and Cognition},
	shortjournal = {Brain and Cognition},
	author = {Heming, Joanne E. and Brown, Lenora N.},
	urldate = {2019-05-02},
	date = {2005-11-01},
	keywords = {Early deafness, Hearing loss, Laterality, Sensory processing, Tactile thresholds, Temporal processing, Timing, Visual thresholds},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/HT77NUB2/S027826260500093X.html:text/html}
}

@article{moallem_measures_2010,
	title = {Measures of tactual detection and temporal order resolution in congenitally deaf and normal-hearing adults},
	volume = {127},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.3397432},
	doi = {10.1121/1.3397432},
	pages = {3696--3709},
	number = {6},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Moallem, Theodore M. and Reed, Charlotte M. and Braida, Louis D.},
	urldate = {2019-05-02},
	date = {2010-06-01},
	file = {Full Text:/home/felix/Zotero/storage/BTJVCTL5/Moallem et al. - 2010 - Measures of tactual detection and temporal order r.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/6FATKZ8T/1.html:text/html}
}

@article{bolognini_hearing_2011,
	title = {Hearing Shapes Our Perception of Time: Temporal Discrimination of Tactile Stimuli in Deaf People},
	volume = {24},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/jocn_a_00135},
	doi = {10.1162/jocn_a_00135},
	shorttitle = {Hearing Shapes Our Perception of Time},
	abstract = {Confronted with the loss of one type of sensory input, we compensate using information conveyed by other senses. However, losing one type of sensory information at specific developmental times may lead to deficits across all sensory modalities. We addressed the effect of auditory deprivation on the development of tactile abilities, taking into account changes occurring at the behavioral and cortical level. Congenitally deaf and hearing individuals performed two tactile tasks, the first requiring the discrimination of the temporal duration of touches and the second requiring the discrimination of their spatial length. Compared with hearing individuals, deaf individuals were impaired only in tactile temporal processing. To explore the neural substrate of this difference, we ran a {TMS} experiment. In deaf individuals, the auditory association cortex was involved in temporal and spatial tactile processing, with the same chronometry as the primary somatosensory cortex. In hearing participants, the involvement of auditory association cortex occurred at a later stage and selectively for temporal discrimination. The different chronometry in the recruitment of the auditory cortex in deaf individuals correlated with the tactile temporal impairment. Thus, early hearing experience seems to be crucial to develop an efficient temporal processing across modalities, suggesting that plasticity does not necessarily result in behavioral compensation.},
	pages = {276--286},
	number = {2},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Bolognini, Nadia and Cecchetto, Carlo and Geraci, Carlo and Maravita, Angelo and Pascual-Leone, Alvaro and Papagno, Costanza},
	urldate = {2019-05-02},
	date = {2011-09-14},
	file = {Snapshot:/home/felix/Zotero/storage/W2WE9LBN/jocn_a_00135.html:text/html}
}

@article{lambertz_cross-modal_2005,
	title = {Cross-modal plasticity in deaf subjects dependent on the extent of hearing loss},
	volume = {25},
	issn = {0926-6410},
	url = {http://www.sciencedirect.com/science/article/pii/S0926641005002715},
	doi = {10.1016/j.cogbrainres.2005.09.010},
	abstract = {Cross-modal plasticity in deaf subjects is still discussed controversial. We tried to figure out whether the plasticity is dependent on the extent of hearing loss. Three groups of volunteers, comprising twelve individuals each, were investigated. They were characterized by three distinctive features, one had normal hearing, the other one lost hearing and the third had only minimal residual hearing ability. All participants, except those of group one, were capable of using German Sign Language ({GSL}). The groups were studied with functional {MRI} in a standard block design during individuals' watching sign language videos alternating with black frame. During sign language conditions, deaf subjects revealed a significant activation of the auditory cortex in both hemispheres comprising Brodmann areas ({BA}) 42 and 22 corresponding to the secondary associative auditory areas. Additionally, activation of the angular and supramarginal gyrus was seen. Activation of the primary auditory cortex was revealed in deaf subjects with total hearing loss during sign language tasks but not in subjects with residual hearing ability. In conclusion our results indicate a cortical reorganization of the auditory cortex comprising primary auditory fields only present in subjects with total hearing loss.},
	pages = {884--890},
	number = {3},
	journaltitle = {Cognitive Brain Research},
	shortjournal = {Cognitive Brain Research},
	author = {Lambertz, Nicole and Gizewski, Elke R. and de Greiff, Armin and Forsting, Michael},
	urldate = {2019-05-02},
	date = {2005-12-01},
	keywords = {Sign language, Brain plasticity, Deaf, {fMRI}},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/AWWKLHR7/S0926641005002715.html:text/html}
}

@article{noauthor_comparing_nodate-1,
	title = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination: A Human {fMRI} Study},
	url = {https://app.dimensions.ai/details/publication/pub.1024032255},
	doi = {10.1152/jn.00940.2009},
	shorttitle = {Comparing Tactile Pattern and Vibrotactile Frequency Discrimination},
	abstract = {We investigated to which extent the discrimination of tactile patterns and vibrotactile frequencies share common cortical areas. An adaptation paradigm has been used to identify cortical areas specific for processing particular features of tactile stimuli. Healthy right-handed subjects performed a delayed-match-to-sample ({DMTS}) task discriminating between pairs of tactile patterns or vibrotactile frequencies in separate functional {MRI} sessions. The tactile stimuli were presented to the right middle fingertip sequentially with a 5.5 s delay. Regions of interest ({ROIs}) were defined by cortical areas commonly activated in both tasks and those that showed differential activation between both tasks. Results showed recruitment of many common brain regions along the sensory motor pathway (such as bilateral somatosensory, premotor areas, and anterior insula) in both tasks. Three cortical areas, the right intraparietal sulcus ({IPS}), supramarginal gyrus ({SMG})/parietal operculum ({PO}), and {PO}, were significantly more activated during the pattern than in the frequency task. Further {BOLD} time course analysis was performed in the {ROIs}. Significant {BOLD} adaptation was found in bilateral {IPS}, right anterior insula, and {SMG}/{PO} in the pattern task, whereas there was no significant {BOLD} adaptation found in the frequency task. In addition, the right hemisphere was found to be more dominant in the pattern than in the frequency task, which could be attributed to the differences between spatial (pattern) and temporal (frequency) processing. From the different spatio-temporal characteristics of {BOLD} activation in the pattern and frequency tasks, we concluded that different neuronal mechanisms are underlying the tactile spatial and temporal processing.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {20457848},
	file = {Snapshot:/home/felix/Zotero/storage/UG2PIE3A/pub.html:text/html}
}

@article{noauthor_neural_nodate,
	title = {Neural reorganization following sensory loss: the opportunity of change},
	url = {https://app.dimensions.ai/details/publication/pub.1047380724},
	doi = {10.1038/nrn2758},
	shorttitle = {Neural reorganization following sensory loss},
	abstract = {There is growing evidence that sensory deprivation is associated with crossmodal neuroplastic changes in the brain. After visual or auditory deprivation, brain areas that are normally associated with the lost sense are recruited by spared sensory modalities. These changes underlie adaptive and compensatory behaviours in blind and deaf individuals. Although there are differences between these populations owing to the nature of the deprived sensory modality, there seem to be common principles regarding how the brain copes with sensory loss and the factors that influence neuroplastic changes. Here, we discuss crossmodal neuroplasticity with regards to behavioural adaptation after sensory deprivation and highlight the possibility of maladaptive consequences within the context of rehabilitation.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {19935836},
	file = {Accepted Version:/home/felix/Zotero/storage/P368WJ96/Neural reorganization following sensory loss the .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/YY7SC7MD/pub.html:text/html}
}

@article{noauthor_multisensory_nodate,
	title = {Multisensory contributions to the perception of vibrotactile events},
	url = {https://app.dimensions.ai/details/publication/pub.1047563025},
	doi = {10.1016/j.bbr.2008.09.018},
	abstract = {We argue that audio-tactile interactions during vibrotactile processing provide a promising, albeit largely neglected, benchmark for the systematic study multisensory integration. This article reviews and discusses current evidence for multisensory contributions to the perception of vibratory events, and proposes a framework to address a number of relevant questions. First, we highlight some of the features that characterize the senses of hearing and touch in terms of vibratory information processing, and which allow for potential cross-modal interactions at multiple levels along the functional architecture of the sensory systems. Second, we briefly review empirical evidence for interactions between hearing and touch in the domain of vibroactile perception and related stimulus properties, covering behavioural, electrophysiological and neuroimaging studies in humans and animals. Third, we discuss the vibrotactile discrimination task, which has been successfully applied in the study of perception and decision processes in psychophysical and physiological research. We argue that this approach, complemented with computational modeling using biophysically realistic neural networks, may be a convenient framework to address auditory contributions to vibrotactile processing in the somatosensory system. Finally, we comment on a series of particular issues which are relevant in multisensory research and potentially addressable within the proposed framework.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {18930769},
	file = {Snapshot:/home/felix/Zotero/storage/BB6BCJYN/pub.html:text/html}
}

@article{noauthor_congenital_nodate-1,
	title = {Congenital deafness is associated with specific somatosensory deficits in adolescents},
	url = {https://app.dimensions.ai/details/publication/pub.1086249281},
	doi = {10.1038/s41598-017-04074-0},
	abstract = {Hearing and touch represent two distinct sensory systems that both rely on the transformation of mechanical force into electrical signals. Here we used a battery of quantitative sensory tests to probe touch, thermal and pain sensitivity in a young control population (14-20 years old) compared to age-matched individuals with congenital hearing loss. Sensory testing was performed on the dominant hand of 111 individuals with normal hearing and 36 with congenital hearing loss. Subjects with congenital deafness were characterized by significantly higher vibration detection thresholds at 10 Hz (2-fold increase, P {\textless} 0.001) and 125 Hz (P {\textless} 0.05) compared to controls. These sensory changes were not accompanied by any major change in measures of pain perception. We also observed a highly significant reduction (30\% compared to controls p {\textless} 0.001) in the ability of hearing impaired individual's ability to detect cooling which was not accompanied by changes in warm detection. At least 60\% of children with non-syndromic hearing loss showed very significant loss of vibration detection ability (at 10 Hz) compared to age-matched controls. We thus propose that many pathogenic mutations that cause childhood onset deafness may also play a role in the development or functional maintenance of somatic mechanoreceptors.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {28652589},
	file = {Full Text:/home/felix/Zotero/storage/TCWUE5WN/Congenital deafness is associated with specific so.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/Z4W7IA9T/pub.html:text/html}
}

@article{noauthor_multisensory_nodate-1,
	title = {Multisensory Interference in Early Deaf Adults.},
	url = {https://app.dimensions.ai/details/publication/pub.1090251148},
	doi = {10.1093/deafed/enx025},
	abstract = {Multisensory interactions in deaf cognition are largely unexplored. Unisensory studies suggest that behavioral/neural changes may be more prominent for visual compared to tactile processing in early deaf adults. Here we test whether such an asymmetry results in increased saliency of vision over touch during visuo-tactile interactions. About 23 early deaf and 25 hearing adults performed two consecutive visuo-tactile spatial interference tasks. Participants responded either to the elevation of the tactile target while ignoring a concurrent visual distractor at central or peripheral locations (respond to touch/ignore vision), or they performed the opposite task (respond to vision/ignore touch). Multisensory spatial interference emerged in both tasks for both groups. Crucially, deaf participants showed increased interference compared to hearing adults when they attempted to respond to tactile targets and ignore visual distractors, with enhanced difficulties with ipsilateral visual distractors. Analyses on task-order revealed that in deaf adults, interference of visual distractors on tactile targets was much stronger when this task followed the task in which vision was behaviorally relevant (respond to vision/ignore touch). These novel results suggest that behavioral/neural changes related to early deafness determine enhanced visual dominance during visuo-tactile multisensory conflict.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {28961871},
	file = {Snapshot:/home/felix/Zotero/storage/DYMDUSYQ/pub.html:text/html}
}

@article{noauthor_response_nodate-1,
	title = {Response speed advantage for vision does not extend to touch in early deaf adults},
	url = {https://app.dimensions.ai/details/publication/pub.1052412686},
	doi = {10.1007/s00221-014-3852-x},
	abstract = {Early deaf adults typically respond faster than hearing controls when performing a speeded simple detection on visual targets. Whether this response time advantage can generalise to another intact modality (touch) or it is instead specific to visual processing remained unexplored. We tested eight early deaf adults and twelve hearing controls in a simple detection task, with visual or tactile targets delivered on the arms and occupying the same locations in external space. Catch trials were included in the experimental paradigm. Results revealed a response time advantage in deaf adults compared to hearing controls, selectively for visual targets. This advantage did not extend to touch. The number of anticipation errors was negligible and comparable in both groups. The present findings strengthen the notion that response time advantage in deaf adults emerges as a consequence of changes specific to visual processing. They also exclude the involvement of sensory-unspecific cognitive mechanisms in this improvement (e.g. increased impulsivity in initiation of response, longer-lasting sustained attention or higher motivation to perform the task). Finally, they provide initial evidence that the intact sensory modalities can reorganise independently from each other following early auditory deprivation.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {24477765},
	file = {Snapshot:/home/felix/Zotero/storage/Q8REAJKQ/pub.html:text/html}
}

@article{noauthor_task-specific_nodate,
	title = {Task-specific reorganization of the auditory cortex in deaf humans},
	url = {https://app.dimensions.ai/details/publication/pub.1001216230},
	doi = {10.1073/pnas.1609000114},
	abstract = {The principles that guide large-scale cortical reorganization remain unclear. In the blind, several visual regions preserve their task specificity; ventral visual areas, for example, become engaged in auditory and tactile object-recognition tasks. It remains open whether task-specific reorganization is unique to the visual cortex or, alternatively, whether this kind of plasticity is a general principle applying to other cortical areas. Auditory areas can become recruited for visual and tactile input in the deaf. Although nonhuman data suggest that this reorganization might be task specific, human evidence has been lacking. Here we enrolled 15 deaf and 15 hearing adults into an functional {MRI} experiment during which they discriminated between temporally complex sequences of stimuli (rhythms). Both deaf and hearing subjects performed the task visually, in the central visual field. In addition, hearing subjects performed the same task in the auditory modality. We found that the visual task robustly activated the auditory cortex in deaf subjects, peaking in the posterior-lateral part of high-level auditory areas. This activation pattern was strikingly similar to the pattern found in hearing subjects performing the auditory version of the task. Although performing the visual task in deaf subjects induced an increase in functional connectivity between the auditory cortex and the dorsal visual cortex, no such effect was found in hearing subjects. We conclude that in deaf humans the high-level auditory cortex switches its input modality from sound to vision but preserves its task-specific activation pattern independent of input modality. Task-specific reorganization thus might be a general principle that guides cortical plasticity in the brain.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {28069964},
	file = {Full Text:/home/felix/Zotero/storage/B8JH5EMI/Task-specific reorganization of the auditory corte.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/48RP7YLZ/pub.html:text/html}
}

@article{noauthor_audio-tactile_nodate,
	title = {Audio-Tactile Integration in Congenitally and Late Deaf Cochlear Implant Users},
	url = {https://app.dimensions.ai/details/publication/pub.1044365155},
	doi = {10.1371/journal.pone.0099606},
	abstract = {Several studies conducted in mammals and humans have shown that multisensory processing may be impaired following congenital sensory loss and in particular if no experience is achieved within specific early developmental time windows known as sensitive periods. In this study we investigated whether basic multisensory abilities are impaired in hearing-restored individuals with deafness acquired at different stages of development. To this aim, we tested congenitally and late deaf cochlear implant ({CI}) recipients, age-matched with two groups of hearing controls, on an audio-tactile redundancy paradigm, in which reaction times to unimodal and crossmodal redundant signals were measured. Our results showed that both congenitally and late deaf {CI} recipients were able to integrate audio-tactile stimuli, suggesting that congenital and acquired deafness does not prevent the development and recovery of basic multisensory processing. However, we found that congenitally deaf {CI} recipients had a lower multisensory gain compared to their matched controls, which may be explained by their faster responses to tactile stimuli. We discuss this finding in the context of reorganisation of the sensory systems following sensory loss and the possibility that these changes cannot be "rewired" through auditory reafferentation.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {24918766},
	file = {Full Text:/home/felix/Zotero/storage/2MIY8F7D/Audio-Tactile Integration in Congenitally and Late.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/TREJ4EDA/pub.html:text/html}
}

@article{noauthor_audiotactile_nodate,
	title = {Audiotactile interaction can change over time in cochlear implant users},
	url = {https://app.dimensions.ai/details/publication/pub.1006770067},
	doi = {10.3389/fnhum.2014.00316},
	abstract = {Recent results suggest that audiotactile interactions are disturbed in cochlear implant ({CI}) users. However, further exploration regarding the factors responsible for such abnormal sensory processing is still required. Considering the temporal nature of a previously used multisensory task, it remains unclear whether any aberrant results were caused by the specificity of the interaction studied or rather if it reflects an overall abnormal interaction. Moreover, although duration of experience with a {CI} has often been linked with the recovery of auditory functions, its impact on multisensory performance remains uncertain. In the present study, we used the parchment-skin illusion, a robust illustration of sound-biased perception of touch based on changes in auditory frequencies, to investigate the specificities of audiotactile interactions in {CI} users. Whereas individuals with relatively little experience with the {CI} performed similarly to the control group, experienced {CI} users showed a significantly greater illusory percept. The overall results suggest that despite being able to ignore auditory distractors in a temporal audiotactile task, {CI} users develop to become greatly influenced by auditory input in a spectral audiotactile task. When considered with the existing body of research, these results confirm that normal sensory interaction processing can be compromised in {CI} users.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {24904359},
	file = {Full Text:/home/felix/Zotero/storage/UU6QQXZY/Audiotactile interaction can change over time in c.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/4R7S5QXL/pub.html:text/html}
}

@article{noauthor_altered_nodate,
	title = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults: A Visual-Somatosensory {fMRI} Study with a Double-Flash Illusion},
	url = {https://app.dimensions.ai/details/publication/pub.1022075426},
	doi = {10.1523/jneurosci.6488-11.2012},
	shorttitle = {Altered Cross-Modal Processing in the Primary Auditory Cortex of Congenitally Deaf Adults},
	abstract = {The developing brain responds to the environment by using statistical correlations in input to guide functional and structural changes-that is, the brain displays neuroplasticity. Experience shapes brain development throughout life, but neuroplasticity is variable from one brain system to another. How does the early loss of a sensory modality affect this complex process? We examined cross-modal neuroplasticity in anatomically defined subregions of Heschl's gyrus, the site of human primary auditory cortex, in congenitally deaf humans by measuring the {fMRI} signal change in response to spatially coregistered visual, somatosensory, and bimodal stimuli. In the deaf Heschl's gyrus, signal change was greater for somatosensory and bimodal stimuli than that of hearing participants. Visual responses in Heschl's gyrus, larger in deaf than hearing, were smaller than those elicited by somatosensory stimulation. In contrast to Heschl's gyrus, in the superior-temporal cortex visual signal was comparable to somatosensory signal. In addition, deaf adults perceived bimodal stimuli differently; in contrast to hearing adults, they were susceptible to a double-flash visual illusion induced by two touches to the face. Somatosensory and bimodal signal change in rostrolateral Heschl's gyrus predicted the strength of the visual illusion in the deaf adults in line with the interpretation that the illusion is a functional consequence of the altered cross-modal organization observed in deaf auditory cortex. Our results demonstrate that congenital and profound deafness alters how vision and somatosensation are processed in primary auditory cortex.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {22787048},
	file = {Full Text:/home/felix/Zotero/storage/PJG5ALFW/Altered Cross-Modal Processing in the Primary Audi.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/9QIY5MXF/pub.html:text/html}
}

@article{noauthor_what_nodate,
	title = {What is the function of auditory cortex when it develops in the absence of acoustic input?},
	url = {https://app.dimensions.ai/details/publication/pub.1084678314},
	doi = {10.1016/j.cogdev.2017.02.007},
	abstract = {When the brain is deprived of input from one sensory modality, it often compensates with supranormal performance in one or more of the intact sensory systems. Therefore, we were interested in examining the function of auditory cortex when it is deprived of normal acoustic input. In this context, it has been proposed that auditory cortex of the deaf may be recruited to perform visual functions. Here, we review recent evidence of a causal link between supranormal visual performance and visual activity in reorganized deaf auditory cortex. Furthermore, we considered that if auditory cortex does mediate the enhanced visual abilities of the deaf, are these functions distributed uniformly across deaf auditory cortex, or are specific functions differentially localized to distinct portions of the affected cortices? Finally, we considered whether reorganized cortex retains any relationship to functions performed in these regions in hearing subjects. These fundamental questions are of significant clinical importance as restoration of hearing in prelingually deaf children is possible with cochlear prosthetics.},
	urldate = {2019-05-02},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/JALG7GLQ/pub.html:text/html}
}

@article{noauthor_visuo-tactile_nodate,
	title = {Visuo-tactile interactions in the congenitally deaf: a behavioral and event-related potential study},
	url = {https://app.dimensions.ai/details/publication/pub.1036793282},
	doi = {10.3389/fnint.2014.00098},
	shorttitle = {Visuo-tactile interactions in the congenitally deaf},
	abstract = {Auditory deprivation is known to be accompanied by alterations in visual processing. Yet not much is known about tactile processing and the interplay of the intact sensory modalities in the deaf. We presented visual, tactile, and visuo-tactile stimuli to congenitally deaf and hearing individuals in a speeded detection task. Analyses of multisensory responses showed a redundant signals effect that was attributable to a coactivation mechanism in both groups, although the redundancy gain was less in the deaf. In line with these behavioral results, on a neural level, there were multisensory interactions in both groups that were again weaker in the deaf. In hearing but not deaf participants, somatosensory event-related potential N200 latencies were modulated by simultaneous visual stimulation. A comparison of unisensory responses between groups revealed larger N200 amplitudes for visual and shorter N200 latencies for tactile stimuli in the deaf. Furthermore, P300 amplitudes were also larger in the deaf. This group difference was significant for tactile and approached significance for visual targets. The differences in visual and tactile processing between deaf and hearing participants, however, were not reflected in behavior. Both the behavioral and electroencephalography ({EEG}) results suggest more pronounced multisensory interaction in hearing than in deaf individuals. Visuo-tactile enhancements could not be explained by perceptual deficiency, but could be partly attributable to inverse effectiveness.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {25653602},
	file = {Full Text:/home/felix/Zotero/storage/YFA5GTDQ/Visuo-tactile interactions in the congenitally dea.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/E46JZ7MH/pub.html:text/html}
}

@article{noauthor_adaptation_nodate,
	title = {Adaptation to sensory loss},
	url = {https://app.dimensions.ai/details/publication/pub.1003668902},
	doi = {10.1002/wcs.13},
	abstract = {The human brain has the remarkable ability to adapt to changes in its environment by benefiting from its 'plastic' properties. Following brain injury, the amputation of a limb, or the loss of a sensory input such as peripheral blindness, brain circuitry often seems to be able to reorganize itself in order to compensate for the handicap by being recruited to carry out tasks not associated with their prior 'default' functioning. The purpose of this review is to illustrate the brain's remarkable ability to adapt to changes in its environment, particularly when it is faced with a sensory loss. Two excellent models to study this phenomenon are provided by blind and deaf individuals. In both cases, studies have shown that they appear to compensate for the loss of sensory input with enhanced abilities in their remaining senses. These behavioral modifications are often coupled with changes in cerebral processing, generally in the form of crossmodal recruitment of deaffarented primary and secondary sensory areas. We will also discuss the possible mechanisms underlying these changes and whether the functional topography of these regions present in unimpaired individuals is preserved in blindness and deafness. The notion of a critical period for plastic changes will also be discussed and its importance will be shown to be twofold. On the one hand, the functional relevance of crossmodal processing appears to decrease as a function of the age of onset of the deficiency. On the other hand, the more cortical reorganization takes place, the less likely brain areas will be able to process input from its original sensory modality. This is especially important for deaf individuals as auditory input can now be restored thanks to cochlear implants. Copyright © 2010 John Wiley \& Sons, Ltd. For further resources related to this article, please visit the {WIREs} website.},
	urldate = {2019-05-02},
	langid = {english},
	pmid = {26271373},
	file = {Snapshot:/home/felix/Zotero/storage/VALERES2/pub.html:text/html}
}

@article{noauthor_revisiting_nodate,
	title = {Revisiting the adaptive and maladaptive effects of crossmodal plasticity},
	url = {https://app.dimensions.ai/details/publication/pub.1014059296?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1016/j.neuroscience.2014.08.003},
	abstract = {One of the most striking demonstrations of experience-dependent plasticity comes from studies of sensory-deprived individuals (e.g., blind or deaf), showing that brain regions deprived of their natural inputs change their sensory tuning to support the processing of inputs coming from the spared senses. These mechanisms of crossmodal plasticity have been traditionally conceptualized as having a double-edged sword effect on behavior. On one side, crossmodal plasticity is conceived as adaptive for the development of enhanced behavioral skills in the remaining senses of early-deaf or blind individuals. On the other side, crossmodal plasticity raises crucial challenges for sensory restoration and is typically conceived as maladaptive since its presence may prevent optimal recovery in sensory-re-afferented individuals. In the present review we stress that this dichotomic vision is oversimplified and we emphasize that the notions of the unavoidable adaptive/maladaptive effects of crossmodal reorganization for sensory compensation/restoration may actually be misleading. For this purpose we critically review the findings from the blind and deaf literatures, highlighting the complementary nature of these two fields of research. The integrated framework we propose here has the potential to impact on the way rehabilitation programs for sensory recovery are carried out, with the promising prospect of eventually improving their final outcomes.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {25139761},
	file = {Full Text:/home/felix/Zotero/storage/9NAWGI46/Revisiting the adaptive and maladaptive effects of.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/34FUT8E7/pub.html:text/html}
}

@article{noauthor_enhancement_nodate,
	title = {Enhancement of Visual Motion Detection Thresholds in Early Deaf People},
	url = {https://app.dimensions.ai/details/publication/pub.1015026026?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1371/journal.pone.0090498},
	abstract = {In deaf people, the auditory cortex can reorganize to support visual motion processing. Although this cross-modal reorganization has long been thought to subserve enhanced visual abilities, previous research has been unsuccessful at identifying behavioural enhancements specific to motion processing. Recently, research with congenitally deaf cats has uncovered an enhancement for visual motion detection. Our goal was to test for a similar difference between deaf and hearing people. We tested 16 early and profoundly deaf participants and 20 hearing controls. Participants completed a visual motion detection task, in which they were asked to determine which of two sinusoidal gratings was moving. The speed of the moving grating varied according to an adaptive staircase procedure, allowing us to determine the lowest speed necessary for participants to detect motion. Consistent with previous research in deaf cats, the deaf group had lower motion detection thresholds than the hearing. This finding supports the proposal that cross-modal reorganization after sensory deprivation will occur for supramodal sensory features and preserve the output functions.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {24587381},
	file = {Full Text:/home/felix/Zotero/storage/8HFEU2EE/Enhancement of Visual Motion Detection Thresholds .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/FHBX7K66/pub.html:text/html}
}

@article{noauthor_superior_nodate,
	title = {Superior spatial touch: improved haptic orientation processing in deaf individuals},
	url = {https://app.dimensions.ai/details/publication/pub.1028730088?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1007/s00221-013-3653-7},
	shorttitle = {Superior spatial touch},
	abstract = {The present study investigated haptic spatial orientation processing in deaf signers, hearing sign language interpreters, and hearing controls. Blindfolded participants had to set two bars parallel in the horizontal plane, with either a 2-s or a 10-s delay between inspection of the reference bar and the setting of the test bar. The deaf group outperformed the other two groups which did not differ from each other. Together these results indicate that deaf individuals can better identify the allocentric spatial coordinates of haptically inspected orientations. These results are discussed in terms of the possible neurocognitive consequences of auditory deprivation.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {23897133},
	file = {Snapshot:/home/felix/Zotero/storage/2RZ9GSHE/pub.html:text/html}
}

@article{noauthor_congenital_nodate-2,
	title = {Congenital blindness leads to enhanced vibrotactile perception},
	url = {https://app.dimensions.ai/details/publication/pub.1023851354?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1016/j.neuropsychologia.2009.10.001},
	abstract = {Previous studies have shown that in comparison with the sighted, blind individuals display superior non-visual perceptual abilities and differ in brain organisation. In this study, we investigated the performance of blind and sighted participants on a vibrotactile discrimination task. Thirty-three blind participants were classified into one of three groups (congenital, early, late), depending on the age at which they became blind. Consistent with previous neuroimaging data, individuals blinded after late childhood (14 years) showed no advantage over sighted participants. Both the congenitally- and early-blind participants were better than the sighted. The congenitally blind participants were even more accurate than the early-blind participants; a distinction that has not been drawn previously. Duration of blindness did not predict task performance and the effect of onset age persisted after duration of daily Braille reading was accounted for. We conclude that complete visual deprivation early in life leads to heightened tactile acuity.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {19819246},
	file = {Snapshot:/home/felix/Zotero/storage/MQ4B7LVN/pub.html:text/html}
}

@article{noauthor_tactile_nodate-2,
	title = {Tactile acuity in the blind: A closer look reveals superiority over the sighted in some but not all cutaneous tasks},
	url = {https://app.dimensions.ai/details/publication/pub.1017489679?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1016/j.neuropsychologia.2009.03.014},
	shorttitle = {Tactile acuity in the blind},
	abstract = {Previous studies have shown that blind subjects may outperform the sighted on certain tactile discrimination tasks. We recently showed that blind subjects outperformed the sighted in a haptic 2D-angle discrimination task. The purpose of this study was to compare the performance of the same blind (n=16) and sighted (n=17, G1) subjects in three tactile discrimination tasks dependent solely on cutaneous inputs from the fingertip of the index finger, D2. A second group of sighted subjects (n=30, G2) were also tested. Texture discrimination thresholds were 0.62 (G1)-0.80 mm (G2) for the sighted subjects, and 0.64 mm for the blind (standard, 2mm spatial period). Grating orientation thresholds were 0.99 (G1)-1.12 mm (G2) for the sighted subjects, and 0.96 mm for the blind. Finally, vibrotactile frequency discrimination thresholds (100 Hz standard) were 19.5 (G2) and 20.0 Hz (G1) for the sighted, and 16.5 Hz for the blind subjects. There were no significant differences in performance between the blind and the sighted subjects for the grating orientation or vibrotactile frequency discrimination tasks. In contrast, blind subjects outperformed the sighted for the texture discrimination task (G2 only), possibly reflecting the fact that the raised dot surfaces were similar to the dots forming Braille characters (all were fluent Braille readers).},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {19467354},
	file = {Snapshot:/home/felix/Zotero/storage/I22X4BUH/pub.html:text/html}
}

@article{noauthor_sensory_nodate,
	title = {Sensory temporal processing in adults with early hearing loss},
	url = {https://app.dimensions.ai/details/publication/pub.1027512200?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1016/j.bandc.2005.05.012},
	abstract = {This study examined tactile and visual temporal processing in adults with early loss of hearing. The tactile task consisted of punctate stimulations that were delivered to one or both hands by a mechanical tactile stimulator. Pairs of light emitting diodes were presented on a display for visual stimulation. Responses consisted of {YES} or {NO} judgments as to whether the onset of the pairs of stimuli was perceived simultaneously or non-simultaneously. Tactile and visual temporal thresholds were significantly higher for the deaf group when compared to controls. In contrast to controls, tactile and visual temporal thresholds for the deaf group did not differ when presentation locations were examined. Overall findings of this study support the notion that temporal processing is compromised following early deafness regardless of the spatial location in which the stimuli are presented.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {16043276},
	file = {Snapshot:/home/felix/Zotero/storage/MPGM9SQB/pub.html:text/html}
}

@article{noauthor_deaf_nodate,
	title = {Deaf, blind or deaf-blind: Is touch enhanced?},
	url = {https://app.dimensions.ai/details/publication/pub.1033927632?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1007/s00221-015-4488-1},
	shorttitle = {Deaf, blind or deaf-blind},
	abstract = {When someone looses one type of sensory input, s/he may compensate by using the sensory information conveyed by other senses. To verify whether loosing a sense or two has consequences on a spared sensory modality, namely touch, and whether these consequences depend on the type of sensory loss, we investigated the effects of deafness and blindness on temporal and spatial tactile tasks in deaf, blind and deaf-blind people. Deaf and deaf-blind people performed the spatial tactile task better than the temporal one, while blind and controls showed the opposite pattern. Deaf and deaf-blind participants were impaired in temporal discrimination as compared to controls, while deaf-blind individuals outperformed blind participants in the spatial tactile task. Overall, sensory-deprived participants did not show an enhanced tactile performance. We speculate that discriminative touch is not so relevant in humans, while social touch is. Probably, more complex tactile tasks would have revealed an increased performance in sensory-deprived people.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {26573575},
	file = {Snapshot:/home/felix/Zotero/storage/XIKQ9K7B/pub.html:text/html}
}

@article{noauthor_tactile_nodate-3,
	title = {Tactile spatial resolution in blind braille readers.},
	url = {https://app.dimensions.ai/details/publication/pub.1064378222?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.1212/wnl.54.12.2230},
	abstract = {{OBJECTIVE}: To determine if blind people have heightened tactile spatial acuity. {BACKGROUND}: Recently, studies using magnetic source imaging and somatosensory evoked potentials have shown that the cortical representation of the reading fingers of blind Braille readers is expanded compared to that of fingers of sighted subjects. Furthermore, the visual cortex is activated during certain tactile tasks in blind subjects but not sighted subjects. The authors hypothesized that the expanded cortical representation of fingers used in Braille reading may reflect an enhanced fidelity in the neural transmission of spatial details of a stimulus. If so, the quantitative limit of spatial acuity would be superior in blind people. {METHODS}: The authors employed a grating orientation discrimination task in which threshold performance is accounted for by the spatial resolution limits of the neural image evoked by a stimulus. The authors quantified the psychophysical limits of spatial acuity at the middle and index fingers of 15 blind Braille readers and 15 sighted control subjects. {RESULTS}: The mean grating orientation threshold was significantly (p = 0.03) lower in the blind group (1.04 mm) compared to the sighted group (1.46 mm). The self-reported dominant reading finger in blind subjects had a mean grating orientation threshold of 0.80 mm, which was significantly better than other fingers tested. Thresholds at non-Braille reading fingers in blind subjects averaged 1.12 mm, which were also superior to sighted subjects' performances. {CONCLUSION}: Superior tactile spatial acuity in blind Braille readers may represent an adaptive, behavioral correlate of cortical plasticity.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {10881245},
	file = {Snapshot:/home/felix/Zotero/storage/72CF2PRU/pub.html:text/html}
}

@article{noauthor_tactile_nodate-4,
	title = {Tactile perception in blind Braille readers: A psychophysical study of acuity and hyperacuity using gratings and dot patterns},
	url = {https://app.dimensions.ai/details/publication/pub.1031678990?search_text=Deaf%2C%20blind%20or%20deaf-blind%20touch%20enhanced&search_type=kws&search_field=full_search},
	doi = {10.3758/bf03205550},
	shorttitle = {Tactile perception in blind Braille readers},
	abstract = {It is not clear whether the blind are generally superior to the sighted on measures of tactile sensitivity or whether they excel only on certain tests owing to the specifics of their tactile experience. We compared the discrimination performance of blind Braille readers and age-matched sighted subjects on three tactile tasks using precisely specified stimuli. Initially, the blind significantly outperformed the sighted at a hyperacuity task using Braille-like dot patterns, although, with practice, both groups performed equally well. On two other tasks, hyperacute discrimination of gratings that differed in ridge width and spatial-acuity-dependent discrimination of grating orientation, the performance of the blind did not differ significantly from that of sighted subjects. These results probably reflect the specificity of perceptual learning due to Braille-reading experience.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {10723209},
	file = {Full Text:/home/felix/Zotero/storage/YMCJPI9I/Tactile perception in blind Braille readers A psy.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/IC7XKKUL/pub.html:text/html}
}

@article{noauthor_deaf_nodate-1,
	title = {Deaf and Hearing Children\&\#x27;s Performance on a Tactual Perception Battery},
	url = {https://app.dimensions.ai/details/publication/pub.1070788027?search_text=deaf%20AND%20tactile%20OR%20tactual%20AND%20acuity%20OR%20sensitivity&search_type=kws&search_field=full_search},
	doi = {10.2466/pms.1972.35.3.683},
	abstract = {A battery of tactual sensitivity tests was administered to 300 deaf and hearing children and adolescents. The tests included vibrotactile and two-point sensitivity on several areas of the hand, gap-detection using two stimulation techniques, roughness discrimination, pattern discrimination, and cross-modal object identification. Measures included sensory thresholds, correct discrimination, errors, and in some cases, response latencies. Deaf youngsters were more sensitive than their hearing counterparts with vibrotactile and two-point measures. On most remaining tasks, deaf and hearing Ss' performance accuracies did not differ, although hearing Ss performed faster on all timed tasks. Improvements with age were evident with both speed and accuracy measures for several tasks. Results were discussed as to deaf/hearing differences, and reading achievement scores, active versus passive touch, developmental changes, and relations among the tactual tasks and measures of the battery. The findings strongly suggested that different measures of tactual sensitivity tap quite different sensory and perceptual abilities.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {4643958},
	file = {Snapshot:/home/felix/Zotero/storage/BSIMH4DY/pub.html:text/html}
}

@article{noauthor_enhanced_nodate,
	title = {Enhanced reactivity to visual stimuli in deaf individuals.},
	url = {https://app.dimensions.ai/details/publication/pub.1078147716?search_text=deaf%20AND%20tactile%20OR%20tactual%20AND%20acuity%20OR%20sensitivity&search_type=kws&search_field=full_search},
	doi = {10.3233/rnn-2010-0502},
	abstract = {{PURPOSE}: Several studies have reported faster response time to visual stimuli in profoundly deaf individuals. This result is often linked to the processing of peripheral targets, and it is assumed to occur in relation to attention orienting. We evaluated whether enhanced reactivity to visual events in profoundly deaf individuals can be explained by faster orienting of visual attention alone. {METHODS}: We examined 11 deaf individuals and 11 hearing controls, in a simple detection task and in a shape discrimination task. While simple detection can be performed under distributed attention, shape discrimination requires orienting of spatial attention to the target. The same visual targets served for both tasks, presented at central or peripheral locations and corrected for cortical magnification. {RESULTS}: The simple detection task revealed faster {RTs} in deaf than hearing controls, regardless of target location. Moreover, while hearing controls paid a cost in responding to peripheral than central targets, deaf participants performed equally well regardless of target eccentricity. In the shape discrimination task deaf never outperformed hearing controls. {CONCLUSIONS}: These findings reveal that enhanced reactivity to visual stimuli in the deaf cannot be explained only by faster orienting of visual attention and can emerge for central as well as peripheral targets. Moreover, the persisting advantage for peripheral locations in the deaf, observed here under distributed attention, suggests that this spatially-selective effect could result from reorganised sensory processing rather than different attentional gradients.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {20404406},
	file = {Snapshot:/home/felix/Zotero/storage/SII3IUFI/pub.html:text/html}
}

@article{noauthor_deaf_nodate-2,
	title = {Do deaf individuals see better?},
	url = {https://app.dimensions.ai/details/publication/pub.1015765786?search_text=deaf%20AND%20tactile%20OR%20tactual%20AND%20acuity%20OR%20sensitivity&search_type=kws&search_field=full_search},
	doi = {10.1016/j.tics.2006.09.006},
	abstract = {The possibility that, following early auditory deprivation, the remaining senses such as vision are enhanced has been met with much excitement. However, deaf individuals exhibit both better and worse visual skills than hearing controls. We show that, when deafness is considered to the exclusion of other confounds, enhancements in visual cognition are noted. The changes are not, however, widespread but are selective, limited, as we propose, to those aspects of vision that are attentionally demanding and would normally benefit from auditory-visual convergence. The behavioral changes are accompanied by a reorganization of multisensory areas, ranging from higher-order cortex to early cortical areas, highlighting cross-modal interactions as a fundamental feature of brain organization and cognitive processing.},
	urldate = {2019-05-03},
	langid = {english},
	pmid = {17015029},
	file = {Accepted Version:/home/felix/Zotero/storage/QRDYZ94S/Do deaf individuals see better.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/H6ENKQYP/pub.html:text/html}
}

@article{van_dijk_superior_2013,
	title = {Superior spatial touch: improved haptic orientation processing in deaf individuals},
	volume = {230},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-013-3653-7},
	doi = {10.1007/s00221-013-3653-7},
	shorttitle = {Superior spatial touch},
	abstract = {The present study investigated haptic spatial orientation processing in deaf signers, hearing sign language interpreters, and hearing controls. Blindfolded participants had to set two bars parallel in the horizontal plane, with either a 2-s or a 10-s delay between inspection of the reference bar and the setting of the test bar. The deaf group outperformed the other two groups which did not differ from each other. Together these results indicate that deaf individuals can better identify the allocentric spatial coordinates of haptically inspected orientations. These results are discussed in terms of the possible neurocognitive consequences of auditory deprivation.},
	pages = {283--289},
	number = {3},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {van Dijk, Rick and Kappers, Astrid M. L. and Postma, Albert},
	urldate = {2019-05-03},
	date = {2013-10-01},
	langid = {english},
	keywords = {Deafness, Haptic spatial perception, Sign language usage},
	file = {van Dijk et al. - 2013 - Superior spatial touch improved haptic orientatio.pdf:/home/felix/Zotero/storage/RKS9T7K2/van Dijk et al. - 2013 - Superior spatial touch improved haptic orientatio.pdf:application/pdf}
}

@article{noauthor_sensory_nodate-1,
	title = {Sensory Loss Enhances Multisensory Integration Performance},
	url = {https://app.dimensions.ai/details/publication/pub.1110586352},
	doi = {10.1101/483586},
	abstract = {Auditory and visual sensory loss has repeatedly been shown to alter abilities in remaining sensory modalities. It is, however, unclear whether sensory loss also impacts multisensory integration; an ability that is fundamental for the perception of the world around us. We determined effects of complete olfactory sensory loss on multisensory perception by assessing temporal as well as semantic aspects of audio-visual integration in 37 individuals with anosmia (complete olfactory sensory loss) and 37 healthy, matched controls. Participants performed a simultaneity judgement task to determine the temporal binding window, and a multisensory object identification task with individually degraded, dynamic visual, auditory, and audio-visual stimuli. Individuals with anosmia demonstrated an increased ability to detect multisensory temporal asynchronies, represented by a narrowing of the audio-visual temporal binding window. Furthermore, individuals with congenital, but not acquired, anosmia demonstrated indications of greater benefits from bimodal, as compared to unimodal, stimulus presentation when faced with degraded, semantic information. This suggests that complete olfactory sensory loss alters multisensory integration of remaining senses by sharpening the perception of cross-modal temporal violations, independent of sensory loss etiology. In addition, congenital sensory loss may further lead to increased gain from multisensory, compared to unisensory, information. Taken together, multisensory compensatory mechanisms at different levels of perceptual complexity are present in individuals with complete olfactory sensory loss.},
	urldate = {2019-05-03},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/CYTUWN56/pub.html:text/html}
}

@article{noauthor_what_nodate-1,
	title = {What is the function of auditory cortex when it develops in the absence of acoustic input?},
	url = {https://app.dimensions.ai/details/publication/pub.1084678314},
	doi = {10.1016/j.cogdev.2017.02.007},
	abstract = {When the brain is deprived of input from one sensory modality, it often compensates with supranormal performance in one or more of the intact sensory systems. Therefore, we were interested in examining the function of auditory cortex when it is deprived of normal acoustic input. In this context, it has been proposed that auditory cortex of the deaf may be recruited to perform visual functions. Here, we review recent evidence of a causal link between supranormal visual performance and visual activity in reorganized deaf auditory cortex. Furthermore, we considered that if auditory cortex does mediate the enhanced visual abilities of the deaf, are these functions distributed uniformly across deaf auditory cortex, or are specific functions differentially localized to distinct portions of the affected cortices? Finally, we considered whether reorganized cortex retains any relationship to functions performed in these regions in hearing subjects. These fundamental questions are of significant clinical importance as restoration of hearing in prelingually deaf children is possible with cochlear prosthetics.},
	urldate = {2019-05-03},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/2VRHNBAP/pub.html:text/html}
}

@article{lomber_what_2017,
	title = {What is the function of auditory cortex when it develops in the absence of acoustic input?},
	volume = {42},
	issn = {0885-2014},
	url = {http://www.sciencedirect.com/science/article/pii/S0885201416300880},
	doi = {10.1016/j.cogdev.2017.02.007},
	series = {Current Perspectives on Neuroplasticity in Human Development},
	abstract = {When the brain is deprived of input from one sensory modality, it often compensates with supranormal performance in one or more of the intact sensory systems. Therefore, we were interested in examining the function of auditory cortex when it is deprived of normal acoustic input. In this context, it has been proposed that auditory cortex of the deaf may be recruited to perform visual functions. Here, we review recent evidence of a causal link between supranormal visual performance and visual activity in reorganized deaf auditory cortex. Furthermore, we considered that if auditory cortex does mediate the enhanced visual abilities of the deaf, are these functions distributed uniformly across deaf auditory cortex, or are specific functions differentially localized to distinct portions of the affected cortices? Finally, we considered whether reorganized cortex retains any relationship to functions performed in these regions in hearing subjects. These fundamental questions are of significant clinical importance as restoration of hearing in prelingually deaf children is possible with cochlear prosthetics.},
	pages = {49--61},
	journaltitle = {Cognitive Development},
	shortjournal = {Cognitive Development},
	author = {Lomber, Stephen G.},
	urldate = {2019-05-03},
	date = {2017-04-01},
	keywords = {Deafness, Hearing loss, Cortical plasticity, Crossmodal plasticity, Sensory deprivation},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/XBWEV89N/Lomber - 2017 - What is the function of auditory cortex when it de.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/IWEUQATZ/S0885201416300880.html:text/html}
}

@article{frenzel_genetic_2012,
	title = {A Genetic Basis for Mechanosensory Traits in Humans},
	volume = {10},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001318},
	doi = {10.1371/journal.pbio.1001318},
	abstract = {Hearing and touch are genetically related, and people with excellent hearing are more likely to have a fine sense of touch and vice versa.},
	pages = {e1001318},
	number = {5},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Frenzel, Henning and Bohlender, Jörg and Pinsker, Katrin and Wohlleben, Bärbel and Tank, Jens and Lechner, Stefan G. and Schiska, Daniela and Jaijo, Teresa and Rüschendorf, Franz and Saar, Kathrin and Jordan, Jens and Millán, José M. and Gross, Manfred and Lewin, Gary R.},
	urldate = {2019-05-04},
	date = {2012-05-01},
	langid = {english},
	keywords = {Touch, Tactile sensation, Vibration, Deafness, Heredity, Mutation, Pain sensation, Twins},
	file = {Full Text PDF:/home/felix/Zotero/storage/4W9FJF5J/Frenzel et al. - 2012 - A Genetic Basis for Mechanosensory Traits in Human.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/N7TB4QEB/article.html:text/html}
}

@article{heimler_multisensory_2017,
	title = {Multisensory Interference in Early Deaf Adults},
	volume = {22},
	issn = {1081-4159},
	url = {https://academic.oup.com/jdsde/article/22/4/422/4091308},
	doi = {10.1093/deafed/enx025},
	abstract = {Abstract.  Multisensory interactions in deaf cognition are largely unexplored. Unisensory studies suggest that behavioral/neural changes may be more prominent f},
	pages = {422--433},
	number = {4},
	journaltitle = {The Journal of Deaf Studies and Deaf Education},
	shortjournal = {J Deaf Stud Deaf Educ},
	author = {Heimler, Benedetta and Baruffaldi, Francesca and Bonmassar, Claudia and Venturini, Marta and Pavani, Francesco},
	urldate = {2019-05-04},
	date = {2017-10-01},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/Q8H2J57X/Heimler et al. - 2017 - Multisensory Interference in Early Deaf Adults.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/LC9DWID9/4091308.html:text/html}
}

@article{bavelier_deaf_2006,
	title = {Do deaf individuals see better?},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306002439},
	doi = {10.1016/j.tics.2006.09.006},
	abstract = {The possibility that, following early auditory deprivation, the remaining senses such as vision are enhanced has been met with much excitement. However, deaf individuals exhibit both better and worse visual skills than hearing controls. We show that, when deafness is considered to the exclusion of other confounds, enhancements in visual cognition are noted. The changes are not, however, widespread but are selective, limited, as we propose, to those aspects of vision that are attentionally demanding and would normally benefit from auditory–visual convergence. The behavioral changes are accompanied by a reorganization of multisensory areas, ranging from higher-order cortex to early cortical areas, highlighting cross-modal interactions as a fundamental feature of brain organization and cognitive processing.},
	pages = {512--518},
	number = {11},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Bavelier, Daphne and Dye, Matthew W. G. and Hauser, Peter C.},
	urldate = {2019-05-04},
	date = {2006-11-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/NJ9I7BPL/Bavelier et al. - 2006 - Do deaf individuals see better.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/Y4CKAJAU/S1364661306002439.html:text/html}
}

@article{voss_adaptation_2010,
	title = {Adaptation to sensory loss},
	volume = {1},
	rights = {Copyright © 2010 John Wiley \& Sons, Ltd.},
	issn = {1939-5086},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcs.13},
	doi = {10.1002/wcs.13},
	abstract = {The human brain has the remarkable ability to adapt to changes in its environment by benefiting from its ‘plastic’ properties. Following brain injury, the amputation of a limb, or the loss of a sensory input such as peripheral blindness, brain circuitry often seems to be able to reorganize itself in order to compensate for the handicap by being recruited to carry out tasks not associated with their prior ‘default’ functioning. The purpose of this review is to illustrate the brain's remarkable ability to adapt to changes in its environment, particularly when it is faced with a sensory loss. Two excellent models to study this phenomenon are provided by blind and deaf individuals. In both cases, studies have shown that they appear to compensate for the loss of sensory input with enhanced abilities in their remaining senses. These behavioral modifications are often coupled with changes in cerebral processing, generally in the form of crossmodal recruitment of deaffarented primary and secondary sensory areas. We will also discuss the possible mechanisms underlying these changes and whether the functional topography of these regions present in unimpaired individuals is preserved in blindness and deafness. The notion of a critical period for plastic changes will also be discussed and its importance will be shown to be twofold. On the one hand, the functional relevance of crossmodal processing appears to decrease as a function of the age of onset of the deficiency. On the other hand, the more cortical reorganization takes place, the less likely brain areas will be able to process input from its original sensory modality. This is especially important for deaf individuals as auditory input can now be restored thanks to cochlear implants. Copyright © 2010 John Wiley \& Sons, Ltd. This article is categorized under: Psychology {\textgreater} Perception and Psychophysics Neuroscience {\textgreater} Development},
	pages = {308--328},
	number = {3},
	journaltitle = {Wiley Interdisciplinary Reviews: Cognitive Science},
	author = {Voss, Patrice and Collignon, Olivier and Lassonde, Maryse and Lepore, Franco},
	urldate = {2019-05-04},
	date = {2010},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/U85USTVP/Voss et al. - 2010 - Adaptation to sensory loss.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/UK3VGXTE/wcs.html:text/html}
}

@article{ghazanfar_is_2006-1,
	title = {Is neocortex essentially multisensory?},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306001045},
	doi = {10.1016/j.tics.2006.04.008},
	abstract = {Although sensory perception and neurobiology are traditionally investigated one modality at a time, real world behaviour and perception are driven by the integration of information from multiple sensory sources. Mounting evidence suggests that the neural underpinnings of multisensory integration extend into early sensory processing. This article examines the notion that neocortical operations are essentially multisensory. We first review what is known about multisensory processing in higher-order association cortices and then discuss recent anatomical and physiological findings in presumptive unimodal sensory areas. The pervasiveness of multisensory influences on all levels of cortical processing compels us to reconsider thinking about neural processing in unisensory terms. Indeed, the multisensory nature of most, possibly all, of the neocortex forces us to abandon the notion that the senses ever operate independently during real-world cognition.},
	pages = {278--285},
	number = {6},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Ghazanfar, Asif A. and Schroeder, Charles E.},
	urldate = {2019-05-05},
	date = {2006-06-01},
	file = {Full Text:/home/felix/Zotero/storage/AD3BFELF/Ghazanfar and Schroeder - 2006 - Is neocortex essentially multisensory.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/RD9YZRLW/S1364661306001045.html:text/html}
}

@online{noauthor_new_nodate,
	title = {The New Handbook of Multisensory Processing {\textbar} {MIT} {CogNet}},
	url = {http://cognet.mit.edu/erefs/new-handbook-of-multisensory-processing},
	urldate = {2019-05-05},
	file = {The New Handbook of Multisensory Processing | MIT CogNet:/home/felix/Zotero/storage/XA778XT4/new-handbook-of-multisensory-processing.html:text/html}
}

@article{pavani_crossmodal_2012,
	title = {Crossmodal plasticity as a consequence of sensory loss: insights from blindness and deafness},
	shorttitle = {Crossmodal plasticity as a consequence of sensory loss},
	pages = {737--759},
	journaltitle = {The new handbook of multisensory processes},
	author = {Pavani, F. and Röder, B.},
	date = {2012}
}

@incollection{roder_compensatory_2004,
	location = {Cambridge, {MA}, {US}},
	title = {Compensatory Plasticity as a Consequence of Sensory Loss},
	isbn = {978-0-262-03321-3},
	abstract = {This chapter reviews findings in blind and deaf individuals for different functional domains, including perceptual, language, and spatial functions. To understand what the underlying neural mechanisms of cross-modal compensation are, some relevant findings from animal research are reported and the meaning of the term neuroplasiticity is discussed. The focus is on the visual deprivation model, but some parallel findings in the deaf are reported as well. ({PsycINFO} Database Record (c) 2019 {APA}, all rights reserved)},
	pages = {719--747},
	booktitle = {The handbook of multisensory processes},
	publisher = {{MIT} Press},
	author = {Röder, Brigitte and Rösler, Frank},
	date = {2004},
	keywords = {Blind, Sensory Deprivation, Language, Brain, Models, Intersensory Processes, Deaf, Consequence, Neural Plasticity},
	file = {Snapshot:/home/felix/Zotero/storage/LEVFKIST/2004-17469-046.html:text/html}
}

@article{schroeder_somatosensory_2001,
	title = {Somatosensory Input to Auditory Association Cortex in the Macaque Monkey},
	volume = {85},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.2001.85.3.1322},
	doi = {10.1152/jn.2001.85.3.1322},
	abstract = {We investigated the convergence of somatosensory and auditory inputs in within subregions of macaque auditory cortex. Laminar current source density and multiunit activity profiles were sampled with linear array multielectrodes during penetrations of the posterior superior temporal plane in three macaque monkeys. At each recording site, auditory responses to binaural clicks, pure tones, and band-passed noise, all presented by earphones, were compared with somatosensory responses evoked by contralateral median nerve stimulation. Subjects were awake but were not required to discriminate the stimuli. Borders between A1 and surrounding belt regions were identified by mapping best frequency and stimulus preferences and by subsequent histological analysis. Regions immediately caudomedial to A1 had robust somatosensory responses co-represented with auditory responses. In these regions, both somatosensory and auditory response profiles had “feedforward” patterns; initial excitation beginning in Lamina 4 and spreading to extragranular laminae. Auditory and somatosensory responses displayed a high degree of temporal overlap. Anatomical reconstruction indicated that the somatosensory input region includes, but may not be restricted to, the caudomedial auditory association cortex. As was earlier reported for this region, auditory frequency tuning curves were broad and band-passed noise responses were larger than pure tone responses. No somatosensory responses were observed in A1. These findings suggest a potential neural substrate for multisensory integration at an early stage of auditory cortical processing.},
	pages = {1322--1327},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Schroeder, Charles E. and Lindsley, Robert W. and Specht, Colleen and Marcovici, Alvin and Smiley, John F. and Javitt, Daniel C.},
	urldate = {2019-05-05},
	date = {2001-03-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/FH7CASUT/Schroeder et al. - 2001 - Somatosensory Input to Auditory Association Cortex.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/3BE3L34B/jn.2001.85.3.html:text/html}
}

@article{lomber_cross-modal_2010,
	title = {Cross-modal plasticity in specific auditory cortices underlies visual compensations in the deaf},
	volume = {13},
	rights = {2010 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2653},
	doi = {10.1038/nn.2653},
	abstract = {When the brain is deprived of input from one sensory modality, it often compensates with supranormal performance in one or more of the intact sensory systems. In the absence of acoustic input, it has been proposed that cross-modal reorganization of deaf auditory cortex may provide the neural substrate mediating compensatory visual function. We tested this hypothesis using a battery of visual psychophysical tasks and found that congenitally deaf cats, compared with hearing cats, have superior localization in the peripheral field and lower visual movement detection thresholds. In the deaf cats, reversible deactivation of posterior auditory cortex selectively eliminated superior visual localization abilities, whereas deactivation of the dorsal auditory cortex eliminated superior visual motion detection. Our results indicate that enhanced visual performance in the deaf is caused by cross-modal reorganization of deaf auditory cortex and it is possible to localize individual visual functions in discrete portions of reorganized auditory cortex.},
	pages = {1421--1427},
	number = {11},
	journaltitle = {Nature Neuroscience},
	author = {Lomber, Stephen G. and Meredith, M. Alex and Kral, Andrej},
	urldate = {2019-05-05},
	date = {2010-11},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/S8LI2J3R/nn.html:text/html}
}

@article{bavelier_cross-modal_2002,
	title = {Cross-modal plasticity: where and how?},
	volume = {3},
	rights = {2002 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn848},
	doi = {10.1038/nrn848},
	shorttitle = {Cross-modal plasticity},
	abstract = {Both young and adult brains show a remarkable capacity to be shaped by environmental input, and to be altered by the deprivation of input in one sensory modality (for example, deafness or blindness). However, different areas and functions show different susceptibilities to such plasticity, and different times during the life span of the individual when they are sensitive to such changes. 
                  
                  
                     Plastic changes, such as increases in spine density or neuronal density, can occur in the primary cortices that mediate the spared modalities after sensory deprivation in one modality. These changes might underlie reports of behavioural improvements in the spared modalities and/or might result from increased reliance on these modalities. 
                  
                  
                     In humans, it is difficult (but not impossible) to distinguish between changes that result from sensory deprivation (for example, deafness) and those that result from altered linguistic experience (for example, using sign language). 
                  
                  
                     Improvements in behaviour tend to involve complex processing rather than simple thresholds. 
                  
                  
                     Polymodal association areas of cortex can also become reorganized after sensory deprivation. For example, visual deprivation can lead to increased recruitment of parietal cortex and the superior colliculus by the auditory and somatosensory systems. Few studies have investigated the possible critical periods for such reorganization. Studies in deaf and blind humans indicate that recruitment of polymodal association areas might be associated with improved performance in the spared modalities. 
                  
                  
                     The primary cortex that is associated with the deprived modality might also undergo plastic changes, in some cases becoming activated by stimuli in the spared modalities. Such activation might result from the persistence of normally pruned polymodal connections, but has been difficult to show in humans. 
                  
                  
                     Cross-modal plasticity might result from a variety of mechanisms. Changes in subcortical connectivity might lead to recruitment of the primary visual cortex by auditory inputs, as in the case of the blind mole rat. Other possible mechanisms include alterations in feedback between cortico-cortical connections and the stabilization of long-range connections, such as those found between the primary visual and auditory cortices in the monkey. 
                  
                  
                     An understanding of these mechanisms could help in deciding when to provide sensory implants (such as cochlear implants in the deaf or retinal implants in the blind): although some mechanisms might be available throughout life, others seem to be restricted in their time periods of occurrence and in the types of altered experience that they respond to. For example, changes in subcortical connectivity are less likely to occur in the adult and, if they occur at all, might be observed only after major deafferentation. Changes in cortico-cortical connections, however, might be more amenable to changes throughout life and across a variety of altered experiences. 
                  
                  
                     Further understanding of the plastic changes that follow sensory deprivation will help to clarify the role of sensory input in specifying cortical responses and behaviour. Such knowledge will also be important for efforts to restore lost sensory modalities by implants or other techniques.
                  
                
                Both young and adult brains show a remarkable capacity to be shaped by environmental input, and to be altered by the deprivation of input in one sensory modality (for example, deafness or blindness). However, different areas and functions show different susceptibilities to such plasticity, and different times during the life span of the individual when they are sensitive to such changes.   Plastic changes, such as increases in spine density or neuronal density, can occur in the primary cortices that mediate the spared modalities after sensory deprivation in one modality. These changes might underlie reports of behavioural improvements in the spared modalities and/or might result from increased reliance on these modalities.   In humans, it is difficult (but not impossible) to distinguish between changes that result from sensory deprivation (for example, deafness) and those that result from altered linguistic experience (for example, using sign language).   Improvements in behaviour tend to involve complex processing rather than simple thresholds.   Polymodal association areas of cortex can also become reorganized after sensory deprivation. For example, visual deprivation can lead to increased recruitment of parietal cortex and the superior colliculus by the auditory and somatosensory systems. Few studies have investigated the possible critical periods for such reorganization. Studies in deaf and blind humans indicate that recruitment of polymodal association areas might be associated with improved performance in the spared modalities.   The primary cortex that is associated with the deprived modality might also undergo plastic changes, in some cases becoming activated by stimuli in the spared modalities. Such activation might result from the persistence of normally pruned polymodal connections, but has been difficult to show in humans.   Cross-modal plasticity might result from a variety of mechanisms. Changes in subcortical connectivity might lead to recruitment of the primary visual cortex by auditory inputs, as in the case of the blind mole rat. Other possible mechanisms include alterations in feedback between cortico-cortical connections and the stabilization of long-range connections, such as those found between the primary visual and auditory cortices in the monkey.   An understanding of these mechanisms could help in deciding when to provide sensory implants (such as cochlear implants in the deaf or retinal implants in the blind): although some mechanisms might be available throughout life, others seem to be restricted in their time periods of occurrence and in the types of altered experience that they respond to. For example, changes in subcortical connectivity are less likely to occur in the adult and, if they occur at all, might be observed only after major deafferentation. Changes in cortico-cortical connections, however, might be more amenable to changes throughout life and across a variety of altered experiences.   Further understanding of the plastic changes that follow sensory deprivation will help to clarify the role of sensory input in specifying cortical responses and behaviour. Such knowledge will also be important for efforts to restore lost sensory modalities by implants or other techniques.},
	pages = {443},
	number = {6},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Bavelier, Daphne and Neville, Helen J.},
	urldate = {2019-05-05},
	date = {2002-06},
	file = {Snapshot:/home/felix/Zotero/storage/G95HHECN/nrn848.html:text/html}
}

@article{bavelier_cross-modal_2002-1,
	title = {Cross-modal plasticity: where and how?},
	volume = {3},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn848},
	doi = {10.1038/nrn848},
	shorttitle = {Cross-modal plasticity},
	pages = {443--452},
	number = {6},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Bavelier, Daphne and Neville, Helen J.},
	urldate = {2019-05-05},
	date = {2002-06},
	langid = {english},
	file = {Bavelier and Neville - 2002 - Cross-modal plasticity where and how.pdf:/home/felix/Zotero/storage/Y24594MH/Bavelier and Neville - 2002 - Cross-modal plasticity where and how.pdf:application/pdf}
}

@incollection{rauschecker_chapter_1996,
	title = {Chapter 22 Substitution of visual by auditory inputs in the cat's anterior ectosylvian cortex},
	volume = {112},
	url = {http://www.sciencedirect.com/science/article/pii/S0079612308633385},
	series = {Extrageniculostriate Mechanisms Underlying Visually-Guided Orientation Behavior},
	abstract = {Long-term visual deprivation from birth leads to reorganization of the anterior ectosylvian region of the cat's cortex. A visual area in the fundus of anterior ectosylvian sulcus ({AES})—anterior ectosylvian visual ({AEV}) area, in which neurons normally respond briskly to visual stimuli, is taken over almost completely by auditory and somatosensory inputs. Auditory neurons are sharply tuned to the location of a sound source in azimuth. A higher than normal proportion of neurons in the {AES} of visually deprived cats responds to multimodal stimuli. Takeover of visual regions by non-visual inputs can be explained by the same mechanisms that are invoked for developmental plasticity within the visual system; neural activity and competition among different inputs leads to the changes in synaptic efficacy. Additional sprouting cannot be excluded. The radical changes of sensory modality within the {AES}, caused by visual deprivation, suggest that the same code is used by visual, auditory and somatosensory maps in this region to represent the sensory environment and lead to sensorimotor transformation.},
	pages = {313--323},
	booktitle = {Progress in Brain Research},
	publisher = {Elsevier},
	author = {Rauschecker, J. P.},
	editor = {Norita, Masao and Bando, Takehiko and Stein, Barry E.},
	urldate = {2019-05-05},
	date = {1996-01-01},
	doi = {10.1016/S0079-6123(08)63338-5},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/GFPR5IR3/S0079612308633385.html:text/html}
}

@article{rauschecker_compensatory_1995,
	title = {Compensatory plasticity and sensory substitution in the cerebral cortex},
	volume = {18},
	issn = {0166-2236},
	url = {http://www.sciencedirect.com/science/article/pii/016622369593948W},
	doi = {10.1016/0166-2236(95)93948-W},
	abstract = {Cats deprived visually from birth show few overt impairments in their natural behavior. Therefore, they seem well suited as an animal model for the study of compensatory plasticity after early vision loss. It can be demonstrated that binocularly deprived cats show improved abilities of auditory localization, and at least equal tactile behavior compared to normal controls. Within the anterior ectosylvian cortex of binocularly deprived cats, where different sensory modalities come together, the anterior ectosylvian visual area is completely taken over by auditory and somatosensory inputs. Furthermore, the auditory spatial tuning of single units in this cortical region is sharpened significantly as a result of visual deprivation. Somatosensory compensation for early loss of vision can be demonstrated by a hypertrophy of the facial vibrissae, and a corresponding expansion of their central representation in the somatosensory cortex of binocularly deprived animals. The compensatory changes in the cortex can be explained by a reorganization of sensory representations under the guidance of sensorimotor feedback rather than by instruction through an extraneous ‘supervisory’ signal. These processes might form the neural basis of sensory substitution in blind humans.},
	pages = {36--43},
	number = {1},
	journaltitle = {Trends in Neurosciences},
	shortjournal = {Trends in Neurosciences},
	author = {Rauschecker, Josef P.},
	urldate = {2019-05-05},
	date = {1995-01-01},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/7NEXEMWV/016622369593948W.html:text/html}
}

@article{hong_lore_central_1991,
	title = {Central and peripheral visual processing in hearing and nonhearing individuals},
	volume = {29},
	issn = {0090-5054},
	url = {https://doi.org/10.3758/BF03333964},
	doi = {10.3758/BF03333964},
	abstract = {Hearing and nonhearing students responded to stimuli presented in their central and peripheral visual fields. No significant difference was found between the reaction times of hearing and nonhearing students in the central visual field condition. However, in the peripheral visual field condition, nonhearing students were significantly faster than hearing students. Hearing-impaired students may have developed a more alert peripheral vision. Perhaps, as a result of their auditory impairment, nonhearing students make greater use of visual communication and need to monitor new information more via the visual channel. Specific suggestions for future research on the development of peripheral vision are discussed.},
	pages = {437--440},
	number = {5},
	journaltitle = {Bulletin of the Psychonomic Society},
	shortjournal = {Bull. Psychon. Soc.},
	author = {Hong Lore, Wing and Song, Shareen},
	urldate = {2019-05-05},
	date = {1991-05-01},
	langid = {english},
	keywords = {Deaf People, Peripheral Vision, Peripheral Visual Field, Sign Language, Visual Field},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/JZ97QSAI/Hong Lore and Song - 1991 - Central and peripheral visual processing in hearin.pdf:application/pdf}
}

@article{calvert_crossmodal_2001,
	title = {Crossmodal Processing in the Human Brain: Insights from Functional Neuroimaging Studies},
	volume = {11},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/11/12/1110/492310},
	doi = {10.1093/cercor/11.12.1110},
	shorttitle = {Crossmodal Processing in the Human Brain},
	abstract = {Abstract.  Modern brain imaging techniques have now made it possible to study the neural sites and mechanisms underlying crossmodal processing in the human brai},
	pages = {1110--1123},
	number = {12},
	journaltitle = {Cerebral Cortex},
	shortjournal = {Cereb Cortex},
	author = {Calvert, Gemma A.},
	urldate = {2019-05-05},
	date = {2001-12-01},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/96F9HKP4/Calvert - 2001 - Crossmodal Processing in the Human Brain Insights.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/WXY66L6J/492310.html:text/html}
}

@article{bottari_enhanced_2010,
	title = {Enhanced reactivity to visual stimuli in deaf individuals},
	volume = {28},
	issn = {0922-6028},
	url = {https://content.iospress.com/articles/restorative-neurology-and-neuroscience/rnn00502},
	doi = {10.3233/RNN-2010-0502},
	abstract = {Purpose: Several studies have reported faster response time to visual stimuli in profoundly deaf individuals. This result is often linked to the processing of peripheral targets, and it is assumed to occur in relation to attention orienting. We evalu},
	pages = {167--179},
	number = {2},
	journaltitle = {Restorative Neurology and Neuroscience},
	author = {Bottari, Davide and Nava, Elena and Ley, Pia and Pavani, Francesco},
	urldate = {2019-05-05},
	date = {2010-01-01},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/QS4Q6NAY/rnn00502.html:text/html}
}

@article{davide_enhanced_2010,
	title = {Enhanced reactivity to visual stimuli in deaf individuals},
	rights = {©2010 {IOS} Press. All rights reserved},
	issn = {0922-6028},
	url = {http://www.medra.org/servlet/aliasResolver?alias=iospress&genre=article&issn=0922-6028&volume=28&issue=2&spage=167&doi=10.3233/RNN-2010-0502},
	doi = {10.3233/RNN-2010-0502},
	abstract = {Methods: We examined 11 deaf individuals and 11 hearing controls, in a simple detection task and in a shape discrimination task. While simple detection can be performed under distributed attention, shape discrimination requires orienting of spatial attention to the target. The same visual targets served for both tasks, presented at central or peripheral locations and corrected for cortical magniﬁcation.
Results: The simple detection task revealed faster {RTs} in deaf than hearing controls, regardless of target location. Moreover, while hearing controls paid a cost in responding to peripheral than central targets, deaf participants performed equally well regardless of target eccentricity. In the shape discrimination task deaf never outperformed hearing controls.
Conclusions: These ﬁndings reveal that enhanced reactivity to visual stimuli in the deaf cannot be explained only by faster orienting of visual attention and can emerge for central as well as peripheral targets. Moreover, the persisting advantage for peripheral locations in the deaf, observed here under distributed attention, suggests that this spatially-selective effect could result from reorganised sensory processing rather than different attentional gradients.},
	pages = {167--179},
	number = {2},
	journaltitle = {Restorative Neurology and Neuroscience},
	author = {Davide, Bottari and Elena, Nava and Pia, Ley and Francesco, Pavani},
	urldate = {2019-05-05},
	date = {2010},
	langid = {english},
	file = {Davide et al. - 2010 - Enhanced reactivity to visual stimuli in deaf indi.pdf:/home/felix/Zotero/storage/9NDPQRXS/Davide et al. - 2010 - Enhanced reactivity to visual stimuli in deaf indi.pdf:application/pdf}
}

@article{lazzouni_compensatory_2014,
	title = {Compensatory plasticity: time matters},
	volume = {8},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2014.00340/full},
	doi = {10.3389/fnhum.2014.00340},
	shorttitle = {Compensatory plasticity},
	abstract = {Plasticity in the human and animal brain is the rule, the base for development, and the way to deal effectively with the environment for making the most efficient use of all the senses. When the brain is deprived of one sensory modality, plasticity becomes compensatory: the exception that invalidates the general loss hypothesis giving the opportunity of effective change. Sensory deprivation comes with massive alterations in brain structure and function, behavioural outcomes, and neural interactions. Blind individuals do as good as the sighted and even more, show superior abilities in auditory, tactile and olfactory processing. This behavioural enhancement is accompanied with changes in occipital cortex function, where visual areas at different levels become responsive to non-visual information. The intact senses are in general used more efficiently in the blind but are also used more exclusively. New findings are disentangling these two aspects of compensatory plasticity. What is due to visual deprivation and what is dependent on the extended use of spared modalities? The latter seems to contribute highly to compensatory changes in the congenitally blind. Short term deprivation through the use of blindfolds shows that cortical excitability of the visual cortex is likely to show rapid modulatory changes after few minutes of light deprivation and therefore changes are possible in adulthood. However, reorganization remains more pronounced in the congenitally blind. Cortico-cortical pathways between visual areas and the areas of preserved sensory modalities are inhibited in the presence of vision, but are unmasked after loss of vision or blindfolding as a mechanism likely to drive cross-modal information to the deafferented visual cortex. Plasticity in the blind is also accompanied with neurochemical and morphological changes; both intrinsic connectivity and functional coupling at rest are altered but are likewise dependent on different sensory experience and training.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Lazzouni, Latifa and Lepore, Franco},
	urldate = {2019-05-05},
	date = {2014},
	keywords = {blindfolding, Compensatory plasticity, cortico-cortical pathways, early visual deprivation, onset time},
	file = {Full Text PDF:/home/felix/Zotero/storage/MD43UM4S/Lazzouni and Lepore - 2014 - Compensatory plasticity time matters.pdf:application/pdf}
}

@article{theoret_behavioral_2004,
	title = {Behavioral and neuroplastic changes in the blind: evidence for functionally relevant cross-modal interactions},
	volume = {98},
	issn = {0928-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425704000828},
	doi = {10.1016/j.jphysparis.2004.03.009},
	series = {Representation of 3-D Space Using Different Senses In Different Species},
	shorttitle = {Behavioral and neuroplastic changes in the blind},
	abstract = {The study of blind individuals provides insight into the brain re-organization and behavioral compensations that occur following sensory deprivation. While behavioral studies have yielded conflicting results in terms of performance levels within the remaining senses, deafferentation of visual cortical areas through peripheral blindness results in clear neuroplastic changes. Most striking is the activation of occipital cortex in response to auditory and tactile stimulation. Indeed, parts of the “unimodal” visual cortex are recruited by other sensory modalities to process sensory information in a functionally relevant manner. In addition, a larger area of the sensorimotor cortex is devoted to the representation of the reading finger in blind Braille readers. The “visual” function of the deafferented occipital cortex is also altered, where transcranial magnetic stimulation-induced phosphenes can be elicited in only 20\% of blind subjects. The neural mechanisms underlying these changes remain elusive but recent data showing rapid cross-modal plasticity in blindfolded, sighted subjects argue against the establishment of new connections to explain cross-modal interactions in the blind. Rather, latent pathways that participate in multisensory percepts in sighted subjects might be unmasked and may be potentiated in the event of complete loss of visual input. These issues have important implications for the development of visual prosthesis aimed at restoring some degree of vision in the blind.},
	pages = {221--233},
	number = {1},
	journaltitle = {Journal of Physiology-Paris},
	shortjournal = {Journal of Physiology-Paris},
	author = {Théoret, Hugo and Merabet, Lotfi and Pascual-Leone, Alvaro},
	urldate = {2019-05-05},
	date = {2004-01-01},
	keywords = {Plasticity, Cross-modal, Multimodal, Blindness, Transcranial magnetic stimulation, Visual cortex},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/WBAMUXCU/S0928425704000828.html:text/html}
}

@article{theoret_behavioral_2004-1,
	title = {Behavioral and neuroplastic changes in the blind: evidence for functionally relevant cross-modal interactions},
	volume = {98},
	issn = {0928-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425704000828},
	doi = {10.1016/j.jphysparis.2004.03.009},
	series = {Representation of 3-D Space Using Different Senses In Different Species},
	shorttitle = {Behavioral and neuroplastic changes in the blind},
	abstract = {The study of blind individuals provides insight into the brain re-organization and behavioral compensations that occur following sensory deprivation. While behavioral studies have yielded conflicting results in terms of performance levels within the remaining senses, deafferentation of visual cortical areas through peripheral blindness results in clear neuroplastic changes. Most striking is the activation of occipital cortex in response to auditory and tactile stimulation. Indeed, parts of the “unimodal” visual cortex are recruited by other sensory modalities to process sensory information in a functionally relevant manner. In addition, a larger area of the sensorimotor cortex is devoted to the representation of the reading finger in blind Braille readers. The “visual” function of the deafferented occipital cortex is also altered, where transcranial magnetic stimulation-induced phosphenes can be elicited in only 20\% of blind subjects. The neural mechanisms underlying these changes remain elusive but recent data showing rapid cross-modal plasticity in blindfolded, sighted subjects argue against the establishment of new connections to explain cross-modal interactions in the blind. Rather, latent pathways that participate in multisensory percepts in sighted subjects might be unmasked and may be potentiated in the event of complete loss of visual input. These issues have important implications for the development of visual prosthesis aimed at restoring some degree of vision in the blind.},
	pages = {221--233},
	number = {1},
	journaltitle = {Journal of Physiology-Paris},
	shortjournal = {Journal of Physiology-Paris},
	author = {Théoret, Hugo and Merabet, Lotfi and Pascual-Leone, Alvaro},
	urldate = {2019-05-05},
	date = {2004-01-01},
	keywords = {Plasticity, Cross-modal, Multimodal, Blindness, Transcranial magnetic stimulation, Visual cortex},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/95HMXE4V/Théoret et al. - 2004 - Behavioral and neuroplastic changes in the blind .pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/F2CL4C3X/S0928425704000828.html:text/html}
}

@article{voss_evidence_2014,
	title = {Evidence for both compensatory plastic and disuse atrophy-related neuroanatomical changes in the blind},
	volume = {137},
	issn = {0006-8950},
	url = {https://academic.oup.com/brain/article/137/4/1224/370778},
	doi = {10.1093/brain/awu030},
	abstract = {How does blindness affect brain structure? Voss et al. compare blind subjects and sighted controls using voxel-based morphometry and magnetization transfer imag},
	pages = {1224--1240},
	number = {4},
	journaltitle = {Brain},
	shortjournal = {Brain},
	author = {Voss, Patrice and Pike, Bruce G. and Zatorre, Robert J.},
	urldate = {2019-05-05},
	date = {2014-04-01},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/5FFCXKUC/Voss et al. - 2014 - Evidence for both compensatory plastic and disuse .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/LBU2CABQ/370778.html:text/html}
}

@article{merabet_neural_2010,
	title = {Neural reorganization following sensory loss: the opportunity of change},
	volume = {11},
	rights = {2009 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn2758},
	doi = {10.1038/nrn2758},
	shorttitle = {Neural reorganization following sensory loss},
	abstract = {There is growing evidence that sensory deprivation is associated with crossmodal neuroplastic changes in the brain. After visual or auditory deprivation, brain areas that are normally associated with the lost sense are recruited by spared sensory modalities. These changes underlie adaptive and compensatory behaviours in blind and deaf individuals. Although there are differences between these populations owing to the nature of the deprived sensory modality, there seem to be common principles regarding how the brain copes with sensory loss and the factors that influence neuroplastic changes. Here, we discuss crossmodal neuroplasticity with regards to behavioural adaptation after sensory deprivation and highlight the possibility of maladaptive consequences within the context of rehabilitation.},
	pages = {44--52},
	number = {1},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Merabet, Lotfi B. and Pascual-Leone, Alvaro},
	urldate = {2019-05-05},
	date = {2010-01},
	langid = {english},
	file = {Accepted Version:/home/felix/Zotero/storage/RR2C2FBV/Merabet and Pascual-Leone - 2010 - Neural reorganization following sensory loss the .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/VSE64STJ/nrn2758.html:text/html}
}

@article{burton_adaptive_2002,
	title = {Adaptive Changes in Early and Late Blind: A {fMRI} Study of Braille Reading},
	volume = {87},
	issn = {0022-3077},
	url = {https://www.physiology.org/doi/full/10.1152/jn.00285.2001},
	doi = {10.1152/jn.00285.2001},
	shorttitle = {Adaptive Changes in Early and Late Blind},
	abstract = {Braille reading depends on remarkable adaptations that connect the somatosensory system to language. We hypothesized that the pattern of cortical activations in blind individuals reading Braille would reflect these adaptations. Activations in visual (occipital-temporal), frontal-language, and somatosensory cortex in blind individuals reading Braille were examined for evidence of differences relative to previously reported studies of sighted subjects reading print or receiving tactile stimulation. Nine congenitally blind and seven late-onset blind subjects were studied with {fMRI} as they covertly performed verb generation in response to reading Braille embossed nouns. The control task was reading the nonlexical Braille string “\#\#\#\#\#\#”. This study emphasized image analysis in individual subjects rather than pooled data. Group differences were examined by comparing magnitudes and spatial extent of activated regions first determined to be significant using the general linear model. The major adaptive change was robust activation of visual cortex despite the complete absence of vision in all subjects. This included foci in peri-calcarine, lingual, cuneus and fusiform cortex, and in the lateral and superior occipital gyri encompassing primary (V1), secondary (V2), and higher tier ({VP}, V4v, {LO} and possibly V3A) visual areas previously identified in sighted subjects. Subjects who never had vision differed from late blind subjects in showing even greater activity in occipital-temporal cortex, provisionally corresponding to V5/{MT} and V8. In addition, the early blind had stronger activation of occipital cortex located contralateral to the hand used for reading Braille. Responses in frontal and parietal cortex were nearly identical in both subject groups. There was no evidence of modifications in frontal cortex language areas (inferior frontal gyrus and dorsolateral prefrontal cortex). Surprisingly, there was also no evidence of an adaptive expansion of the somatosensory or primary motor cortex dedicated to the Braille reading finger(s). Lack of evidence for an expected enlargement of the somatosensory representation may have resulted from balanced tactile stimulation and gross motor demands during Braille reading of nouns and the control fields. Extensive engagement of visual cortex without vision is discussed in reference to the special demands of Braille reading. It is argued that these responses may represent critical language processing mechanisms normally present in visual cortex.},
	pages = {589--607},
	number = {1},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Burton, H. and Snyder, A. Z. and Conturo, T. E. and Akbudak, E. and Ollinger, J. M. and Raichle, M. E.},
	urldate = {2019-05-05},
	date = {2002-01-01},
	file = {Full Text PDF:/home/felix/Zotero/storage/STAVSRX3/Burton et al. - 2002 - Adaptive Changes in Early and Late Blind A fMRI S.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/M9XKQFEW/jn.00285.html:text/html}
}

@article{buchel_different_1998,
	title = {Different activation patterns in the visual cortex of late and congenitally blind subjects.},
	volume = {121},
	issn = {0006-8950},
	url = {https://academic.oup.com/brain/article/121/3/409/360227},
	doi = {10.1093/brain/121.3.409},
	abstract = {Abstract.  A key issue in developmental neuroscience is the role of activity-dependent mechanisms in the epigenetic induction of functional organization in visu},
	pages = {409--419},
	number = {3},
	journaltitle = {Brain},
	shortjournal = {Brain},
	author = {Büchel, C. and Price, C. and Frackowiak, R. S. and Friston, K.},
	urldate = {2019-05-05},
	date = {1998-03-01},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/AM69QDVU/Büchel et al. - 1998 - Different activation patterns in the visual cortex.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/JJ3Q6ARZ/360227.html:text/html}
}

@article{sadato_activation_1996,
	title = {Activation of the primary visual cortex by Braille reading in blind subjects},
	volume = {380},
	rights = {1996 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/380526a0},
	doi = {10.1038/380526a0},
	abstract = {{PRIMARY} visual cortex receives visual input from the eyes through the lateral geniculate nuclei, but is not known to receive input from other sensory modalities1. Its level of activity, both at rest and during auditory or tactile tasks, is higher in blind subjects than in normal controls2, suggesting that it can subserve non-visual functions; however, a direct effect of non-visual tasks on activation has not been demonstrated2–4. To determine whether the visual cortex receives input from the somatosensory system5–8, we used positron emission tomography ({PET}) to measure activation during tactile discrimination tasks in normal subjects and in Braille readers blinded in early life. Blind subjects showed activation of primary and secondary visual cortical areas during tactile tasks, whereas normal controls showed deactiva-tion. A simple tactile stimulus that did not require discrimination produced no activation of visual areas in either group. Thus, in blind subjects, cortical areas normally reserved for vision may be activated by other sensory modalities.},
	pages = {526},
	number = {6574},
	journaltitle = {Nature},
	author = {Sadato, Norihiro and Pascual-Leone, Alvaro and Grafman, Jordan and Ibañez, Vicente and Deiber, Marie-Pierre and Dold, George and Hallett, Mark},
	urldate = {2019-05-05},
	date = {1996-04},
	file = {Snapshot:/home/felix/Zotero/storage/QN2NCYH5/380526a0.html:text/html}
}

@article{cohen_functional_1997,
	title = {Functional relevance of cross-modal plasticity in blind humans},
	volume = {389},
	rights = {1997 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/38278},
	doi = {10.1038/38278},
	abstract = {Functional imaging studies of people who were blind from an early age have revealed that their primary visual cortex can be activated by Braille reading and other tactile discrimination tasks1. Other studies have also shown that visual cortical areas can be activated by somatosensory input in blind subjects but not those with sight2,3,4,5,6,7. The significance of this cross-modal plasticity is unclear, however, as it is not known whether the visual cortex can process somatosensory information in a functionally relevant way. To address this issue, we used transcranial magnetic stimulation to disrupt the function of different cortical areas in people who were blind from an early age as they identified Braille or embossed Roman letters. Transient stimulation of the occipital (visual) cortex induced errors in both tasks and distorted the tactile perceptions of blind subjects. In contrast, occipital stimulation had no effect on tactile performance in normal-sighted subjects, whereas similar stimulation is known to disrupt their visual performance. We conclude that blindness from an early age can cause the visual cortex to be recruited to a role in somatosensory processing. We propose that this cross-modal plasticity may account in part for the superior tactile perceptual abilities of blind subjects.},
	pages = {180},
	number = {6647},
	journaltitle = {Nature},
	author = {Cohen, Leonardo G. and Celnik, Pablo and Pascual-Leone, Alvaro and Corwell, Brian and Faiz, Lala and Dambrosia, James and Honda, Manabu and Sadato, Norihiro and Gerloff, Christian and Catala´, M. Dolores and Hallett, Mark},
	urldate = {2019-05-05},
	date = {1997-09},
	file = {Snapshot:/home/felix/Zotero/storage/BCYR8YLT/38278.html:text/html}
}

@article{kujala_visual_1995,
	title = {Visual cortex activation in blind humans during sound discrimination},
	volume = {183},
	issn = {0304-3940},
	url = {http://www.sciencedirect.com/science/article/pii/0304394094111356},
	doi = {10.1016/0304-3940(94)11135-6},
	abstract = {We used a whole-scalp magnetometer with 122 planar gradiometers to study the activity of the visual cortex of five blind humans deprived of visual input since early infancy. Magnetic responses were recorded to pitch changes in a sound sequence when the subjects were either counting these changes or ignoring the stimuli. In two of the blind subjects, magnetic resonance images were also obtained, showing normal visual cortex macroanatomy. In these subjects, the magnetic responses to counted pitch changes were located at visual and temporal cortices whereas ignored pitch changes activated the temporal cortices almost exclusively. Also in two of the other three blind, the visual-cortex activation was detectable in the auditory counting task. Our results suggest that the visual cortex of blind humans can participate in auditory discrimination.},
	pages = {143--146},
	number = {1},
	journaltitle = {Neuroscience Letters},
	shortjournal = {Neuroscience Letters},
	author = {Kujala, Teija and Huotilainen, Minna and Sinkkonen, Janne and Ahonen, Antti I. and Alho, Kimmo and Hämälä:inen, Matti S. and Ilmoniemi, Risto J. and Kajola, Matti and Knuutila, Jukka E. T. and Lavikainen, Juha and Salonen, Oili and Simola, Juha and Standertskjöld-Nordenstam, Carl-Gustaf and Tiitinen, Hannu and Tissari, Satu O. and Näätänen, Risto},
	urldate = {2019-05-05},
	date = {1995-01-02},
	keywords = {Human, Plasticity, Audition, Blindness, Visual cortex, Magnetic resonance imaging, Magnetoencephalography},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/Q4HMSYDB/Kujala et al. - 1995 - Visual cortex activation in blind humans during so.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/2WF39JCD/0304394094111356.html:text/html}
}

@article{voss_differential_2008,
	title = {Differential occipital responses in early- and late-blind individuals during a sound-source discrimination task},
	volume = {40},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811907011354},
	doi = {10.1016/j.neuroimage.2007.12.020},
	abstract = {Blind individuals do not necessarily receive more auditory stimulation than sighted individuals. However, to interact effectively with their environment, they have to rely on non-visual cues (in particular auditory) to a greater extent. Often benefiting from cerebral reorganization, they not only learn to rely more on such cues but also may process them better and, as a result, demonstrate exceptional abilities in auditory spatial tasks. Here we examine the effects of blindness on brain activity, using positron emission tomography ({PET}), during a sound-source discrimination task ({SSDT}) in both early- and late-onset blind individuals. This should not only provide an answer to the question of whether the blind manifest changes in brain activity but also allow a direct comparison of the two subgroups performing an auditory spatial task. The task was presented under two listening conditions: one binaural and one monaural. The binaural task did not show any significant behavioural differences between groups, but it demonstrated striate and extrastriate activation in the early-blind groups. A subgroup of early-blind individuals, on the other hand, performed significantly better than all the other groups during the monaural task, and these enhanced skills were correlated with elevated activity within the left dorsal extrastriate cortex. Surprisingly, activation of the right ventral visual pathway, which was significantly activated in the late-blind individuals during the monaural task, was negatively correlated with performance. This suggests the possibility that not all cross-modal plasticity is beneficial. Overall, our results not only support previous findings showing that occipital cortex of early-blind individuals is functionally engaged in spatial auditory processing but also shed light on the impact the age of onset of blindness can have on the ensuing cross-modal plasticity.},
	pages = {746--758},
	number = {2},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Voss, Patrice and Gougoux, Frederic and Zatorre, Robert J. and Lassonde, Maryse and Lepore, Franco},
	urldate = {2019-05-05},
	date = {2008-04-01},
	keywords = {Blindness, Auditory localization, Cross-modal reorganization, Functional neuroimaging, Visual cortex plasticity},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/4BE7MSZC/Voss et al. - 2008 - Differential occipital responses in early- and lat.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/AJRMYE6R/S1053811907011354.html:text/html}
}

@online{noauthor_cortical_nodate,
	title = {Cortical activity to vibrotactile stimulation: An {fMRI} study in blind and sighted individuals - Burton - 2004 - Human Brain Mapping - Wiley Online Library},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.20064},
	urldate = {2019-05-05},
	file = {Cortical activity to vibrotactile stimulation\: An fMRI study in blind and sighted individuals - Burton - 2004 - Human Brain Mapping - Wiley Online Library:/home/felix/Zotero/storage/JSGL7NQP/hbm.html:text/html}
}

@article{gougoux_functional_2005,
	title = {A Functional Neuroimaging Study of Sound Localization: Visual Cortex Activity Predicts Performance in Early-Blind Individuals},
	volume = {3},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.0030027},
	doi = {10.1371/journal.pbio.0030027},
	shorttitle = {A Functional Neuroimaging Study of Sound Localization},
	abstract = {Blind individuals often demonstrate enhanced nonvisual perceptual abilities. However, the neural substrate that underlies this improved performance remains to be fully understood. An earlier behavioral study demonstrated that some early-blind people localize sounds more accurately than sighted controls using monaural cues. In order to investigate the neural basis of these behavioral differences in humans, we carried out functional imaging studies using positron emission tomography and a speaker array that permitted pseudo-free-field presentations within the scanner. During binaural sound localization, a sighted control group showed decreased cerebral blood flow in the occipital lobe, which was not seen in early-blind individuals. During monaural sound localization (one ear plugged), the subgroup of early-blind subjects who were behaviorally superior at sound localization displayed two activation foci in the occipital cortex. This effect was not seen in blind persons who did not have superior monaural sound localization abilities, nor in sighted individuals. The degree of activation of one of these foci was strongly correlated with sound localization accuracy across the entire group of blind subjects. The results show that those blind persons who perform better than sighted persons recruit occipital areas to carry out auditory localization under monaural conditions. We therefore conclude that computations carried out in the occipital cortex specifically underlie the enhanced capacity to use monaural cues. Our findings shed light not only on intermodal compensatory mechanisms, but also on individual differences in these mechanisms and on inhibitory patterns that differ between sighted individuals and those deprived of vision early in life.},
	pages = {e27},
	number = {2},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Gougoux, Frédéric and Zatorre, Robert J. and Lassonde, Maryse and Voss, Patrice and Lepore, Franco},
	urldate = {2019-05-05},
	date = {2005-01-25},
	langid = {english},
	keywords = {Vision, Blindness, Visual cortex, Cerebral blood flow assay, Ears, Neuroimaging, Occipital lobe, Positron emission tomography},
	file = {Full Text PDF:/home/felix/Zotero/storage/FYW2KI3E/Gougoux et al. - 2005 - A Functional Neuroimaging Study of Sound Localizat.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/KEQ6TEAA/article.html:text/html}
}

@article{burton_cortical_2004,
	title = {Cortical activity to vibrotactile stimulation: An {fMRI} study in blind and sighted individuals},
	volume = {23},
	rights = {Copyright © 2004 Wiley‐Liss, Inc.},
	issn = {1097-0193},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.20064},
	doi = {10.1002/hbm.20064},
	shorttitle = {Cortical activity to vibrotactile stimulation},
	abstract = {Blind individuals show visual cortex activity during Braille reading. We examined whether such cross-modal activations reflect processing somatosensory stimuli independent of language by identifying cortical activity during a one-back vibrotactile matching task. Three groups (sighted, early-onset, and late-onset [{\textgreater}12 years] blind) detected whether paired vibrations (25 and 100 Hz), delivered to the right index finger, differed in frequency. Three successive paired vibrations, followed by a no-stimulation interval, were presented in a long event-related design. A fixed effects average z-score analysis showed increased activity throughout the visuotopic visual cortex, where it was mostly restricted to foveal and parafoveal eccentricities. Early blind showed the most extensive distribution of activity. Late blind exhibited activity mostly in similar regions but with declining response magnitudes with age of blindness onset. Three sighted individuals had suprathreshold activity in V1 but negative responses elsewhere in visual cortex. Mixed effects {ANOVA} confirmed group distinctions in defined regions (V1, V3, V4v, V7, {LOC}, and {MT}). These results suggest cross-modal adaptation to tactile stimulation in visual cortex independent of language processes. All groups showed increased activity in left primary (S1) and bilateral second somatosensory areas, but without response magnitude differences between groups throughout sensorimotor cortex. Early blind showed the greatest spatial extent of S1 activity. Blind participants had more extensive bilateral activity in anterior intraparietal sulcus and supramarginal gyrus. Extensive usage of touch in Braille reading may underlie observed S1 expansions in the reading finger representation. In addition, learned attentiveness to touch may explain similar expansion of parietal tactile attention regions. Hum. Brain Mapp. 23:210–228, 2004. © 2004 Wiley-Liss, Inc.},
	pages = {210--228},
	number = {4},
	journaltitle = {Human Brain Mapping},
	author = {Burton, Harold and Sinclair, Robert J. and {McLaren}, Donald G.},
	urldate = {2019-05-05},
	date = {2004},
	langid = {english},
	keywords = {human, blindness, magnetic resonance imaging, visual cortex/*physiology},
	file = {Accepted Version:/home/felix/Zotero/storage/RDHA6QSW/Burton et al. - 2004 - Cortical activity to vibrotactile stimulation An .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/8SZ4H5S2/hbm.html:text/html}
}

@article{goldreich_tactile_2003-2,
	title = {Tactile Acuity is Enhanced in Blindness},
	volume = {23},
	rights = {Copyright © 2003 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/23/8/3439},
	doi = {10.1523/JNEUROSCI.23-08-03439.2003},
	abstract = {Functional imaging studies in blind subjects have shown tactile activation of cortical areas that normally subserve vision, but whether blind people have enhanced tactile acuity has long been controversial. We compared the passive tactile acuity of blind and sighted subjects on a fully automated grating orientation task and used multivariate Bayesian data analysis to determine predictors of acuity. Acuity was significantly superior in blind subjects, independently of the degree of childhood vision, light perception level, or Braille reading. Acuity was strongly dependent on the force of contact between the stimulus surface and the skin, declined with subject age, and was better in women than in men. Despite large intragroup variability, the difference between blind and sighted subjects was highly significant: the average blind subject had the acuity of an average sighted subject of the same gender but 23 years younger. The results suggest that crossmodal plasticity may underlie tactile acuity enhancement in blindness.},
	pages = {3439--3445},
	number = {8},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Goldreich, Daniel and Kanics, Ingrid M.},
	urldate = {2019-05-05},
	date = {2003-04-15},
	langid = {english},
	pmid = {12716952},
	keywords = {crossmodal plasticity, blind, Braille, grating orientation, sensory compensation, somatosensory psychophysics, tactile acuity},
	file = {Full Text PDF:/home/felix/Zotero/storage/NJRUPQQD/Goldreich and Kanics - 2003 - Tactile Acuity is Enhanced in Blindness.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/HS5B9FVM/3439.html:text/html}
}

@article{ponsford_tactile_2000,
	title = {Tactile spatial resolution in blind Braille readers},
	volume = {55},
	rights = {© 2000},
	issn = {0028-3878, 1526-632X},
	url = {https://n.neurology.org/content/55/10/1597},
	doi = {10.1212/WNL.55.10.1597},
	abstract = {To the Editor:

Van Boven et al.1 are to be congratulated on their report on tactile spatial resolution in blind Braille readers. Like Horatio in Hamlet , they may be even more surprised, and intrigued, by the report of A. I. Lang–Stevenson2 regarding the “induction of hyperplasia and hypertrophy of Pacinian corpuscles” in a 60-year-old …},
	pages = {1597--1597},
	number = {10},
	journaltitle = {Neurology},
	author = {Ponsford, J. R.},
	urldate = {2019-05-05},
	date = {2000-11-28},
	langid = {english},
	pmid = {11094135},
	file = {Snapshot:/home/felix/Zotero/storage/8Y97MNSU/1597.html:text/html}
}

@article{muchnik_central_1991,
	title = {Central Auditory Skills in Blind and Sighted Subjects},
	volume = {20},
	issn = {0105-0397},
	url = {https://doi.org/10.3109/01050399109070785},
	doi = {10.3109/01050399109070785},
	abstract = {Three different central auditory skills were compared and evaluated in 56 blind and 40 sighted subjects. The study consisted of three experiments conducted in three subgroups. Experiment A was performed in order to evaluate the localization function; experiment B for the temporal auditory resolution ability of the blind adult, and experiment C to test the ability of the blind person to discriminate speech material in noise. In all three experiments the blind subjects obtained significantly better results than the sighted subjects. From these results it was concluded that there is supporting evidence of a certain superiority of the blind individual with regard to central auditory function.},
	pages = {19--23},
	number = {1},
	journaltitle = {Scandinavian Audiology},
	author = {Muchnik, Chava and Efrati, Michal and Nemeth, Esther and Malin, Michal and Hildesheimer, Minka},
	urldate = {2019-05-05},
	date = {1991-01-01},
	pmid = {1842264},
	keywords = {blindness, auditory perception, central auditory},
	file = {Snapshot:/home/felix/Zotero/storage/8CKFKZA8/01050399109070785.html:text/html}
}

@article{tonning_ability_1975,
	title = {Ability of the Blind to Localize Noise Practical Consequences},
	volume = {4},
	issn = {0105-0397},
	url = {https://doi.org/10.3109/01050397509043080},
	doi = {10.3109/01050397509043080},
	abstract = {The directional hearing ability of normal-hearing blind persons and persons with normal hearing and sight was examined in the horizontal plane for white noise in an anechoic room. No difference in localization ability between these two populations could be demonstrated. For blind persons, orientation may be facilitated by fixed, appropriate sound sources, the character of the sound being complex and presented as pulses. Normal-hearing persons are expected to benefit from this arrangement, and it may be of help also for persons with impaired hearing. These conclusions are valid for the patients as a population, and must not be taken as absolutely valid for the single individual.},
	pages = {183--186},
	number = {3},
	journaltitle = {Scandinavian Audiology},
	author = {Tonning, F.-M.},
	urldate = {2019-05-05},
	date = {1975-01-01},
	file = {Snapshot:/home/felix/Zotero/storage/TB65XZBB/01050397509043080.html:text/html}
}

@article{collignon_cross-modal_2008,
	title = {Cross-modal plasticity for the spatial processing of sounds in visually deprived subjects},
	volume = {192},
	issn = {1432-1106},
	url = {https://doi.org/10.1007/s00221-008-1553-z},
	doi = {10.1007/s00221-008-1553-z},
	abstract = {Until only a few decades ago, researchers still considered sensory cortices to be fixed or “hardwired,” with specific cortical regions solely dedicated to the processing of selective sensory inputs. But recent evidences have shown that the brain can rewire itself, showing an impressive range of cross-modal plasticity. Visual deprivation is one of the rare human models that allow us to explore the role of experience-dependent plasticity of a sensory cortex deprived of its natural inputs. The objective of this paper is to describe recent results regarding the spatial processing of sounds in blind subjects. These studies suggest that blind individuals may demonstrate exceptional abilities in auditory spatial processing and that such enhanced performances may be intrinsically linked to the recruitment of occipital areas deprived of their normal visual inputs. Such results highlight the brain’s remarkable ability to rewire its components to compensate for the challenging neurological condition that is visual deprivation. Moreover, we shall discuss that such cross-modal recruitment may, to some extent, follow organizational principles similar to the functional topography of the region observed in the sighted. Even if such recruitment is especially present in individuals having lost their sight in early infancy, occipital regions also show impressive plastic properties when vision is lost at a later age. This observation will be related to recent results demonstrating that occipital regions play a more important role than previously expected in the spatial processing of sounds, even in sighted subjects. Putative physiological mechanisms underlying such cross-modal recruitment will then be discussed. All these results have important implications for understanding the role of visual experience in shaping the development of occipital regions and may guide the implementation of rehabilitative methods such as sensory substitution or neural implants.},
	pages = {343},
	number = {3},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Collignon, Olivier and Voss, Patrice and Lassonde, Maryse and Lepore, Franco},
	urldate = {2019-05-05},
	date = {2008-09-02},
	langid = {english},
	keywords = {Plasticity, Cross-modal, Auditory, Blindness, Spatial},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/86I8GRJS/Collignon et al. - 2008 - Cross-modal plasticity for the spatial processing .pdf:application/pdf}
}

@article{voss_early-_2004,
	title = {Early- and Late-Onset Blind Individuals Show Supra-Normal Auditory Abilities in Far-Space},
	volume = {14},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S096098220400747X},
	doi = {10.1016/j.cub.2004.09.051},
	abstract = {Blind individuals manifest remarkable abilities in navigating through space despite their lack of vision. They have previously been shown to perform normally or even supra-normally in tasks involving spatial hearing in near space 1, 2, a region that, however, can be calibrated with sensory-motor feedback. Here we show that blind individuals not only properly map auditory space beyond their peri-personal environment but also demonstrate supra-normal performance when subtle acoustic cues for target location and distance must be used to carry out the task. Moreover, it is generally postulated that such abilities rest in part on cross-modal cortical reorganizations 3, 4, 5, 6, particularly in the immature brain, where important synaptogenesis is still possible 7, 8, 9. Nonetheless, we show for the first time that even late-onset blind subjects develop above-normal spatial abilities, suggesting that significant compensation can occur in the adult.},
	pages = {1734--1738},
	number = {19},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Voss, Patrice and Lassonde, Maryse and Gougoux, Frederic and Fortin, Madeleine and Guillemot, Jean-Paul and Lepore, Franco},
	urldate = {2019-05-05},
	date = {2004-10-05},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/YUV4N8UP/Voss et al. - 2004 - Early- and Late-Onset Blind Individuals Show Supra.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/ZMPPHR9V/S096098220400747X.html:text/html}
}

@article{bross_temporal_1982,
	title = {Temporal Auditory Acuity in Blind and Sighted Subjects: A Signal Detection Analysis},
	volume = {55},
	issn = {0031-5125},
	url = {https://doi.org/10.2466/pms.1982.55.3.963},
	doi = {10.2466/pms.1982.55.3.963},
	shorttitle = {Temporal Auditory Acuity in Blind and Sighted Subjects},
	abstract = {Temporal auditory sensitivity was compared in five adventitiously blind and five normally sighted subjects in a signal-detection paradigm. Following determination of individual auditory flutter fusion ({AFF}) thresholds the subjects were required to make forced-choice responses between a fluttering and fused white noise under stimulus probabilities of 0.25, 0.50, and 0.75. From these data indices of sensory sensitivity (d') and response bias (Beta) were computed and compared. Analysis indicated no significant differences in auditory sensitivity between the two groups. These findings further weaken the traditional hypothesis of sensory compensation.},
	pages = {963--966},
	number = {3},
	journaltitle = {Perceptual and Motor Skills},
	shortjournal = {Percept Mot Skills},
	author = {Bross, Michael and Borenstein, Myra},
	urldate = {2019-05-05},
	date = {1982-12-01},
	langid = {english},
	file = {SAGE PDF Full Text:/home/felix/Zotero/storage/KU2FJIK6/Bross and Borenstein - 1982 - Temporal Auditory Acuity in Blind and Sighted Subj.pdf:application/pdf}
}

@article{lessard_early-blind_1998,
	title = {Early-blind human subjects localize sound sources better than sighted subjects},
	volume = {395},
	rights = {1998 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/26228},
	doi = {10.1038/26228},
	abstract = {Do blind persons develop capacities of their remaining senses that exceed those of sighted individuals? Besides anecdotal suggestions, two views based on experimental studies have been advanced1. The first proposes that blind individuals should be severely impaired, given that vision is essential to develop spatial concepts2. The second suggests that compensation occurs through the remaining senses, allowing them to develop an accurate concept of space3. Here we investigate how an ecologically critical function, namely three-dimensional spatial mapping, is carried out by early-blind individuals with or without residual vision. Subjects were tested under monaural and binaural listening conditions. We find that early-blind subjects can map the auditory environment with equal or better accuracy than sighted subjects. Furthermore, unlike sighted subjects, they can correctly localize sounds monaurally. Surprisingly, blind individuals with residual peripheral vision localized sounds less precisely than sighted or totally blind subjects, confirming that compensation varies according to the aetiology and extent of blindness4. Our results resolve a long-standing controversy in that they provide behavioural evidence that totally blind individuals have better auditory ability than sighted subjects, enabling them to compensate for their loss of vision.},
	pages = {278},
	number = {6699},
	journaltitle = {Nature},
	author = {Lessard, N. and Paré, M. and Lepore, F. and Lassonde, M.},
	urldate = {2019-05-05},
	date = {1998-09},
	file = {Snapshot:/home/felix/Zotero/storage/NTZKWGXB/26228.html:text/html}
}

@article{gougoux_pitch_2004,
	title = {Pitch discrimination in the early blind},
	volume = {430},
	rights = {2004 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/430309a},
	doi = {10.1038/430309a},
	abstract = {People blinded in infancy have sharper listening skills than those who lost their sight later.},
	pages = {309},
	number = {6997},
	journaltitle = {Nature},
	author = {Gougoux, Frédéric and Lepore, Franco and Lassonde, Maryse and Voss, Patrice and Zatorre, Robert J. and Belin, Pascal},
	urldate = {2019-05-05},
	date = {2004-07},
	file = {Snapshot:/home/felix/Zotero/storage/CYR4EMXF/430309a.html:text/html}
}

@article{wong_tactile_2011-1,
	title = {Tactile Spatial Acuity Enhancement in Blindness: Evidence for Experience-Dependent Mechanisms},
	volume = {31},
	rights = {Copyright © 2011 the authors 0270-6474/11/317028-10\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/31/19/7028},
	doi = {10.1523/JNEUROSCI.6461-10.2011},
	shorttitle = {Tactile Spatial Acuity Enhancement in Blindness},
	abstract = {Tactile spatial acuity is enhanced in blindness, according to several studies, but the cause of this enhancement has been controversial. Two competing hypotheses are the tactile experience hypothesis (reliance on the sense of touch drives tactile-acuity enhancement) and the visual deprivation hypothesis (the absence of vision itself drives tactile-acuity enhancement). Here, we performed experiments to distinguish between these two hypotheses. We used force-controlled grating orientation tasks to compare the passive (finger stationary) tactile spatial acuity of 28 profoundly blind and 55 normally sighted humans on the index, middle, and ring fingers of each hand, and on the lips. The tactile experience hypothesis predicted that blind participants would outperform the sighted on the fingers, and that Braille reading would correlate with tactile acuity. The visual deprivation hypothesis predicted that blind participants would outperform the sighted on fingers and lips. Consistent with the tactile experience hypothesis, the blind significantly outperformed the sighted on all fingers, but not on the lips. Additionally, among blind participants, proficient Braille readers on their preferred reading index finger outperformed nonreaders. Finally, proficient Braille readers performed better with their preferred reading index finger than with the opposite index finger, and their acuity on the preferred reading finger correlated with their weekly reading time. These results clearly implicate reliance on the sense of touch as the trigger for tactile spatial acuity enhancement in the blind, and suggest the action of underlying experience-dependent neural mechanisms such as somatosensory and/or cross-modal cortical plasticity.},
	pages = {7028--7037},
	number = {19},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Wong, Michael and Gnanakumaran, Vishi and Goldreich, Daniel},
	urldate = {2019-05-05},
	date = {2011-05-11},
	langid = {english},
	pmid = {21562264},
	file = {Full Text PDF:/home/felix/Zotero/storage/JEHJ2IWZ/Wong et al. - 2011 - Tactile Spatial Acuity Enhancement in Blindness E.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/V92KV9D5/7028.html:text/html}
}

@article{voss_organization_2012,
	title = {Organization and Reorganization of Sensory-Deprived Cortex},
	volume = {22},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982212000607},
	doi = {10.1016/j.cub.2012.01.030},
	abstract = {The scientific literature has grown rich in research illustrating the remarkable ability of the brain to reorganize itself following sensory loss. In particular, visually deafferented regions within the occipital cortex of early blind individuals have been repeatedly shown to be functionally recruited to carry out a wide variety of nonvisual tasks. While the novelty of such a finding might be wearing off, more recent research has begun to examine whether this crossmodal takeover of the occipital cortex in blindness follows some sort of organizational principle. Here we first review the most recent evidence from neuroimaging studies that illustrate how the pre-existing functional specialization of cortical sub-regions appears to be preserved following sensory deprivation. We discuss and compare work on visual and auditory deprivation, as well as research on individuals with intact sensory systems. We suggest avenues for future exploration of these issues, such as identifying the neuroanatomical markers of crossmodal plasticity and elucidating the behavioral relevance of observed changes.},
	pages = {R168--R173},
	number = {5},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Voss, Patrice and Zatorre, Robert J.},
	urldate = {2019-05-06},
	date = {2012-03-06},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/M2LQTW9T/Voss and Zatorre - 2012 - Organization and Reorganization of Sensory-Deprive.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/SGHTJIEY/S0960982212000607.html:text/html}
}

@article{niemeyer_blind_1981,
	title = {Do the Blind Hear Better? Investigations on Auditory Processing in Congenital or Early Acquired Blindness {II}. Central Functions},
	volume = {20},
	issn = {0020-6091},
	url = {https://www.tandfonline.com/doi/abs/10.3109/00206098109072719},
	doi = {10.3109/00206098109072719},
	shorttitle = {Do the Blind Hear Better?},
	abstract = {The same 18 normally hearing students and 18 matched normal-sighted students, as in part I of this study, were compared in regard to pure-tone integration, speech discrimination ability and late cortical-evoked potentials. The blind subjects showed increased disinhibition (‘cleaning’) with broad-band noise and a decreased inhibition with the same stimulus at the contralateral ear, better speech discrimination, especially with regard to sentence tests without and with competing environment-simulating noise, and, by electric response audiometry ({ERA}), a shortened N, latency. Thus, the hypothesis of a better utilization of auditory information after the loss of the visual information channel could be confirmed, and may be ascribed to the plasticity of the central nervous system.Dans cette 2e partie de notre étude, nous avons examiné la fonction auditive centrale des měmes sujets que précédemment à l'aide des tests suivants: intégration binaurale du son pur; intelligibilité vocale monaurale à l'aide de chiffres binaires et de substantifs monosylla-biques et binaurale, d'une part et, d'autre part, à l'aide de phrases prononcées en présence ou en l'absence d'un bruit ambiant de 50 {dB} (A); latence et amplitude de N1/P2 des potentiels évoqués tardifs corticaux. Le groupe des aveugles présente: une plus faible inhibition de δl par un son de měme fréquence à l'oreille controlatérale; une meilleure activation de δI par un bruit à bande large, mais les résultats restent à la limite de la signification statistique; une bien meilleure discrimination de la parole à tous les niveaux, et surtout en présence de bruit en audition binaurale et, en {ERA}, une diminution significative de la latence de N1, sans modification de l'amplitude de N1/P2. Une conclusion définitive ne peut pas ětre formulée pour le moment, toutefois, ces résultats semblent confirmer l'hypothèse de l'existence, à la suite d'une cécité prolongée, d'une meilleure utilisation de l'information auditive graˇce à la plasticité du système nerveux central.},
	pages = {510--515},
	number = {6},
	journaltitle = {Audiology},
	author = {Niemeyer, W. and Starlinger, I.},
	urldate = {2019-05-06},
	date = {1981-01-01},
	keywords = {Blind, Chocholle's test, {ERA}, Plasticity of the brain, Sentence discrimination in noise, Speech audiometry},
	file = {Snapshot:/home/felix/Zotero/storage/48HIQM3V/00206098109072719.html:text/html}
}

@article{collignon_further_2009-1,
	title = {Further evidence that congenitally blind participants react faster to auditory and tactile spatial targets.},
	volume = {63},
	issn = {1878-7290, 1196-1961},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0015415},
	doi = {10.1037/a0015415},
	abstract = {Congenital blindness is one of the rare human models to explore the role of experience-driven cross-modal compensation after early sensory deprivation. We re-examined spatial attention abilities in congenitally blind participants and sighted controls using a paradigm comparable to the one of our previous study (Collignon, Renier, Bruyer, Tranduy, \& Veraart, 2006), except that this time the auditory and tactile stimuli were now presented in sequence. Although both groups performed the task with similar accuracy, we observed that blind participants had shorter reaction times than sighted controls for the detection of spatial targets in both sensory modalities. Moreover, this finding held true for both the selective and divided attention conditions. These results not only confirm previous reports on the superiority of the blind during auditory and tactile attention tasks, but also broaden our knowledge of the mechanisms underlying cross-modal compensation.},
	pages = {287--293},
	number = {4},
	journaltitle = {Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale},
	author = {Collignon, Olivier and De Volder, Anne G.},
	urldate = {2019-05-06},
	date = {2009},
	langid = {english},
	file = {Collignon and De Volder - 2009 - Further evidence that congenitally blind participa.pdf:/home/felix/Zotero/storage/D6BVAJPG/Collignon and De Volder - 2009 - Further evidence that congenitally blind participa.pdf:application/pdf}
}

@article{ponsford_tactile_2000-1,
	title = {Tactile spatial resolution in blind Braille readers},
	volume = {55},
	rights = {© 2000},
	issn = {0028-3878, 1526-632X},
	url = {https://n.neurology.org/content/55/10/1597},
	doi = {10.1212/WNL.55.10.1597},
	abstract = {To the Editor:

Van Boven et al.1 are to be congratulated on their report on tactile spatial resolution in blind Braille readers. Like Horatio in Hamlet , they may be even more surprised, and intrigued, by the report of A. I. Lang–Stevenson2 regarding the “induction of hyperplasia and hypertrophy of Pacinian corpuscles” in a 60-year-old …},
	pages = {1597--1597},
	number = {10},
	journaltitle = {Neurology},
	author = {Ponsford, J. R.},
	urldate = {2019-05-06},
	date = {2000-11-28},
	langid = {english},
	pmid = {11094135},
	file = {Snapshot:/home/felix/Zotero/storage/Y63K75RI/1597.html:text/html}
}

@article{boven_tactile_2000,
	title = {Tactile spatial resolution in blind Braille readers},
	volume = {54},
	url = {http://n.neurology.org/content/54/12/2230.abstract},
	doi = {10.1212/WNL.54.12.2230},
	abstract = {Objective: To determine if blind people have heightened tactile spatial acuity. Background: Recently, studies using magnetic source imaging and somatosensory evoked potentials have shown that the cortical representation of the reading fingers of blind Braille readers is expanded compared to that of fingers of sighted subjects. Furthermore, the visual cortex is activated during certain tactile tasks in blind subjects but not sighted subjects. The authors hypothesized that the expanded cortical representation of fingers used in Braille reading may reflect an enhanced fidelity in the neural transmission of spatial details of a stimulus. If so, the quantitative limit of spatial acuity would be superior in blind people. Methods: The authors employed a grating orientation discrimination task in which threshold performance is accounted for by the spatial resolution limits of the neural image evoked by a stimulus. The authors quantified the psychophysical limits of spatial acuity at the middle and index fingers of 15 blind Braille readers and 15 sighted control subjects. Results: The mean grating orientation threshold was significantly (p = 0.03) lower in the blind group (1.04 mm) compared to the sighted group (1.46 mm). The self-reported dominant reading finger in blind subjects had a mean grating orientation threshold of 0.80 mm, which was significantly better than other fingers tested. Thresholds at non-Braille reading fingers in blind subjects averaged 1.12 mm, which were also superior to sighted subjects’ performances. Conclusion: Superior tactile spatial acuity in blind Braille readers may represent an adaptive, behavioral correlate of cortical plasticity.},
	pages = {2230},
	number = {12},
	journaltitle = {Neurology},
	shortjournal = {Neurology},
	author = {Boven, R.W. Van and Hamilton, R.H. and Kauffman, T. and Keenan, J.P. and Pascual–Leone, A.},
	date = {2000-06-27}
}

@article{grant_tactile_2000,
	title = {Tactile perception in blind Braille readers: A psychophysical study of acuity and hyperacuity using gratings and dot patterns},
	volume = {62},
	issn = {1532-5962},
	url = {https://doi.org/10.3758/BF03205550},
	doi = {10.3758/BF03205550},
	shorttitle = {Tactile perception in blind Braille readers},
	abstract = {It is not clear whether the blind are generally superior to the sighted on measures of tactile sensitivity or whether they excel only on certain tests owing to the specifics of their tactile experience. We compared the discrimination performance of blind Braille readers and age-matched sighted subjects on three tactile tasks using precisely specified stimuli. Initially, the blind significantly outperformed the sighted at a hyperacuity task using Braille-like dot patterns, although, with practice, both groups performed equally well. On two other tasks, hyperacute discrimination of gratings that differed in ridge width and spatial-acuity-dependent discrimination of grating orientation, the performance of the blind did not differ significantly from that of sighted subjects. These results probably reflect the specificity of perceptual learning due to Braille-reading experience.},
	pages = {301--312},
	number = {2},
	journaltitle = {Perception \& Psychophysics},
	shortjournal = {Perception \& Psychophysics},
	author = {Grant, Arthur C. and Thiagarajah, Mahesh C. and Sathian, K.},
	urldate = {2019-05-06},
	date = {2000-01-01},
	langid = {english},
	keywords = {Blind Subject, Dominant Hand, Groove Width, Perceptual Learning, Tactile Perception},
	file = {Springer Full Text PDF:/home/felix/Zotero/storage/MMUWWEBQ/Grant et al. - 2000 - Tactile perception in blind Braille readers A psy.pdf:application/pdf}
}

@article{heimler_revisiting_2014,
	title = {Revisiting the adaptive and maladaptive effects of crossmodal plasticity},
	volume = {283},
	issn = {0306-4522},
	url = {http://www.sciencedirect.com/science/article/pii/S0306452214006435},
	doi = {10.1016/j.neuroscience.2014.08.003},
	series = {Compensation Following Injury to the Adult Brain: Always for Good?},
	abstract = {One of the most striking demonstrations of experience-dependent plasticity comes from studies of sensory-deprived individuals (e.g., blind or deaf), showing that brain regions deprived of their natural inputs change their sensory tuning to support the processing of inputs coming from the spared senses. These mechanisms of crossmodal plasticity have been traditionally conceptualized as having a double-edged sword effect on behavior. On one side, crossmodal plasticity is conceived as adaptive for the development of enhanced behavioral skills in the remaining senses of early-deaf or blind individuals. On the other side, crossmodal plasticity raises crucial challenges for sensory restoration and is typically conceived as maladaptive since its presence may prevent optimal recovery in sensory-re-afferented individuals. In the present review we stress that this dichotomic vision is oversimplified and we emphasize that the notions of the unavoidable adaptive/maladaptive effects of crossmodal reorganization for sensory compensation/restoration may actually be misleading. For this purpose we critically review the findings from the blind and deaf literatures, highlighting the complementary nature of these two fields of research. The integrated framework we propose here has the potential to impact on the way rehabilitation programs for sensory recovery are carried out, with the promising prospect of eventually improving their final outcomes.},
	pages = {44--63},
	journaltitle = {Neuroscience},
	shortjournal = {Neuroscience},
	author = {Heimler, B. and Weisz, N. and Collignon, O.},
	urldate = {2019-05-06},
	date = {2014-12-26},
	keywords = {crossmodal plasticity, blindness, adaptive, behavior, deafness, maladaptive},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/AU77CNE8/Heimler et al. - 2014 - Revisiting the adaptive and maladaptive effects of.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/QEJRPTDJ/S0306452214006435.html:text/html}
}

@article{bavelier_deaf_2006-1,
	title = {Do deaf individuals see better?},
	volume = {10},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661306002439},
	doi = {10.1016/j.tics.2006.09.006},
	abstract = {The possibility that, following early auditory deprivation, the remaining senses such as vision are enhanced has been met with much excitement. However, deaf individuals exhibit both better and worse visual skills than hearing controls. We show that, when deafness is considered to the exclusion of other confounds, enhancements in visual cognition are noted. The changes are not, however, widespread but are selective, limited, as we propose, to those aspects of vision that are attentionally demanding and would normally benefit from auditory–visual convergence. The behavioral changes are accompanied by a reorganization of multisensory areas, ranging from higher-order cortex to early cortical areas, highlighting cross-modal interactions as a fundamental feature of brain organization and cognitive processing.},
	pages = {512--518},
	number = {11},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Bavelier, Daphne and Dye, Matthew W. G. and Hauser, Peter C.},
	urldate = {2019-05-06},
	date = {2006-11-01},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/NY8ZKK2B/Bavelier et al. - 2006 - Do deaf individuals see better.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/PB79DE3W/S1364661306002439.html:text/html}
}

@article{bavelier_visual_2000-1,
	title = {Visual attention to the periphery is enhanced in congenitally deaf individuals},
	volume = {20},
	issn = {0270-6474},
	url = {https://archive-ouverte.unige.ch/unige:103930},
	abstract = {We compared normally hearing individuals and congenitally deaf individuals as they monitored moving stimuli either in the periphery or in the center of the visual field. When participants monitored the peripheral visual field, greater recruitment (as measured by functional magnetic resonance imaging) of the motion-selective area {MT}/{MST} was observed in deaf than in hearing individuals, whereas the two groups were comparable when attending to the central visual field. This finding indicates an enhancement of visual attention to peripheral visual space in deaf individuals. Structural equation modeling was used to further characterize the nature of this plastic change in the deaf. The effective connectivity between {MT}/{MST} and the posterior parietal cortex was stronger in deaf than in hearing individuals during peripheral but not central attention. Thus, enhanced peripheral attention to moving stimuli in the deaf may be mediated by alterations of the connectivity between {MT}/{MST} and the parietal cortex, one of the primary centers for spatial representation and attention.},
	pages = {RC931--6},
	number = {17},
	journaltitle = {Journal of Neuroscience},
	author = {Bavelier, D. and  Tomann, Andrea and Hutton, C. and Mitchell, Teresa and Corina, D. and Liu, Guoying and Neville, Helen},
	urldate = {2019-05-06},
	date = {2000},
	file = {Full Text PDF:/home/felix/Zotero/storage/NRGD9VSP/Bavelier et al. - 2000 - Visual attention to the periphery is enhanced in c.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/JV3GQ9W4/unige103930.html:text/html}
}

@article{proksch_changes_2002,
	title = {Changes in the Spatial Distribution of Visual Attention after Early Deafness},
	volume = {14},
	issn = {0898-929X},
	url = {https://doi.org/10.1162/08989290260138591},
	doi = {10.1162/08989290260138591},
	abstract = {There is much anecdotal suggestion of improved visual skills in congenitally deaf individuals. However, this claim has only been met by mixed results from careful investigations of visual skills in deaf individuals. Psychophysical assessments of visual functions have failed, for the most part, to validate the view of enhanced visual skills after deafness. Only a few studies have shown an advantage for deaf individuals in visual tasks. Interestingly, all of these studies share the requirement that participants process visual information in their peripheral visual field under demanding conditions of attention. This work has led us to propose that congenital auditory deprivation alters the gradient of visual attention from central to peripheral field by enhancing peripheral processing. This hypothesis was tested by adapting a search task from Lavie and colleagues in which the interference from distracting information on the search task provides a measure of attentional resources. These authors have established that during an easy central search for a target, any surplus attention remaining will involuntarily process a peripheral distractor that the subject has been instructed to ignore. Attentional resources can be measured by adjusting the difficulty of the search task to the point at which no surplus resources are available for the distractor. Through modification of this paradigm, central and peripheral attentional resources were compared in deaf and hearing individuals. Deaf individuals possessed greater attentional resources in the periphery but less in the center when compared to hearing individuals. Furthermore, based on results from native hearing signers, it was shown that sign language alone could not be responsible for these changes. We conclude that auditory deprivation from birth leads to compensatory changes within the visual system that enhance attentional processing of the peripheral visual field.},
	pages = {687--701},
	number = {5},
	journaltitle = {Journal of Cognitive Neuroscience},
	shortjournal = {Journal of Cognitive Neuroscience},
	author = {Proksch, Jason and Bavelier, Daphne},
	urldate = {2019-05-06},
	date = {2002-07-01},
	file = {Full Text:/home/felix/Zotero/storage/6T4SDPCT/Proksch and Bavelier - 2002 - Changes in the Spatial Distribution of Visual Atte.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/I26Z4XU8/08989290260138591.html:text/html}
}

@article{bosworth_effects_2002,
	title = {The Effects of Spatial Attention on Motion Processing in Deaf Signers, Hearing Signers, and Hearing Nonsigners},
	volume = {49},
	issn = {0278-2626},
	url = {http://www.sciencedirect.com/science/article/pii/S0278262601914976},
	doi = {10.1006/brcg.2001.1497},
	abstract = {Visual abilities in deaf individuals may be altered as a result of auditory deprivation and/or because the deaf rely heavily on a sign language (American Sign Language, or {ASL}). In this study, we asked whether attentional abilities of deaf subjects are altered. Using a direction of motion discrimination task in the periphery, we investigated three aspects of spatial attention: orienting of attention, divided attention, and selective attention. To separate influences of auditory deprivation and sign language experience, we compared three subject groups: deaf and hearing native signers of {ASL} and hearing nonsigners. To investigate the ability to orient attention, we compared motion thresholds obtained with and without a valid spatial precue, with the notion that subjects orient to the stimulus prior to its appearance when a precue is presented. Results suggest a slight advantage for deaf subjects in the ability to orient spatial attention. To investigate divided attention, we compared motion thresholds obtained when a single motion target was presented to thresholds obtained when the motion target was presented among confusable distractors. The effect of adding distractors was found to be identical across subject groups, suggesting that attentional capacity is not altered in deaf subjects. Finally, to investigate selective attention, we compared performance for a single, cued motion target with that of a cued motion target presented among distractors. Here, deaf, but not hearing, subjects performed better when the motion target was presented among distractors than when it was presented alone, suggesting that deaf subjects are more affected by the presence of distractors. In sum, our results suggest that attentional orienting and selective attention are altered in the deaf and that these effects are most likely due to auditory deprivation as opposed to sign language experience.},
	pages = {152--169},
	number = {1},
	journaltitle = {Brain and Cognition},
	shortjournal = {Brain and Cognition},
	author = {Bosworth, Rain G. and Dobkins, Karen R.},
	urldate = {2019-05-06},
	date = {2002-06-01},
	keywords = {Key Words: deaf, motion perception, sign language, visual attention},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/7H3TC5YY/Bosworth and Dobkins - 2002 - The Effects of Spatial Attention on Motion Process.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/HM377L32/S0278262601914976.html:text/html}
}

@article{nishimura_sign_1999,
	title = {Sign language ‘heard’ in the auditory cortex},
	volume = {397},
	rights = {1999 Macmillan Magazines Ltd.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/16376},
	doi = {10.1038/16376},
	abstract = {The upper regions of the brain's temporal lobe are important both for hearing and for comprehending spoken language. We have discovered that these regions can be activated by sign language in congenitally deaf subjects, even though the temporal lobe normally functions as an auditory area. This finding indicates that, in deaf people, the brain region usually reserved for hearing may be activated by other sensory modalities, providing striking evidence of neural plasticity.},
	pages = {116},
	number = {6715},
	journaltitle = {Nature},
	author = {Nishimura, Hiroshi and Hashikawa, Kazuo and Doi, Katsumi and Iwaki, Takako and Watanabe, Yoshiyuki and Kusuoka, Hideo and Nishimura, Tsunehiko and Kubo, Takeshi},
	urldate = {2019-05-06},
	date = {1999-01},
	file = {Snapshot:/home/felix/Zotero/storage/3PMDIRHH/16376.html:text/html}
}

@article{petitto_speech-like_2000,
	title = {Speech-like cerebral activity in profoundly deaf people processing signed languages: Implications for the neural basis of human language},
	volume = {97},
	rights = {Copyright © 2000, The National Academy of Sciences},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/97/25/13961},
	doi = {10.1073/pnas.97.25.13961},
	shorttitle = {Speech-like cerebral activity in profoundly deaf people processing signed languages},
	abstract = {For more than a century we have understood that our brain's left hemisphere is the primary site for processing language, yet why this is so has remained more elusive. Using positron emission tomography, we report cerebral blood flow activity in profoundly deaf signers processing specific aspects of sign language in key brain sites widely assumed to be unimodal speech or sound processing areas: the left inferior frontal cortex when signers produced meaningful signs, and the planum temporale bilaterally when they viewed signs or meaningless parts of signs (sign-phonetic and syllabic units). Contrary to prevailing wisdom, the planum temporale may not be exclusively dedicated to processing speech sounds, but may be specialized for processing more abstract properties essential to language that can engage multiple modalities. We hypothesize that the neural tissue involved in language processing may not be prespecified exclusively by sensory modality (such as sound) but may entail polymodal neural tissue that has evolved unique sensitivity to aspects of the patterning of natural language. Such neural specialization for aspects of language patterning appears to be neurally unmodifiable in so far as languages with radically different sensory modalities such as speech and sign are processed at similar brain sites, while, at the same time, the neural pathways for expressing and perceiving natural language appear to be neurally highly modifiable.},
	pages = {13961--13966},
	number = {25},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Petitto, Laura Ann and Zatorre, Robert J. and Gauna, Kristine and Nikelski, E. J. and Dostie, Deanna and Evans, Alan C.},
	urldate = {2019-05-06},
	date = {2000-12-05},
	langid = {english},
	pmid = {11106400},
	file = {Full Text PDF:/home/felix/Zotero/storage/JELNMUPN/Petitto et al. - 2000 - Speech-like cerebral activity in profoundly deaf p.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/FFANA44Q/13961.html:text/html}
}

@article{finney_visual_2003,
	title = {Visual stimuli activate auditory cortex in deaf subjects: evidence from {MEG}:},
	volume = {14},
	issn = {0959-4965},
	url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00001756-200308060-00004},
	doi = {10.1097/00001756-200308060-00004},
	shorttitle = {Visual stimuli activate auditory cortex in deaf subjects},
	pages = {1425--1427},
	number = {11},
	journaltitle = {{NeuroReport}},
	author = {Finney, Eva M. and Clementz, Brett A. and Hickok, Gregory and Dobkins, Karen R.},
	urldate = {2019-05-06},
	date = {2003-08},
	langid = {english},
	file = {Finney et al. - 2003 - Visual stimuli activate auditory cortex in deaf su.pdf:/home/felix/Zotero/storage/5Z23RCYK/Finney et al. - 2003 - Visual stimuli activate auditory cortex in deaf su.pdf:application/pdf}
}

@article{finney_visual_2001,
	title = {Visual stimuli activate auditory cortex in the deaf},
	volume = {4},
	rights = {2001 Nature Publishing Group},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn763},
	doi = {10.1038/nn763},
	abstract = {Previous brain imaging studies have demonstrated responses to tactile and auditory stimuli in visual cortex of blind subjects, suggesting that removal of one sensory modality leads to neural reorganization of the remaining modalities1,2,3. To investigate whether similar 'cross-modal' plasticity occurs in human auditory cortex, we used functional magnetic resonance imaging ({fMRI}) to measure visually evoked activity in auditory areas of both early-deafened and hearing individuals. Here we find that deaf subjects exhibit activation in a region of the right auditory cortex, corresponding to Brodmann's areas 42 and 22, as well as in area 41 (primary auditory cortex), demonstrating that early deafness results in the processing of visual stimuli in auditory cortex.},
	pages = {1171},
	number = {12},
	journaltitle = {Nature Neuroscience},
	author = {Finney, Eva M. and Fine, Ione and Dobkins, Karen R.},
	urldate = {2019-05-06},
	date = {2001-12},
	file = {Snapshot:/home/felix/Zotero/storage/ZGTU4ZJC/nn763.html:text/html}
}

@article{sadato_cross-modal_2005,
	title = {Cross-modal integration and plastic changes revealed by lip movement, random-dot motion and sign languages in the hearing and deaf},
	volume = {15},
	issn = {1047-3211},
	url = {https://academic.oup.com/cercor/article/15/8/1113/304603},
	doi = {10.1093/cercor/bhh210},
	abstract = {Abstract.  Sign language activates the auditory cortex of deaf subjects, which is evidence of cross-modal plasticity. Lip-reading (visual phonetics), which invo},
	pages = {1113--1122},
	number = {8},
	journaltitle = {Cerebral Cortex},
	shortjournal = {Cereb Cortex},
	author = {Sadato, Norihiro and Okada, Tomohisa and Honda, Manabu and Matsuki, Ken-Ichi and Yoshida, Masaki and Kashikura, Ken-Ichi and Takei, Wataru and Sato, Tetsuhiro and Kochiyama, Takanori and Yonekura, Yoshiharu},
	urldate = {2019-05-06},
	date = {2005-08-01},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/GL2C2IMM/Sadato et al. - 2005 - Cross-modal integration and plastic changes reveal.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/F7BG5FKQ/304603.html:text/html}
}

@article{hauthal_visual_2013,
	title = {Visual movement perception in deaf and hearing individuals},
	volume = {9},
	issn = {1895-1171},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3699779/},
	doi = {10.2478/v10053-008-0131-z},
	abstract = {A number of studies have investigated changes in the perception of visual motion
as a result of altered sensory experiences. An animal study has shown that
auditory-deprived cats exhibit enhanced performance in a visual movement
detection task compared to hearing cats (). In humans, the behavioural evidence
regarding the perception of motion is less clear. The present study investigated
deaf and hearing adult participants using a movement localization task and a
direction of motion task employing coherently-moving and static visual dot
patterns. Overall, deaf and hearing participants did not differ in their
movement localization performance, although within the deaf group, a left visual
field advantage was found. When discriminating the direction of motion, however,
deaf participants responded faster and tended to be more accurate when detecting
small differences in direction compared with the hearing controls. These results
conform to the view that visual abilities are enhanced after auditory
deprivation and extend previous findings regarding visual motion processing in
deaf individuals.},
	pages = {53--61},
	number = {2},
	journaltitle = {Advances in Cognitive Psychology},
	shortjournal = {Adv Cogn Psychol},
	author = {Hauthal, Nadine and Sandmann, Pascale and Debener, Stefan and Thorne, Jeremy D.},
	urldate = {2019-05-06},
	date = {2013-06-17},
	pmid = {23826037},
	pmcid = {PMC3699779},
	file = {PubMed Central Full Text PDF:/home/felix/Zotero/storage/96BWNKW6/Hauthal et al. - 2013 - Visual movement perception in deaf and hearing ind.pdf:application/pdf}
}

@article{shiell_enhancement_2014-1,
	title = {Enhancement of Visual Motion Detection Thresholds in Early Deaf People},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0090498},
	doi = {10.1371/journal.pone.0090498},
	abstract = {In deaf people, the auditory cortex can reorganize to support visual motion processing. Although this cross-modal reorganization has long been thought to subserve enhanced visual abilities, previous research has been unsuccessful at identifying behavioural enhancements specific to motion processing. Recently, research with congenitally deaf cats has uncovered an enhancement for visual motion detection. Our goal was to test for a similar difference between deaf and hearing people. We tested 16 early and profoundly deaf participants and 20 hearing controls. Participants completed a visual motion detection task, in which they were asked to determine which of two sinusoidal gratings was moving. The speed of the moving grating varied according to an adaptive staircase procedure, allowing us to determine the lowest speed necessary for participants to detect motion. Consistent with previous research in deaf cats, the deaf group had lower motion detection thresholds than the hearing. This finding supports the proposal that cross-modal reorganization after sensory deprivation will occur for supramodal sensory features and preserve the output functions.},
	pages = {e90498},
	number = {2},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Shiell, Martha M. and Champoux, François and Zatorre, Robert J.},
	urldate = {2019-05-06},
	date = {2014-02-28},
	langid = {english},
	keywords = {Vision, Deafness, Hearing disorders, Language, Behavior, Cats, Motion, Velocity},
	file = {Full Text PDF:/home/felix/Zotero/storage/78ZRQGBG/Shiell et al. - 2014 - Enhancement of Visual Motion Detection Thresholds .pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/ZNBSUFHM/article.html:text/html}
}

@article{brozinsky_motion_2004,
	title = {Motion velocity thresholds in deaf signers: changes in lateralization but not in overall sensitivity},
	volume = {21},
	issn = {0926-6410},
	url = {http://www.sciencedirect.com/science/article/pii/S092664100400148X},
	doi = {10.1016/j.cogbrainres.2004.05.002},
	shorttitle = {Motion velocity thresholds in deaf signers},
	abstract = {In a series of three experiments, we tested whether deaf native signers process motion velocity information differently from hearing nonsigners. In Experiment 1, participants watched radially moving dots and were asked to detect the quadrant in which the velocity of the dots had changed. Similar 79\% thresholds were observed in the two populations. In Experiments 2 and 3, peripheral and central thresholds were assessed separately as previous studies suggest early deafness leads mainly to changes in the processing of visual peripheral information. Neither condition produced an overall population difference. These negative results were not due to a lack of sensitivity in our experiments. Indeed, as has been previously reported, deaf native signers exhibited better thresholds in the right than in the left visual field, whereas the opposite pattern was observed in the hearing. This effect appears triggered by experience with American Sign Language ({ASL}) rather than deafness per se. Overall, this study confirms that early deafness does not enhance motion processing, and suggests that most of the changes previously described in the literature are instead attributable to changes in attention, and possibly special alterations of attention-to-motion processes.},
	pages = {1--10},
	number = {1},
	journaltitle = {Cognitive Brain Research},
	shortjournal = {Cognitive Brain Research},
	author = {Brozinsky, Craig J. and Bavelier, Daphne},
	urldate = {2019-05-06},
	date = {2004-09-01},
	keywords = {Plasticity, Laterality, Motion, Velocity, Deaf},
	file = {ScienceDirect Snapshot:/home/felix/Zotero/storage/R8SE6U6J/S092664100400148X.html:text/html}
}

@online{noauthor_congenital_nodate-3,
	title = {Congenital deafness is associated with specific somatosensory deficits in adolescents {\textbar} Scientific Reports},
	url = {https://www.nature.com/articles/s41598-017-04074-0},
	urldate = {2019-05-12}
}

@article{moshourab_congenital_2017,
	title = {Congenital deafness is associated with specific somatosensory deficits in adolescents},
	volume = {7},
	rights = {2017 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-017-04074-0},
	doi = {10.1038/s41598-017-04074-0},
	abstract = {Hearing and touch represent two distinct sensory systems that both rely on the transformation of mechanical force into electrical signals. Here we used a battery of quantitative sensory tests to probe touch, thermal and pain sensitivity in a young control population (14–20 years old) compared to age-matched individuals with congenital hearing loss. Sensory testing was performed on the dominant hand of 111 individuals with normal hearing and 36 with congenital hearing loss. Subjects with congenital deafness were characterized by significantly higher vibration detection thresholds at 10 Hz (2-fold increase, P {\textless} 0.001) and 125 Hz (P {\textless} 0.05) compared to controls. These sensory changes were not accompanied by any major change in measures of pain perception. We also observed a highly significant reduction (30\% compared to controls p {\textless} 0.001) in the ability of hearing impaired individual’s ability to detect cooling which was not accompanied by changes in warm detection. At least 60\% of children with non-syndromic hearing loss showed very significant loss of vibration detection ability (at 10 Hz) compared to age-matched controls. We thus propose that many pathogenic mutations that cause childhood onset deafness may also play a role in the development or functional maintenance of somatic mechanoreceptors.},
	pages = {4251},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Moshourab, Rabih and Bégay, Valérie and Wetzel, Christiane and Walcher, Jan and Middleton, Steven and Gross, Manfred and Lewin, Gary R.},
	urldate = {2019-05-12},
	date = {2017-06-26},
	file = {Full Text PDF:/home/felix/Zotero/storage/KUTL3IJC/Moshourab et al. - 2017 - Congenital deafness is associated with specific so.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/UWTXJ36F/s41598-017-04074-0.html:text/html}
}

@article{peter_sensory_2019,
	title = {Sensory Loss Enhances Multisensory Integration Performance},
	rights = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NoDerivs} 4.0 International), {CC} {BY}-{ND} 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/483586v2},
	doi = {10.1101/483586},
	abstract = {{\textless}p{\textgreater}Auditory and visual sensory loss has repeatedly been shown to alter abilities in remaining sensory modalities. It is, however, unclear whether sensory loss also impacts multisensory integration; an ability that is fundamental for the perception of the world around us. We determined effects of olfactory sensory deprivation on multisensory perception by assessing temporal as well as semantic aspects of audio-visual integration in 37 individuals with anosmia (complete olfactory sensory loss) and 37 healthy, matched controls. Participants performed a simultaneity judgement task to determine the temporal binding window, and a multisensory object identification task with individually degraded, dynamic visual, auditory, and audio-visual stimuli. Individuals with anosmia demonstrated an increased ability to detect multisensory temporal asynchronies, represented by a narrowing of the audio-visual temporal binding window. Furthermore, individuals with congenital, but not acquired, anosmia demonstrated indications of greater benefits from bimodal, as compared to unimodal, stimulus presentation when faced with degraded, semantic information. This suggests that the absence of the olfactory sense alters multisensory integration of remaining senses by sharpening the perception of cross-modal temporal violations, independent of sensory loss etiology. In addition, congenital sensory loss may further lead to increased gain from multisensory, compared to unisensory, information. Taken together, multisensory compensatory mechanisms at different levels of perceptual complexity are present in individuals with anosmia.{\textless}/p{\textgreater}},
	pages = {483586},
	journaltitle = {{bioRxiv}},
	author = {Peter, Moa G. and Porada, Danja K. and Regenbogen, Christina and Olsson, Mats J. and Lundström, Johan N.},
	urldate = {2019-05-13},
	date = {2019-05-08},
	langid = {english},
	file = {Full Text PDF:/home/felix/Zotero/storage/BXZMPMNP/Peter et al. - 2019 - Sensory Loss Enhances Multisensory Integration Per.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/4YFB4HXD/483586v2.html:text/html}
}

@article{hauthal_visuo-tactile_2015-1,
	title = {Visuo-tactile interactions in the congenitally deaf: a behavioral and event-related potential study},
	volume = {8},
	issn = {1662-5145},
	url = {https://www.frontiersin.org/articles/10.3389/fnint.2014.00098/full},
	doi = {10.3389/fnint.2014.00098},
	shorttitle = {Visuo-tactile interactions in the congenitally deaf},
	abstract = {Auditory deprivation is known to be accompanied by alterations in visual processing. Yet not much is known about tactile processing and the interplay of the intact sensory modalities in the deaf. We presented visual, tactile, and visuo-tactile stimuli to congenitally deaf and hearing individuals in a speeded detection task. Analyses of multisensory responses showed a redundant signals effect that was attributable to a coactivation mechanism in both groups, although the redundancy gain was less in the deaf. In hearing but not deaf participants, N200 latencies of somatosensory event-related potentials were modulated by simultaneous visual stimulation. In deaf but not hearing participants, however, there was a modulation of N200 latencies of visual event-related potentials due to simultaneous tactile stimulation. A comparison of unisensory responses between groups revealed larger N200 amplitudes for visual and shorter N200 latencies for tactile stimuli in the deaf. P300 amplitudes in response to both stimuli were larger in deaf participants. The differences in visual and tactile processing between deaf and hearing participants, however, were not reflected in behavior. The electroencephalography ({EEG}) results suggest an asymmetry in visuo-tactile interactions between deaf and hearing individuals. Visuo-tactile enhancements could neither be fully explained by perceptual deficiency nor by inverse effectiveness. Instead, we suggest that results might be explained by a shift in the relative importance of touch and vision in deaf individuals.},
	journaltitle = {Frontiers in Integrative Neuroscience},
	shortjournal = {Front. Integr. Neurosci.},
	author = {Hauthal, Nadine and Debener, Stefan and Rach, Stefan and Sandmann, Pascale and Thorne, Jeremy D.},
	urldate = {2019-05-13},
	date = {2015},
	keywords = {Cross-modal Plasticity, Deafness, multisensory processing, race model, redundant signals effect},
	file = {Full Text PDF:/home/felix/Zotero/storage/G8KLV9ZG/Hauthal et al. - 2015 - Visuo-tactile interactions in the congenitally dea.pdf:application/pdf}
}

@article{noauthor_audiotactile_nodate-1,
	title = {Audiotactile integration is reduced in congenital blindness in a spatial ventriloquism task},
	url = {https://app.dimensions.ai/details/publication/pub.1038248255?search_text=Visuo-tactile%20interactions%20in%20the%20congenitally%20deaf%3A%20a%20behavioral%20and%20event-related%20potential%20study&search_type=kws&search_field=full_search},
	doi = {10.1016/j.neuropsychologia.2011.10.019},
	abstract = {In the ventriloquism effect, the presentation of spatially discrepant visual information biases the localization of simultaneously presented sounds. Recently, an analogous spatial influence of touch on audition has been observed. By manipulating hand posture, it has been demonstrated that this audiotactile ventriloquist effect predominantly operates in an external frame of reference. In the present study, we examined the contribution of developmental vision to audiotactile interactions as indicated by the ventriloquism effect. Congenitally blind, late blind and sighted adults were asked to report the perceived location of sounds presented from a left, a central or a right location. Auditory stimuli were either delivered alone or concurrently with touches at the left or the right hand. The hands were located to the right and to the left of the lateral speakers and participants either adopted an uncrossed or a crossed hand posture. While sighted controls and late blind participants similarly mislocalized auditory stimuli toward the concurrent tactile stimuli in bimodal trials, the congenitally blind showed a reduced ventriloquism effect. All groups showed a reduced audiotactile ventriloquism effect in the crossed hand condition. However, the magnitude of the reduction was significantly larger in the group of congenitally blind than in the group of sighted controls. These results suggest reduced audio-tactile interactions in spatial processing following a lack of visual input from birth.},
	urldate = {2019-05-13},
	langid = {english},
	pmid = {22051726},
	file = {Snapshot:/home/felix/Zotero/storage/6UZIRXMB/pub.html:text/html}
}

@article{champoux_early-_2011-1,
	title = {Early- and Late-Onset Blindness Both Curb Audiotactile Integration on the Parchment-Skin Illusion},
	volume = {22},
	issn = {0956-7976},
	url = {https://doi.org/10.1177/0956797610391099},
	doi = {10.1177/0956797610391099},
	abstract = {It has been shown that congenital blindness can lead to anomalies in the integration of auditory and tactile information, at least under certain conditions. In the present study, we used the parchment-skin illusion, a robust illustration of sound-biased perception of touch based on changes in frequency, to investigate the specificities of audiotactile interactions in early- and late-onset blind individuals. Blind individuals in both groups did not experience any illusory change in tactile perception when the frequency of the auditory signal was modified, whereas sighted individuals consistently experienced the illusion. This demonstration that blind individuals had reduced susceptibility to an auditory-tactile illusion suggests either that vision is necessary for the establishment of audiotactile interactions or that auditory and tactile information can be processed more independently in blind individuals than in sighted individuals. In addition, the results obtained in late-onset blind participants suggest that visual input may play a role in the maintenance of audiotactile integration.},
	pages = {19--25},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Champoux, François and Collignon, Olivier and Bacon, Benoit A. and Lepore, Franco and Zatorre, Robert J. and Théoret, Hugo},
	urldate = {2019-05-13},
	date = {2011-01-01},
	langid = {english}
}

@article{collignon_early_2009,
	title = {Early visual deprivation alters multisensory processing in peripersonal space},
	volume = {47},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S0028393209003194},
	doi = {10.1016/j.neuropsychologia.2009.07.025},
	abstract = {Multisensory peripersonal space develops in a maturational process that is thought to be influenced by early sensory experience. We investigated the role of vision in the effective development of audiotactile interactions in peripersonal space. Early blind ({EB}), late blind ({LB}) and sighted control ({SC}) participants were asked to lateralize auditory, tactile and audiotactile stimuli. The experiment was conducted with the hands uncrossed or crossed over the body midline in order to alter the relationship between personal and peripersonal spatial representations. First, we observed that the crossed posture results in a greater detrimental effect for tactile performance in sighted subjects but a greater deficit in auditory performance in early blind ones. This result is interpreted as evidence for a visually driven developmental process that automatically remaps tactile and proprioceptive spatial representation into an external framework. Second, we demonstrate that improved reaction times observed in the bimodal conditions in {SC} and {LB} exceeds that predicted by probability summation in both conditions of postures, indicating neural integration of different sensory information. In {EB}, nonlinear summation was obtained in the uncrossed but not in the crossed posture. We argue that the default use of an anatomically anchored reference system in {EB} prevents effective audiotactile interactions in the crossed posture due to the poorly aligned spatial coordinates of these two modalities in such conditions. Altogether, these results provide compelling evidence for the critical role of early vision in the development of multisensory perception and action control in peripersonal space.},
	pages = {3236--3243},
	number = {14},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Collignon, Olivier and Charbonneau, Geneviève and Lassonde, Maryse and Lepore, Franco},
	urldate = {2019-05-13},
	date = {2009-12-01},
	keywords = {Somatosensory, Multisensory, Auditory, Blindness, Peripersonal space, Redundant signal effect ({RSE})},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/M8MJH5SE/Collignon et al. - 2009 - Early visual deprivation alters multisensory proce.pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/JNQG6I4E/S0028393209003194.html:text/html}
}

@article{noauthor_hearing_nodate-1,
	title = {Hearing Cheats Touch, but Less in Congenitally Blind Than in Sighted Individuals},
	url = {https://app.dimensions.ai/details/publication/pub.1025149778?search_text=Visuo-tactile%20interactions%20in%20the%20congenitally%20deaf%3A%20a%20behavioral%20and%20event-related%20potential%20study&search_type=kws&search_field=full_search},
	doi = {10.1111/j.0963-7214.2004.01501010.x},
	abstract = {The principles of cross-modal integration were investigated with an auditory-tactile illusion in sighted and congenitally blind adults. Participants had to judge the number of rapidly presented tactile stimuli, which were presented together with task-irrelevant sounds. When one tactile stimulus was accompanied by more than one tone, participants reported perceiving more than a single touch. This illusion was more pronounced in sighted than congenitally blind participants. Given that the congenitally blind were more precise in judging the number of tactile stimuli in a control condition without tones, the present data are in accordance with a modality-appropriateness account suggesting that interference by a task-irrelevant modality is reduced if processing accuracy of the task-relevant modality is high.},
	urldate = {2019-05-13},
	langid = {english},
	pmid = {14717833},
	file = {Snapshot:/home/felix/Zotero/storage/8I5SLFLI/pub.html:text/html}
}

@article{noauthor_early_nodate,
	title = {Early visual deprivation impairs multisensory interactions in humans},
	url = {https://app.dimensions.ai/details/publication/pub.1007827909?search_text=Visuo-tactile%20interactions%20in%20the%20congenitally%20deaf%3A%20a%20behavioral%20and%20event-related%20potential%20study&search_type=kws&search_field=full_search},
	doi = {10.1038/nn1978},
	abstract = {Animal studies have shown that visual deprivation during the first months of life permanently impairs the interactions between sensory systems. Here we report an analogous effect for humans who had been deprived of pattern vision for at least the first five months of their life as a result of congenital binocular cataracts. These patients showed reduced audio-visual interactions in later life, although their visual performance in control tasks was unimpaired. Thus, adequate (multisensory) input during the first months of life seems to be a prerequisite in humans, as well as in animals, for the full development of cross-modal interactions.},
	urldate = {2019-05-13},
	langid = {english},
	pmid = {17873871},
	file = {Snapshot:/home/felix/Zotero/storage/8U4DLQNP/pub.html:text/html}
}

@article{nava_audio-tactile_2014-2,
	title = {Audio-Tactile Integration in Congenitally and Late Deaf Cochlear Implant Users},
	volume = {9},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0099606},
	doi = {10.1371/journal.pone.0099606},
	abstract = {Several studies conducted in mammals and humans have shown that multisensory processing may be impaired following congenital sensory loss and in particular if no experience is achieved within specific early developmental time windows known as sensitive periods. In this study we investigated whether basic multisensory abilities are impaired in hearing-restored individuals with deafness acquired at different stages of development. To this aim, we tested congenitally and late deaf cochlear implant ({CI}) recipients, age-matched with two groups of hearing controls, on an audio-tactile redundancy paradigm, in which reaction times to unimodal and crossmodal redundant signals were measured. Our results showed that both congenitally and late deaf {CI} recipients were able to integrate audio-tactile stimuli, suggesting that congenital and acquired deafness does not prevent the development and recovery of basic multisensory processing. However, we found that congenitally deaf {CI} recipients had a lower multisensory gain compared to their matched controls, which may be explained by their faster responses to tactile stimuli. We discuss this finding in the context of reorganisation of the sensory systems following sensory loss and the possibility that these changes cannot be “rewired” through auditory reafferentation.},
	pages = {e99606},
	number = {6},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Nava, Elena and Bottari, Davide and Villwock, Agnes and Fengler, Ineke and Büchner, Andreas and Lenarz, Thomas and Röder, Brigitte},
	urldate = {2019-05-13},
	date = {2014-06-11},
	langid = {english},
	keywords = {Vision, Reaction time, Deafness, Audio signal processing, Cataracts, Cognitive impairment, Sensory perception, Visual impairments},
	file = {Full Text PDF:/home/felix/Zotero/storage/AAZELBLI/Nava et al. - 2014 - Audio-Tactile Integration in Congenitally and Late.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/857QLP87/article.html:text/html}
}

@article{noauthor_temporary_nodate,
	title = {Temporary Deafness Can Impair Multisensory Integration},
	url = {https://app.dimensions.ai/details/publication/pub.1031443327?search_text=Visuo-tactile%20interactions%20in%20the%20congenitally%20deaf%3A%20a%20behavioral%20and%20event-related%20potential%20study&search_type=kws&search_field=full_search},
	doi = {10.1177/0956797612471142},
	abstract = {Previous investigations suggest that temporary deafness can have a dramatic impact on audiovisual speech processing. The aim of this study was to test whether temporary deafness disturbs other multisensory processes in adults. A nonspeech task involving an audiotactile illusion was administered to a group of normally hearing individuals and a group of individuals who had been temporarily auditorily deprived. Members of this latter group had their auditory detection thresholds restored to normal levels through the use of a cochlear implant. Control conditions revealed that auditory and tactile discrimination capabilities were identical in the two groups. However, whereas normally hearing individuals integrated auditory and tactile information, so that they experienced the audiotactile illusion, individuals who had been temporarily deprived did not. Given the basic nature of the task, failure to integrate multisensory information could not be explained by the use of the cochlear implant. Thus, the results suggest that normally anticipated audiotactile interactions are disturbed following temporary deafness.},
	urldate = {2019-05-13},
	langid = {english},
	pmid = {23722977},
	file = {Snapshot:/home/felix/Zotero/storage/SEII4SY7/pub.html:text/html}
}

@article{occelli_audiotactile_2012,
	title = {Audiotactile integration is reduced in congenital blindness in a spatial ventriloquism task},
	volume = {50},
	issn = {0028-3932},
	url = {http://www.sciencedirect.com/science/article/pii/S0028393211004945},
	doi = {10.1016/j.neuropsychologia.2011.10.019},
	abstract = {In the ventriloquism effect, the presentation of spatially discrepant visual information biases the localization of simultaneously presented sounds. Recently, an analogous spatial influence of touch on audition has been observed. By manipulating hand posture, it has been demonstrated that this audiotactile ventriloquist effect predominantly operates in an external frame of reference. In the present study, we examined the contribution of developmental vision to audiotactile interactions as indicated by the ventriloquism effect. Congenitally blind, late blind and sighted adults were asked to report the perceived location of sounds presented from a left, a central or a right location. Auditory stimuli were either delivered alone or concurrently with touches at the left or the right hand. The hands were located to the right and to the left of the lateral speakers and participants either adopted an uncrossed or a crossed hand posture. While sighted controls and late blind participants similarly mislocalized auditory stimuli toward the concurrent tactile stimuli in bimodal trials, the congenitally blind showed a reduced ventriloquism effect. All groups showed a reduced audiotactile ventriloquism effect in the crossed hand condition. However, the magnitude of the reduction was significantly larger in the group of congenitally blind than in the group of sighted controls. These results suggest reduced audio–tactile interactions in spatial processing following a lack of visual input from birth.},
	pages = {36--43},
	number = {1},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Occelli, Valeria and Bruns, Patrick and Zampini, Massimiliano and Röder, Brigitte},
	urldate = {2019-05-13},
	date = {2012-01-01},
	keywords = {Tactile, Auditory, Blindness, Spatial, Audiotactile, Ventriloquism},
	file = {ScienceDirect Full Text PDF:/home/felix/Zotero/storage/G9WLTQFI/Occelli et al. - 2012 - Audiotactile integration is reduced in congenital .pdf:application/pdf;ScienceDirect Snapshot:/home/felix/Zotero/storage/TIFAWQSC/S0028393211004945.html:text/html}
}

@article{hotting_hearing_2004-1,
	title = {Hearing Cheats Touch, but Less in Congenitally Blind Than in Sighted Individuals},
	volume = {15},
	issn = {0956-7976},
	url = {https://doi.org/10.1111/j.0963-7214.2004.01501010.x},
	doi = {10.1111/j.0963-7214.2004.01501010.x},
	abstract = {The principles of cross-modal integration were investigated with an auditory-tactile illusion in sighted and con-genitally blind adults. Participants had to judge the number of rapidly presented tactile stimuli, which were presented together with task-irrelevant sounds. When one tactile stimulus was accompanied by more than one tone, participants reported perceiving more than a single touch. This illusion was more pronounced in sighted than congenitally blind participants. Given that the congenitally blind were more precise in judging the number of tactile stimuli in a control condition without tones, the present data are in accordance with a modality-appropriateness account suggesting that interference by a task-irrelevant modality is reduced if processing accuracy of the task-relevant modality is high.},
	pages = {60--64},
	number = {1},
	journaltitle = {Psychological Science},
	shortjournal = {Psychol Sci},
	author = {Hötting, Kirsten and Röder, Brigitte},
	urldate = {2019-05-13},
	date = {2004-01-01},
	langid = {english}
}

@article{landry_temporary_2013-2,
	title = {Temporary Deafness Can Impair Multisensory Integration: A Study of Cochlear-Implant Users},
	url = {https://journals.sagepub.com/doi/abs/10.1177/0956797612471142},
	doi = {10.1177/0956797612471142},
	shorttitle = {Temporary Deafness Can Impair Multisensory Integration},
	abstract = {Previous investigations suggest that temporary deafness can have a dramatic impact on audiovisual speech processing. The aim of this study was to test whether t...},
	journaltitle = {Psychological Science},
	author = {Landry, Simon P. and Guillemot, Jean-Paul and Champoux, François},
	urldate = {2019-05-13},
	date = {2013-05-30},
	langid = {english},
	file = {Snapshot:/home/felix/Zotero/storage/EMWKA7UW/0956797612471142.html:text/html}
}

@article{goldreich_tactile_2003-3,
	title = {Tactile Acuity is Enhanced in Blindness},
	volume = {23},
	rights = {Copyright © 2003 Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/23/8/3439},
	doi = {10.1523/JNEUROSCI.23-08-03439.2003},
	abstract = {Functional imaging studies in blind subjects have shown tactile activation of cortical areas that normally subserve vision, but whether blind people have enhanced tactile acuity has long been controversial. We compared the passive tactile acuity of blind and sighted subjects on a fully automated grating orientation task and used multivariate Bayesian data analysis to determine predictors of acuity. Acuity was significantly superior in blind subjects, independently of the degree of childhood vision, light perception level, or Braille reading. Acuity was strongly dependent on the force of contact between the stimulus surface and the skin, declined with subject age, and was better in women than in men. Despite large intragroup variability, the difference between blind and sighted subjects was highly significant: the average blind subject had the acuity of an average sighted subject of the same gender but 23 years younger. The results suggest that crossmodal plasticity may underlie tactile acuity enhancement in blindness.},
	pages = {3439--3445},
	number = {8},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Goldreich, Daniel and Kanics, Ingrid M.},
	urldate = {2019-05-13},
	date = {2003-04-15},
	langid = {english},
	pmid = {12716952},
	keywords = {crossmodal plasticity, blind, Braille, grating orientation, sensory compensation, somatosensory psychophysics, tactile acuity},
	file = {Full Text PDF:/home/felix/Zotero/storage/6YMHXCF8/Goldreich and Kanics - 2003 - Tactile Acuity is Enhanced in Blindness.pdf:application/pdf;Snapshot:/home/felix/Zotero/storage/AFRM43KP/3439.html:text/html}
}